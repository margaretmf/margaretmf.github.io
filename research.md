# Research Questions and Studies #
* A Study on the American Flag, and what the American flag represents through Text
* A Study on Light in the Darkness, and Where This Comes Up in Books, and What This Means, and Its Spiritual Significance
* A Study on Societal Wholeness, and Connectedness; This Concept Comes Up in Multiple Books, Authors, and Texts, and It Is Spiritual
* A Study on Signs and Sybmols
* A Study on Interracial Dating and Marriages 
* A Study on Democracy and Church
* A Study on Shays' Rebellion in Relationship to the Trump Election
* A Study on Cultures that Influence and Shape Engineering
* A Study on the Dark Web
* A Study on What People Listen to While Driving
* A Study on Weaving Individual Narratives with Collective, National Narratives
* A Study on Harassment - Why Do People Harass People? Men, Women, Women, Men; What's the Boundary Between Teasing, Flirting, Harassment
* A Study on the Boundaries on the Internet; the Relationship Between the Boundaries on the Internet and the Boundaries on the Road - the Internet Highway
* A Study on What People Choose to Study and Learn in College


----------


# Romanticism #
## [Romanticism]() ##
* Lyrical Ballads, 1798 the word "Romantic", "fanciful, light, inconsequential", "the concept of Romanticism"
* European Intellectuals, German Literature
* Byron, Dante, Petrach, Boccaccio, Blake, Wordsworth, Coleridge, Byron, Shelley, Keats, Southey, Scott, Shelley
* Charlotte Smith, Hannah More, Anna Laetita Barbauld, Helen Maria Williams, Felicia Dorothea Hemans, Letitia Landon
* "Romantic writers", "English poets"
* The Romantic period, immediacy; values and proccupations; "it coincides with the moment at which Britain industrialized itself. Factories sprang up in towns and cities across the country, and the agrarian lives people had known for centuries stopped being taken for granted. Instead labourers began to move into conurbations, working long hours in close proximity to each other."
* "Today we take our rights for granted, forgetting the length of the intellectual journey workig people had to make merely to understand they had such things."
* "very similar to the feudal system of medieval times continued to dictate their place in society"
* "The process by which people were awakened to a sense of self-determination was global. It began with the American Revolution and continued with that in France. And the impact of those upheavals cannot be overstated. Whole populations began to question the legitimacy of hereditary monarchs whose right to rule had once been accepted"
* National cause, patriotic feeling
* "the inventions of the steam press and the paper-making machine (1814, 1803)" - "produce newspapers on a an industrial scale"


----------


# History #
## How is History Shared? How Do We Appreciate and Share the Past? ##
English teachers define "romance" as "somewhere between the real world and fairy-land, where the actual and imaginary may meet, and each imbue itself with the nature of the other."

People tell stories about the past to share what people overcome, the life lessons people learned, how people lived their lives, and how people loved, and chose to sing through their days. 

It's great to appreciate the best parts of our nation, our families, and our individual past. Stories of the past teach people lessons. People can learn to express the qualities they've heard and felt others express. People can appreciate the reality of today [today's reality] that has evolved from the reality of yesterday [yesterday' reality].

It's also great to learn from the past's dark aspects.

Romanticizing the past stems from feeling like people have lost something from years ago. Romanticizing the past also stems from glorifying a past that was not as pretty in reality. Aspects of the past still remain present today in new forms. Through stories, people can take up dark aspects of the past and learn from them. Also through stories, people can take up hidden realities not fully exposed to the light.

Sharing history helps people understand why the world exists and appears as the way it is, and how our ancestors made decisions. Sharing stories from the past differs from believing that the past is better than the present in an imagined way, however. 

## [The Concept of Scientific History](https://www.jstor.org/stable/2504255?seq=1) ##
"History, according to Aristotle, is an account of what individual human beings have done and suffered. More widely still, history is what historians do. Is history, in this sense, a science, as, let us say, physics or biology or psychology are sciences? And if not, should it seek to be one? And if it fails to be one, what prevents it? Is this due to human weakness, or to the nature of the subject, or does the very problem rest on a confusion between the concept of history and that of natural science? These have been questions that have occupied the minds of both philosophers and philosophically minded historians at least since the beginning of the nineteenth century, when men became self-conscious about the purpose and logic of their intellectual activities. But two centuries before that, Descartes had already denied to history any claim to be a serious study. Those who accepted the validity of the Cartesian criterion of what constitutes rational method could (and did) ask how they could find the clear and simple element could find the clear and simple elements of which historical judgments were composed, and into which they could be analysed; where were the definitions, the logical transformation rules, the rules of inference, the rigorously deduced conclusions?  While this confused amalgam of memories and travelers' tales, fables and  and chroniclers' stories, moral reflections and gossip, might be a harmless pastime, it was beneath the dignity of serious men seeking what alone is worth seeking - the discovery of the truth in accordance with the principles and rules which alone guarantee scientific validity. 

Ever since this doctrine of what was and what was not a science was enunciated, those who have thought about the nature of historical studies have laboured under the stigma of the Cartesian condemnation. Some have tried to show that history could be made respectable by being assimiilated to one of the natural sciences, whose overwhelming success and prestige in the seventeenth and eighteenth centuries held out promise of rich fruit wherever their methods were applicable; others declared that history was indeed a science, but a science in some different sense, with its own methods and canons, no less exacting than those of the sciences of nature, but resting on foundations different from them; others defiantly declared that history was indeed subjective, impressionistic, incapable of being made rigorous, a branch of literature, or an expression"


----------


# I Believe #
## [Credo: 'I Believe...'](https://pluralism.org/credo-“i-believe”) ##
"Statements of belief unite Christians in their articulation of shared commitments. While the Apostles' Creed and the Nicene Creed are the oldest and most universal creeds of the churhc, the process of articulating what it means to give one's heart to Christ has continued to the present.

One of the distinctive features of Christianity is its emphasis on a creed, a summary statement of faith. The Latin term *credo* is often translated today as 'I believe...' but it is important to remember that its literal meaning is 'I give my heart...' It is language of the heart, a profound expression of commitment, not simply a list of statements to which one gives intellectual assent. When the early church was being persecuted, commitment to the way of Christ was often dangerous, requiring true courage.f

Creeds came into use as part of the rite of baptism. In this rite of initiation, a man or woman would take off old clothes, but on new white baptismal clothing, and become a Christian by a ritual bath and the affirmation of commitment to the Christian faith. The *credo* or *creed* expressed that commitment. Among the oldest creeds of the church is the Apostles' Creed, composed about 150 CE and used ritually at the time of Christian baptism, and starts, 'I believe in God, the Father Almighty, creator of heaven and earth. I believe in Jesus Christ, his only Son, Our Lord...' Through baptism, one was spiritually 'born again.' While the term 'born-again' has acquired the resonance of a dramtic and often emotion-laden conversion in modern American Christianity, it has a much wider and older significance for the church. To be 'born again' is what it means to be a baptized Christian.

Christians in the early church had to answer for themselves the question Christ asked his disciples, 'Who do you say that I am?' In the councils of the early church, leaders met to come to a common mind about their faith. The Council of Nicaea, called by the Emperor Constantine in 325 CE, was the most important of these early councils. In the previous centuries, some ahd proposed that Jesus Christ was not really human at all, but was God appearing to be human; others had proposed that he was not really divine, but only a human being. The early church rejected these views as it worked together to articulate its faith: that Jesus Christ was fully God and fully human. The council also worked to express the menaing of God as threefold, a trinity, encompassing three aspects or 'persons' - the Father, the Son Jesus Christ, and the Holy Spirit. At Nicaea, the church articulated the complexity of the divine mystery: that the one God is the transcendent Creator, the fully human Christ, and the indwelling energy, fire, and breath of the Spirit.

While the Apostles' Creed and the Nicene Creed are the oldest and most universal creeds of the church, the process of articulating what it means to give one's heart to Christ ahs continued to the present. New creeds are written in each new era."

## [The American Credo](https://www.freedomsfoundation.org/about/american-credo/) ##
"Right to worship God in one's own way

Right to free speech and press

Right to peaceabily assemble

Right to petition for redress of grievances

Right to privacy in our homes

Right of habeas corpus - no excessive bail

Right to trial by jury - innocent until proven guilty

Right to move about freely at home and abroad

Right to own property

Right to free elections and personal secret ballot

Right to work in callings and localities of our choice

Right to bargain with our employers and employees

Right to go into business, compete, and make a profit

Right to bargain for goods and services in a free market

Right to contract about out affairs

Right to the service of government as a protector and referee

Right to freedom fro arbitrary government regulation and control

To personally understand and maintain the American way of life, to honor by his own exemplary conduct, and to pass this credo intact to succeeding generations is the responsibility of every true American"

## [This I Believe](https://www.npr.org/series/4538138/this-i-believe) ##
"During its four-year run on NPR, This I Believe engaged listeners in a discussion of the core beliefs that guide their daily lives. We heard from people of all walks of life — the very young and the very old, the famous and the previously unknown.'


----------


# Thomas Jefferson, Church and State #
## [Thomas Jefferson](https://billofrightsinstitute.org/founders/thomas-jefferson) ##
"Thomas Jefferson hoped that he would be remembered for three accomplishments: his founding of the University of Virginia, his crafting of the Virginia Statute for Religious Freedom, and his authorship of the Declaration of Independence. It is for the last that he has most endeared himself to succeeding generations as a champion of liberty and equality.

Jefferson believed that these achievements were the high points of a life dedicated to the promotion of human freedom. Education, he held, freed the mind from ignorance, tolerance freed the will from coercion, and the assertion of human liberty and equality freed the body from the chains of tyranny. Securing religious liberty in the new republic was one of Thomas Jefferson’s most important goals. His papers, including the letter to the Danbury Baptists Association, as well as the Virginia Statute for Religious Freedom, reveal a statesman who recognized the civic utility of religion, but believed that government had no business regulating belief.

However, Jefferson’s actions sometimes contradicted his words. An opponent of centralized power, as president he completed the Louisiana Purchase and unhesitatingly employed the resources of the federal government to enforce the harsh and unpopular Embargo Act. Although a proponent of individual rights, he excused the atrocities committed by the French Revolutionaries during the Reign of Terror. A critic of slavery who outlawed the slave trade as president, he was the owner of more than 200 African American slaves. Understanding Jefferson lies in the difficult task of reconciling these inconsistencies."

## [Native American Influences on American Government](https://edtechbooks.org/democracy/nativeinfluence) ##
"1.INVESTIGATE: The Iroquois Confederacy and the Great Law of Peace

The Iroquois Confederacy refers to a group of indigenous tribes living in northeastern North America that had a participatory democracy government with executive, legislative, and judicial branches. The Great Law of Peace was the constitution of the Iroquois Confederacy. Here is the text of The Constitution of the Iroquois Confederacy and its 117 articles."

"The framework of government in the Iroquois Confederacy is said to have inspired Thomas Jefferson, George Washington, Benjamin Franklin and other founders as they wrote the Constitution. The founders adopted the Iroquois nation's symbol, the bald eagle, as the new nation's national symbol.  

Some historians credit the Iroquois chief Canasatego with influencing Benjamin Franklin’s thinking about government (Franklin included references to the Iroquois Confederacy in his writing). Canasatego shared how the Great Law of Peace, the Iroquois Confederacy’s unwritten constitution, included rules of democratic self-government including the rights and responsibilities of each member tribe. He also stressed the importance of a unified, representative government.

In 1988, the United States Senate passed a resolution acknowledging the contributions of the Iroquois Confederacy (Text of Senate Resolution on the Contributions of the Iroquois Confederacy). However, in none of the constitutions of the 13 colonies were First Americans’ rights included and Native Americans did not gain citizenship until 1924.

Today, Native Americans still live with a legacy of inadequate resources and services and continuing social and economic discrimination. In its "Broken Promises" report, the U.S.Commission of Civil Rights (2018) recounted the history as follows:

"In exchange for the surrender and reduction of tribal lands and removal and resettlement of approximately one-fifth of Native American tribes from their original lands, the United States signed 375 treaties, passed laws, and instituted policies that shape and define the special government-to-government relationship between federal and tribal governments. Yet the U.S. government forced many Native Americans to give up their culture and, throughout the history of this relationship, has not provided adequate assistance to support Native American interconnected infrastructure, self-governance, housing, education, health, and economic development needs" (para. 1)."

## [The Native American Government That Inspired the US Constitution](https://www.history.com/news/iroquois-confederacy-influence-us-constitution) ##
"When the delegates to the Constitutional Convention met in 1787 to debate what form of government the United States should have, there were no contemporary democracies in Europe from which they could draw inspiration. The most democratic forms of government that any of the convention members had personally encountered were those of Native American nations. Of particular interest was the Iroquois Confederacy, which historians have argued wielded a significant influence on the U.S. Constitution.

What evidence exists that the delegates studied Native governments? Descriptions of them appear in the three-volume handbook John Adams wrote for the convention surveying different types of governments and ideas about government. It included European philosophers like John Locke and Montesquieu, whom U.S. history textbooks have long identified as constitutional influences; but it also included the Iroquois Confederacy and other Indigenous governments, which many of the delegates knew through personal experience.

'You had the Cherokee chiefs having dinner with [Thomas] Jefferson’s father in Williamsburg, and then in the northern area of course you had this Philadelphia interaction with the Delaware and the Iroquois,' says Kirke Kickingbird, a lawyer, member of the Kiowa Tribe and coauthor with Lynn Kickingbird of Indians and the United States Constitution: A Forgotten Legacy.

Since the U.S. had trade and diplomatic relationships with Native governments, Kickingbird says, thinking the constitutional framers weren’t familiar with them is like saying, 'Gosh, I didn’t know the Germans and the French knew each other.'"

"Similarities and Differences Between the Iroquois Confederacy and the US Constitution

The Iroquois Confederacy was in no way an exact model for the U.S. Constitution. However, it provided something that Locke and Montesquieu couldn’t: a real-life example of some of the political concepts the framers were interested in adopting in the U.S.

The Iroquois Confederacy dates back several centuries, to when the Great Peacemaker founded it by uniting five nations: the Mohawks, the Onondaga, the Cayuga, the Oneida and the Seneca. In around 1722, the Tuscarora nation joined the Iroquois, also known as the Haudenosaunee. Together, these six nations formed a multi-state government while maintaining their own individual governance.

This stacked-government model influenced constitutional framers’ thinking, says Donald A. Grinde, Jr., a professor of transnational studies at the University of Buffalo, member of the Yamasee nation and co-author with Bruce E. Johansen of Exemplar of Liberty: Native America and the Evolution of Democracy.

The constitutional framers 'cite the Iroquois and other Native governments as examples of [federalism],” he says. 'Marriage and divorce is taken care of right in the village; it’s not a thing that the national government or the chiefs have to do with. Each tribe might have its own issues, but the Iroquois Confederacy is about…unification through mutual defense and it conducts foreign affairs.'

The chiefs of the six nations were hereditary rulers, something the framers wanted to avoid, given their grievances with Britain’s King George III. Still, the framers 'did seek to borrow aspects of Iroquois government that enabled them to assert the people's sovereignty over vast geographic expanses since they found no governments in Europe with these characteristics,' Grinde and Johansen write in Exemplar of Liberty."

"Congress Formally Recognizes Iroquois Influence

The fact that many of the framers looked to Native governments for inspiration didn’t stop them from viewing Native people as inferior. This disconnect is evident in a 1751 letter from Benjamin Franklin describing the need for the 13 colonies to form a 'voluntary Union' similar to that of the Iroquois Confederacy:

'It would be a very strange Thing, if six Nations of ignorant Savages should be capable of forming a Scheme for such an Union, and be able to execute it in such a Manner, as that it has subsisted Ages, and appears indissoluble; and yet that a like Union should be impracticable for ten or a Dozen English Colonies, to whom it is more necessary, and must be more advantageous; and who cannot be supposed to want an equal Understanding of their Interests.'

The United States’ bias and violence against Native Americans may have helped obscure the framers’ interest in their governments. However, public awareness of this connection increased around the 1987 bicentennial marking the 200th anniversary of the Constitution.

'Oren Lyons, who was a Faithkeeper for the Iroquois Confederacy, went to the Senate Select Committee on Indian Affairs and broached this subject,' Grinde says. 'And then I went down to Washington and testified before the Senate Select Committee on Indian Affairs.'

This motivated the committee’s chair, Daniel Inoue of Hawaii, to help Congress pass a 1988 resolution formally acknowledging the influence of the Iroquois Confederacy on the U.S. Constitution. In addition to this recognition, the resolution reaffirmed 'the continuing government-to-government relationship between Indian tribes and the United States established in the Constitution'—an acknowledgement of the legitimacy and sovereignty of Native nations and their governments."

## [Heal the Land](https://www.gofundme.com/f/southern-bipoc-farm-retreat) ## 
"we seek to support Black and Indigenous people and people of color in their healing by helping them reconnect with nature.

guided by our ancestors through both blood and thought, we aim to acquire land in the West Tennessee/ Mississippi Delta region for a farm, retreat, residency, and education center. 

“Revolution is based on land. Land is the basis of all independence. Land is the basis of freedom, justice, and equality.”

— Malcolm X

we have found a property in West Tennessee that could not be more perfect. down a winding dirt road sits a magical oasis with passionflower growing wild and nut trees dotting a long driveway. this 40-acre farm holds a 3.5-acre lake, a barn, a fenced pasture as well as a quonset house. there's additional power and septic for other structures. 

our objectives ::

- offer retreats and residencies to organizers, activists, and artists; a space to rest, heal, and create while living in right relationship with the Earth
- provide healing and learning experiences to people in the Mississippi Delta / West Tennessee region
- expand collective imagination through experiments in liberatory living"

## ["Heal Their Land": Evangelical Political Theology from the Great Awakening to the Moral Majority]() ##
In the 1970s, a movement arose among white American evangelicals and fundamentalists that has been labeled variously as the “Christian Right,” or more broadly, “the Religious Right.” While they had not been entirely apolitical in the middle decades of the twentieth century, in the 1970s many theologically conservative Protestants began to organize specifically around their religious concerns, forming a number of groups—of which the Moral Majority was the best-known—in an effort to “bring the nation back to God.” They also moved to the political right, joining forces with “New Right” activists who were seeking to push the Republican Party in a more conservative direction. This dissertation examines the deep roots, long development and vigorous deployment of the ideology of the leaders of this movement. This ideology can be described as a “political theology,” since these evangelicals and fundamentalists thought and wrote in theological categories. Leaders like Jerry Falwell believed that the nation had been founded in a special relationship with God; that it was now being corrupted by an anti-God philosophy; that things as varied as abortion, the push for gay and lesbian rights, the lack of prayer in public schools, the Equal Rights Amendment, and attempts to reduce the nation’s nuclear weapons were evidence of this corruption; and that the time might be short before God judged America. In the words of II Chronicles 7:14, these leaders sought to “heal their land.”

## [Thomas Jefferson and the Ideology of Democratic Schooling](https://democracyeducationjournal.org/cgi/viewcontent.cgi?article=1084&context=home) ##
"But his views on education have been unchallenged. While his reputation as a founding father of the American republic has been subject to revision, his reputation as a founding father of public education has not. He is still remembered uncritically for his ardent support for an educated public as a bastion against the encroach- ment of an overzealous government. He is still praised universally for his dedication to the creation and success of the University of Virginia. His inclusion of the founding of this university as one of the three achievements listed in his tombstone epitaph is well known, as is his admonition that “not a word more” be added (Peterson, 1984, p. 706). He continues to be recognized for being as adamant about the value of educating citizens near the end of his life in 1825 as he was in 1779 when he first proposed to create a system of publicly-supported schools for the children in Virginia. This emphasis he placed on public education has contributed to no less an intellectual figure than John Dewey (1940) to call Jefferson “our first great democrat” (pp. 2-3). Dumas Malone (1948), in his exhaustive biography of Jefferson, called him “the foremost advocate of public education in the early United States” (p. 280). Heslep (1969) has suggested that Jefferson provided “a general statement on education in republican, or democratic society”
(p. 113), without distinguishing between the two. Others have opted specifically to connect his ideas to being democratic. Williams (1967) argued that Jefferson’s impact on our schools is pronounced because “democracy and education are interdependent” and therefore with “education being necessary to its [democracy’s] success, a successful democracy must provide it” (p. 266, 286). James B. Conant (1940) wrote that Jefferson believed that universal educational opportunities would create “a more equitable distribu- tion of opportunity for all the children of the land” (p. 598). And a more recent biographer posits that “the law [Jefferson] considered the most important to the success of all others” was that “to establish a democratic system of education” (Randall, 1993, p. 306).

Contemporary understandings of terminology such as democratic schooling and republican education complicate coming to grips with Jefferson’s own philosophy. Let me make explicit the distinction between democratic schooling and republican education. For most educators and democratic theorists in the late 20th and 21st centuries, democratic schooling refers to pedagogical practices that prepare students to be active citizens. For example, strategies that afford firsthand experience in critical thinking and decision-making are part of a democratic curriculum. Empowering students in meaningful ways to help determine curricular content and assignments help to establish democratic learning communities. Ideally such democratic practice extends to create an entire school atmosphere that empowers students and creates equal opportunities for all to serve in leadership positions and to influence educational decisions.

As used today, republican education generally refers to efforts to prepare students to be good citizens. Republican education hopes to help students know their rights and responsibilities, understand the political and historical legacy of important documents and government actions, and meet the expectations of citizenship. This is characterized by stressing the value of voting, serving on a jury, being a productive member of society, and participating in other ways such as staying informed on current issues and expressing opinions to elected representatives.

Since democratic and republican meant very different things in Jefferson’s time than they do now, it is not within the purview of

One of the personal benefits of this experience was the reinforcement of his love for reading and learning. The pleasure Jefferson found in reading would merge with a belief that maximiz- ing one’s educational opportunities was a civic responsibility. A product of the Enlightenment, he wrote to John Trumbull in 1788 that he considered “Bacon, Locke and Newton . . . as the three greatest men that ever lived, without any exception and as having laid the foundation of those superstructures which have been raised in the Physical and Moral sciences” (Boyd, 1950–2008, Vol. V, p. 561).

Through reading Scottish, English, and French philosophers, Jefferson culled the components of his own philosophy and then synthesized them in the American context. Education in America was a liberating experience that could not be equaled elsewhere. Even after living in France during the 1780s, Jefferson would continue to see life in the United States as offering distinct advan- tages over that of European nations. The fundamental principle of American republicanism would offer social, economic, and moral advantages that no other system could. In a letter to John Bannister, Jr., in 1785, Jefferson discussed what he saw as the disadvantages of sending children to Europe to be educated. There were innumer- able vices to tempt young men, not the least of which were a fondness for 'drinking, horse racing and boxing,' 'a partiality for aristocracy or monarch,' 'a spirit for female intrigue' which led to 'a passion for whores' and 'to consider fidelity to the marriage bed as an ungentlemanly practice and inconsistent with happiness'

In other words, knowledge would enable a citizen to fulfill the ideals Jefferson stated in the Declaration of Independence in 1776: to protect their 'inalienable rights' of 'life, liberty and the pursuit of happiness.' In a republican government there could be no other role for citizens, since they were responsible for the government that made the laws by which all were to abide. As Jefferson would maintain persistently, it was the duty of citizens to provide the security against abuse that governments, even elected governments, might succumb. A citizen’s responsibility was to protect his own freedom and that of his neighbor as well. (I use the masculine pronouns to conform to Jefferson’s narrow definition of participatory citizens.) This responsibility was common to all citizens, be they wealthy or poor, tradesman or farmer. This was the job primary schools, both public and private, were to do. In 1818 he wrote that one of the objectives of education was “to instruct the mass of our citizens in these, their rights, interests and duties, as men and citizens” (Peterson, 1984, p. 459). This would be the common bond uniting all citizens regard-

Jefferson first proposed a comprehensive plan for educating citizens according to his vision in 1779. For this purpose he specifically introduced three pieces of legislation for consideration by the Virginia legislature: A Bill for Establishing a Public Library, A Bill for the Amending of the Constitution of the College of William and Mary, and A Bill for the More General Diffusion of Knowledge. As a package they would provide a literate citizenry able to make informed decisions, the opportunity for the most gifted students even among the poor to advance to a college education, the liberation of the center of higher learning in Virginia from the restrictions of religious dogma thus freeing individuals to pursue their own courses of knowledge, and the creation of opportunities for all men to keep abreast of developments in national and international affairs, politics, philosophy, and other important subjects.

A Bill for the More General Diffusion of Knowledge would remain a favorite of Jefferson’s. The bill was intended to create a pyramid system of education in Virginia. This plan would remain essentially the same according to another bill submitted in 1817 entitled A Bill for Establishing a System of Public Education. As noted earlier, the basic units responsible for maintaining this system were the hundreds or, as he called them later, the wards that would fall within each county. Each of these units would be responsible for building an appropriately sized school for the children living there. Jefferson describes in great detail how an

This system, if imposed, would equip all Virginians with the necessary knowledge to be participatory citizens. They would possess the needed literacy for their own political and economic purposes. Two items are of particular interest. First was Jefferson’s intention to educate all girls, at least all White girls, at the initial level. Girls were restricted from advancing, however, because they would have received the necessary education to carry out house- hold functions by the time they finished these primary or elemen- tary schools. Second was the role to be played by the state in paying for this system. State monies entirely paid for primary schools, as was the one 'best in genius and disposition' (Peterson, 1984, p. 373) who would emerge from the second level. Additionally the state could pay for those students who could not afford to pay for the second level. This system was designed to produce Jefferson’s aristocracy of intelligence and if passed would be, as he told his old friend and mentor George Wythe, “by far the most important bill in our whole code” (p. 859). Of course, what

Jefferson’s vision for a system of public schools in Virginia reflected this thinking. Indeed, paying for the education of those of the lower socioeconomic classes with state monies seems emblematic of this leveling effect. Jefferson’s plan for educating citizens can be seen in this light as belonging in the same category as his attacks on primogeniture and other relics of aristocracy in the United States. Again, from this perspective, he was seeking to build a new aristocracy of talent to replace that of the privilege of birth. In this sense it is understandable how many indeed most have credited Jefferson as being an early proponent of what we would view today as an appropriate function of public schools.

Jefferson can be seen as a founding father of democratic education in the United States. Schools paid for out of public treasuries, open to the children of all citizens (with gender-biased limitations and racial discriminations characteristic of the eighteenth and nineteenth centuries duly noted), merit-based incentives to afford higher educational opportunities for talented students, and a politically liberating curriculum are certainly traits of what we would call a democratic system today. But is this an accurate picture? Was Jefferson’s educational philosophy as democratic as many attribute it to be? To better answer these questions, it is best to situate Jefferson’s plans for education in Virginia in the context of the social and political realities of the founding era.

As we have seen, Jefferson’s vision for public education in Virginia contained elements that today we associate with education for a democracy: universality (at least for White boys and girls in the primary grades), funding from state tax monies, a publically supported university, and rewards for meritorious students. However, if we examine his plans and writings more closely, some contradictory ideas also emerge.

First, while valuing the people as guardians of personal liberty, Jefferson also saw a social hierarchy that precluded equality of status. Obviously his opinion of Blacks is evidence of this fact but so too is his opinion of women. While his plans for public education included White girls attending primary school, they did not allow for their attending any of the higher levels of education. Their need for education was much more confined. Admitting that the proper education for girls 'has never been a subject of systematic contem- plation for me,' Jefferson did concede that his own daughters needed enough education “to educate their own daughters, and even to direct the course for sons, should their fathers be lost, or incapable, or inattentive” (Peterson, 1984, p. 1411). Jefferson was being consistent with the mainstream thinking in post– Revolutionary War America. As Linda Kerber (1980) has noted, 'Even the most radical American men had not intended to make a revolution in the status of their wives and sisters' (p. 9). Their role within the family expanded to the extent that they were expected 'to raise the virtuous male citizens on whom the health of the Republic depended' (p. 10; see also, Norton, 1980, pp. 243–250). Good republican mothers would be able to guide the development of good republican children. Also, Jefferson clearly felt most women incapable, or at least unworthy, of political participation:

What I am arguing is that to apply modern democratic understandings to Jefferson’s views on education is to fall guilty to presentist interpretation. While his plans may have had elements of what we today would label democratic and for his time were radical (e.g., educating all children in the primary grades or paying for such schooling out of public monies), his goal was strictly a political one; namely, he saw education as the best means to preserve the infant republican system that had replaced the former monarchical one. Like others of the founding generation, Jefferson saw the need to address the paradigm shift from subject to citizen as a critical one. Republicanism was not inbred but rather required learning new skills, new responsibilities, and new roles. For example, the republican notion of virtue, both for the leaders and the led, needed to be instilled. According to Wood (1967), this meant citizens obeying the law 'for conscience sake, not for wrath’s' (p. 66). From this perspective, education had a narrow purpose: utility. 'To fail to shape education to the existing political and economic framework of society might imperil republicanism itself' (Boorstin, 1993, p. 223). Thus, the usefulness of educating the citizenry was political; it was to protect the experiment in republi- canism that Jefferson helped to create.

This is not to portray Jefferson as being antidemocratic. It is an attempt to more accurately contextualize his views on educating citizens in a republic. Freeing Jefferson from presentist views of his being a twentieth-century liberal democrat enable us to see him more accurately. By presenting his views in the context of his republicanism, we do not diminish his radicalism for his time as identified by people like Arendt (1963) and Mathews (1984). In the context of the eighteenth century, democracy was seen by most as a slippery slope that resulted in anarchy. Jefferson and a few others did embrace a limited amount of democracy as the best means to preserve the republic. Trusting the masses with political power was radical for that time. The magic potion to temper the potential intoxicating effects of that power was education. Education would enable Americans to assume their roles as republican citizens. They would be able to see through the propaganda espoused by politi- cians, and they would be able to exercise and defend their rights should their elected governments encroach upon them. However, the social and economic understandings of modern democratic theory that posits an egalitarian society were absent from Jefferson’s thinking. Modern scholars who use the term democratic in describing Jefferson’s educational plans have done a disservice to our ability to understand him. By reexamining his ideas, we are able to get a clearer and more accurate picture of Jefferson’s contributions to education and citizenship"

## [Great Awakening](https://www.history.com/topics/british-history/great-awakening) ##
"The Great Awakening was a religious revival that impacted the English colonies in America during the 1730s and 1740s. The movement came at a time when the idea of secular rationalism was being emphasized, and passion for religion had grown stale. Christian leaders often traveled from town to town, preaching about the gospel, emphasizing salvation from sins and promoting enthusiasm for Christianity. The result was a renewed dedication toward religion. Many historians believe the Great Awakening had a lasting impact on various Christian denominations and American culture at large."

"In the 1700s, a European philosophical movement known as the Enlightenment, or the Age of Reason, was making its way across the Atlantic Ocean to the American colonies. Enlightenment thinkers emphasized a scientific and logical view of the world, while downplaying religion.

In many ways, religion was becoming more formal and less personal during this time, which led to lower church attendance. Christians were feeling complacent with their methods of worship, and some were disillusioned with how wealth and rationalism were dominating culture. Many began to crave a return to religious piety.

Around this time, the 13 colonies were religiously divided. Most of New England belonged to congregational churches.


The Middle colonies were made up of Quakers, Anglicans, Lutherans, Baptists, Presbyterians, the Dutch Reformed and Congregational followers.

Southern colonies were mostly members of the Anglican Church, but there were also many Baptists, Presbyterians and Quakers.

The stage was set for a renewal of faith, and in the late 1720s, a revival began to take root as preachers altered their messages and reemphasized concepts of Calvinism. (Calvinism is a theology that was introduced by John Calvin in the 16th century that stressed the importance of scripture, faith, predestination and the grace of God.)"


"Most historians consider Jonathan Edwards, a Northampton Anglican minister, one of the chief fathers of the Great Awakening.

Edwards’ message centered on the idea that humans were sinners, God was an angry judge and individuals needed to ask for forgiveness. He also preached justification by faith alone.

In 1741, Edwards gave an infamous and emotional sermon, entitled “Sinners in the Hands of an Angry God.” News of the message spread quickly throughout the colonies.

Edwards was known for his passion and energy. He generally preached in his home parish, unlike other revival preachers who traveled throughout the colonies.

Edwards is credited for inspiring hundreds of conversions, which he documented in a book, 'Narratives of Surprising Conversions.'"


"George Whitefield, a minister from Britain, had a significant impact during the Great Awakening. Whitefield toured the colonies up and down the Atlantic coast, preaching his message. In one year, Whitefield covered 5,000 miles in America and preached more than 350 times.


His style was charismatic, theatrical and expressive. Whitefield would often shout the word of God and tremble during his sermons. People gathered by the thousands to hear him speak.

Whitefield preached to common people, slaves and Native Americans. No one was out of reach. Even Benjamin Franklin, a religious skeptic, was captivated by Whitefield’s sermons, and the two became friends.

Whitefield’s success convinced English colonists to join local churches and reenergized a once-waning Christian faith."


"Several other pastors and Christian leaders led the charge during the Great Awakening, including David Brainard, Samuel Davies, Theodore Frelinghuysen, Gilbert Tennent and others.

Although these leaders’ backgrounds differed, their messages served the same purpose: to awaken the Christian faith and return to a religion that was relevant to the people of the day."


"The Great Awakening brought various philosophies, ideas and doctrines to the forefront of Christian faith.

Some of the major themes included:

All people are born sinners
Sin without salvation will send a person to hell
All people can be saved if they confess their sins to God, seek forgiveness and accept God’s grace
All people can have a direct and emotional connection with God
Religion shouldn’t be formal and institutionalized, but rather casual and personal"


"Not everyone embraced the ideas of the Great Awakening. One of the leading voices of opposition was Charles Chauncy, a minister in Boston. Chauncy was especially critical of Whitefield’s preaching and instead supported a more traditional, formal style of religion.

By about 1742, debate over the Great Awakening had split the New England clergy and many colonists into two groups.

Preachers and followers who adopted the new ideas brought forth by the Great Awakening became known as 'new lights.' Those who embraced the old-fashioned, traditional church ways were called 'old lights.'"


"The Great Awakening came to an end sometime during the 1740s.

In the 1790s, another religious revival, which became known as the Second Great Awakening, began in New England. This movement is typically regarded as less emotionally charged than the First Great Awakening. It led to the founding of several colleges, seminaries and mission societies.

A Third Great Awakening was said to span from the late 1850s to the early 20th century. Some scholars, however, disagree that this movement was ever a significant event."

## [November 2015 - Rev. Robert Hunt and Virginia Beach](http://blog.releasingheaven.org/2016/01/november-2015-rev-robert-hunt-and-virginia-beach/)
"Covenant Root in Virginia – Rev. Robert Hunt

Back in October while planning a Thanksgiving getaway, I (Yvonne) felt a quickening about visiting Virginia Beach.  In 2007, eight years prior, having arrived early in Virginia Beach for a prophetic conference (for which I felt a similar unctioning to attend), I was getting ready to walk the beach with a friend when a pastor stopped to tell us about Rev. Robert Hunt (an Anglican minister who was commissioned under the Virginia Charter to evangelize the land that stretched from South Carolina to Maine and far to the west) and how close we were to the First Landing where Rev. Hunt, after first making the crew stay on board for three days of fasting and praying, planted a wooden cross on those shores and dedicated this nation to the Lord. In his prayers, Rev. Hunt decreed that the gospel would not only be preached in this new land but would also go out from those shores to all of the nations of the world."


"Appointed times and boundaries

2007 happened to be the 400-year anniversary of that prophetic act. And it was that weekend that I finally got Acts 17:26-27, 'and He made from one man every nation of mankind to live on all the face of the earth, having determined their appointed times and the boundaries of their habitation, that they would seek God, if perhaps they might grope for Him and find Him, though He is not far from each one of us.' Although my call would touch the nations, that weekend my heart turned towards America, knowing that God’s hand was on my ancestors and on this nation and that He had some purpose for bringing my family here even though we were first enslaved."


"Dry Bones

So once again by divine providence, I felt compelled to go to Virginia Beach in the wake of Robert Hunt’s bones having been discovered and now very recently identified  – how profound and what a much needed sign for this nation. I set my heart towards Virginia Beach and towards walking that First Landing Beach,  finding the spot where the cross was planted,  there repenting of our sin of falling away,  and then rededicating the nation to the Lord while asking Him to visit us again. I could almost hear Dutch Sheets’ voice resounding in my ear: it is the synergy of the ages – we need to step into the timeline of the old, old stories."


"Confirmation and Isaiah 22:22

I had planned to get re-fired before my departure to Virginia Beach as Dutch was speaking at Glory of Zion that weekend  at the Awakening Our Prophetic Destiny for the Future Conference but the communication lines in the region had been severed and I was unable to receive any live feed.  So I drove the six hours on Sunday and got settled in; it wasn’t until the early hours of Monday morning that I caught his message from Friday night. Dutch spoke of the keys of opening doors no man could shut and closing doors no man could open (Isaiah 22:22) and high level assignments of apostolic and prophetic intercession being given out to the ekklesia – “He’s going to send us on high level assignments.  He’s going to shift nations and governments in this season through apostolic intercession. Not just through apostles, but through apostolic and prophetic intercession. …this move of the Spirit that’s coming and the prayer movement that’s coming is not for the chosen few.  It’s for the available few. There are going to be people sent to palaces that nobody will ever know they’ve been there and it will shift the government over a nation”; and then Chuck prophesied about a shift happening going back to the covenantal roots in Virginia."


"Apostolic and Prophetic Decrees

My, my. I knew that I was in the right place at the right time and I knew what I needed to do – make decrees based on Isaiah 22:22 and somehow plant a key when I went to the cross that Friday. So on Friday, I rose early and went through the checkpoint at Fort Story and spent an hour in worship and prayer and completed my assignment.

At the cross
'In this year of Ayin Vav and at the beginnings of the 2nd phase of the Third Great Awakening, I stand at the foot of the cross that is a granite replica of the one planted by Robert Hunt on 29 April 1607, where he dedicated this nation to the Lord Jesus Christ and to the preaching of the gospel to all inhabitants here and also to all nations, and with the prophetic sign of the recent identification of his bones, I stake that original covenant to the current & future destiny of our nation and I rededicate the United States of America to the Lord Jesus Christ and to the purposes of preaching the gospel and advancing His Kingdom (Isaiah 22:22)'"


"There’s power in the bones!

It was not until almost a week later that I heard Dutch’s Saturday message which talked about Robert Hunt’s bones!  Holy Spirit is speaking. I can tell you that something shifted in my spirit while “on assignment” in Virginia Beach – I feel Holy-Spirit-fire in my bones once again! And I feel the resonance of the roar of the Lion of the Tribe of Judah through my core – and there is a  listening, watching and waiting for more assignments.

Excerpt of Saturday morning service –  GZI’s 'Awakening Our Prophetic Destiny' Conference

James sings: Some of us thought we had seen the finalization of some things. Some of us saw even death and destruction and we thought it was over. We thought whatever prayers and whatever we had released had been finalized and perhaps the answer that happened was not the answer we were looking for. And that it was over. But just as the man was thrown onto the bones of Elisha and he was raised up from the dead, the Lord says the power of those prayers, the power of your answer is still within me. And although it seems a door had shut, the open door is in me. The answer is in me. And you will see it come around in another way. …The time has come back around. Life is coming round again. There’s power in the bones. There’s still power in the bones. There’s still power in the bones. The time is now. The time is now. The time is now. The time is now. The time is now. There’s power in the prayers, there’s power in the bones, the time is now. There’s power in the prayers, there’s power in the bones, the time is now.

Chuck: This is a word from the Lord. There’s power in the bones – it is where the word of God dwells. … The word of God is quick and powerful, sharper than any two-edged sword, piercing, dividing soul and spirit going even down into your bone marrow.

Dutch:… As I went back through the history of awakening – what are the verses important to us. What should we agree with? What do you want me to grab? I’ve studied our history. Let me tell you what I think God’s purpose for America is. 1607 they planted a cross and dedicated this land to the glory of God. They found 4 skeletons at Jamestown – one is Robert Hunt’s skeleton. Don’t miss that – in this season, it is a sign to us.

At the scent of water!

Job 14: 7-9

7 'For there is hope for a tree, 
When it is cut down, that it will sprout again, 
And its shoots will not fail.
8 “Though its roots grow old in the ground
And its stump dies in the dry soil,
9 At the scent of water it will flourish
And put forth sprigs like a plant.'"


----------


# Church Architecture and the Medieval Age #
## [American Christian Science Architecture and its Influence](https://www.marybakereddylibrary.org/research/american-christian-science-architecture-and-its-influence/) ##
"Building Respectability: Christian Science Architecture in the U. S. A. and its Influence in Europe

Christian Science, a new American religion based largely in both Puritan and Transcendental strains of theology, was formulated by New Englander Mary Baker Eddy and organized as a denomination in the 1880s and 1890s, based on her discovery of a radical method of Christian healing found through a spiritual interpretation of the Bible—a science of Christianity.

In 1875 in Lynn, Massachusetts, Eddy published the complete statement of this methodology in her book Science and Health. Through founding a church organized to reinstate primitive Christianity with its lost element of healing (1879, reformed 1892), and the Massachusetts Metaphysical College (1881-1889), her ideas began to be disseminated across the United States and by the 1890s in Europe. The organization grew rapidly and began attracting popular and critical attention in the secular as well as religious and medical press. In 1895 there were about 250 organizations, and by 1910 there were approximately 1100 congregations attached to the Mother Church in Boston.

In late 1894 the Mother Church of Christian Science was built in Boston. It was a Romanesque edifice built by Eddy as founder, and was similar to more traditional churches dotting the New England townscape. It was filled with symbolic stained-glass windows, many with women as their subject. A symbolic “Window of the Open Book” representing the City Foursquare from the Revelation of John dominated the program. By 1906, a massive extension of the Mother Church was built abutting the original church, in a grand renaissance classical revival style decorated with floral garlands and textual quotations from the Bible and Eddy on its massive walls (Fig. 1). This revealed a shift from the earlier more traditional figural symbolism and positioned architectural style and the Word itself as symbols for the new religion. The style of the immense church fit in with the more classicizing civic architectures defended by architects persuaded by the ideals of the City Beautiful movement, Swedenborgian Daniel Burnham’s civic reform movement that suggested that pure, rational architectural forms could reform not only the city’s physical fabric, but produce upright, efficient and moral citizens.

Architecture became the chief visible proclamation of Christian Science’s presence in American cities and towns, and also in Europe, where it grew rapidly in Great Britain and Germany after the 1890s. While early architectural ornaments and symbols in Christian Science churches were often taken from the traditional Christian iconography familiar to new Protestant converts to Christian Science, their more popular explanations were given metaphysical interpretations through the teachings of Christian Science. The dove, lambs and birds, as well as the seven-pronged candlestick that were carved in the Reader’s desks and decorative screen in Ramsey Traquair’s First Church, Edinburgh (1910) (Fig. 2), for example, were likely interpreted through their spiritual interpretations found in Eddy’s writings.

Increasingly, however, most Christian Scientists turned directly to the Bible and Eddy’s writings for inspiration: the Word became their sacred decorations or declarations on the walls of their auditoriums. The words from the Psalmist, “He sent his word, and healed them (107: 20)” was taken quite literally by Christian Scientists. After all, Christian Science services consisted of lay Readers reading passages from a Lesson-Sermon: passages from the Bible with correlative readings from Science and Health that were believed to be divinely inspired. Bible texts and citations from Eddy’s writings were so commonly displayed on the walls, that she finally restrained their use.

In the early 20th century, Christian Scientists began to practice a typically Protestant belief that had begun to fall out of favor with mainline Protestant churches, who were increasing their use of symbolic accessories: that figuration and even conventional symbols took away from the abstract and direct influence of thinking through the unmediated sacred Word. The Word, essentially, was viewed as a spiritual declarative medium, bringing into mental view spiritual ideas and substance. Eddy herself employed Christian symbols and metaphors in her writings. She wrote that, “Spiritual teaching must always be by symbols.” She preferred what one church official called “churchy church[es]” with “something pointing upward,” similar to her Mother Church and the one she donated to the citizens of Concord, New Hampshire in 1904, both of which had figurative windows with symbols. Nevertheless, the impersonality and unmediated quality of the Word trumped any consistent symbolization, other than the Cross and Crown registered trademark on the covers of Science and Health.

Christian Science congregations generally eschewed any overt ecclesiastical symbolism by the 1920s, though stained glass windows, restrained ornamentation and even seven-pronged candlesticks and stars often had symbolic themes. Several churches used the seven-pointed star as a decorative symbol for Eddy’s seven synonyms for God from Science and Health: “. . .Principle; Mind; Soul; Spirit; Life; Truth; Love. . .” Certainly the “Glossary” in Science and Health underscored metaphysical definitions for scriptural words in the spirit of Swedenborg, suggesting many new possibilities for Christian Science symbolic representation. Sir Herbert Baker wrote that the building committee of Ninth Church, London (1928-30), after he completed the monumental 100 foot diameter auditorium for them, wouldn’t allow him to decorate save with a few sacred inscriptions: “the principles of the community were as antipathetic as those of Mohammedans to any representation of the works of the Divine Creator; nothing could be expressed but the inspired word.”

In many ways, architecture itself became the primary symbol. When building their own churches, Christian Scientists looked to the Boston edifices as examples of appropriate architecture, though the Mother Church never had an official opinion on architecture. By 1907, debates about the appropriateness of the simplified classical revival style emerged in popular periodicals concerning the religion’s self-representation. Should Christian Science be associated with the timeless classicism of the past associated with primitive Christianity or with the more romantic Gothic style associated with historical and ecclesiastical Christianity?
Central to these debates was Solon Spencer Beman, who became the chief theorist of Christian Science architecture, whose classical revival churches were being built across the United States. By 1907, Beman had joined the Christian Science church and defended the classical style for which he was gaining popularity. To Beman, Christian Science represented a rational approach to spirituality, classicism oriented the denomination with the time of primitive Christianity, and the predominance of the classical in Christian Science commissions indicated that the church was progressive. Gothic architecture represented the past and the “ritualisms and [emotional ceremonies of the Orthodox Church].” When asked to help with the building of the Extension of the Mother Church, Beman minimized references to the mystical in favor of the rational: the Mosque of Ahmed I had been an eastern prototype for the edifice. Other American architects, such as Elmer Grey and William Purcell, believed that Christian Science architecture should rest on the democratic and local traditions of the individual congregations, and reflect the site-specificity and honest originality being supported by architects such as Louis Sullivan. Grey also felt that Christian Science should not “exclude from its architecture anything worthy in the Christian architecture of the past.”

In many ways, the Columbian Exposition’s World’s Parliament of Religions that launched Christian Science into the public limelight, unlocked the silent and generally unfamiliar symbolism of eastern mysticism within the rational architecture of the White City. The classical style could be interpreted as the rational outgrowth of a Christian primitivism but it was equally associated with esoteric or specialized knowledge practiced by groups such as the Masons. Masonic interpretations of the Ionic column favored in many Christian Science commissions, for example, would suggest that they represented wisdom. While a penchant for Masonic symbolism was found in the decorative programs for several Christian Science churches, it is doubtful, even with Mrs. Eddy’s understanding and appreciation of Masonic symbolism, that most Christian Scientists discussed these interpretations openly. Most importantly to them, classical Christian Science architecture associated the religion and its adherents with a range of monumental buildings devoted to governmental, legal, and administrative functions, and many churches were sited close to new developing civic centers in an attempt to make them a legitimate part of future religious as well as architectural development.

While classical revival edifices made up the majority of church commissions in the United States between 1897 and 1925, the most architecturally celebrated Christian Science edifice was inspired by traditional Gothic architecture. It was designed by Bernard Maybeck, who modernized the style in his well-known Christian Science church in Berkeley, designed in 1910 (Fig. 3). Its poured concrete foundations and pillars with biblical narrative capitals, fir and redwood beams and trusses, medieval-looking glass placed in factory sashes, and painted stenciled decorations, expressed the unity, harmony, sincerity and honesty requested by the congregation’s building committee.

In Britain, likewise, First Church, Manchester England, a striking expressionist Arts and Crafts design by Edgar Wood, was one of the most celebrated churches in Britain of any denomination, like the Maybeck church (Fig. 4).20 In 1903 the congregation hired Mr. Edgar Wood to be their architect, finding his work to be “most artistic and of a somewhat original character.” The church would be built in sections, and Lady Victoria Murray laid the cornerstone May 30, 1903. The stone was of Concord granite, from Eddy’s home state. This marked a new tradition: the cornerstones of British edifices, whenever possible, would be of New Hampshire granite. The façade presented a steep gable with a clear window shaped like a cross. The first section of the building was completed in April 1904, making it the first edifice erected for the purpose of a Christian Science church in England. The interior of the church was decorated with bronzed lettering for quotations on the walls, an Arabic organ screen, and beautifully carved chairs and Reader’s desks, the latter with doves descending, symbolizing divine Science. On the screen behind the readers was a symbolic cross, surmounted by a crown. A newspaper described the church as “one of the most strikingly original examples of architecture to be found, comprising a curious blending of ancient and modern, European and Eastern.” Mrs. Eddy wrote to Murray that the “the architecture of your church is indeed suggestive and sweet.” The congregation replied to her, writing that “the building of this church has called forth spiritual qualities,—the sacrifice of material sense and self, and a greater sense of the unity of brotherhood,—all of which we know you will treasure more than any material structure.” The entire edifice was completed and dedicated in 1908. With its wings the shape of the church was like the inverted letter Y, said by a local newspaper to be symbolic “of the outstretched hands of love.”

In Europe, the desire for respectability held sway. The church was growing rapidly and being openly criticized by both the clergy and the medical establishment as a new upstart American church, and represented what one newspaper called the “New World message.” By 1900, five congregations had organized in Hannover, Dresden, London, Edinburgh and Paris.27 In April 1903 Eddy founded Der Christian Science Herold. By 1910, there were over 55 congregations organized in English speaking countries, five in Germany, two in Holland and two in Switzerland, with smaller groups in Scandinavia and Italy. Growth remained dramatic in both English and German speaking countries over the next 20 years. In 1925 there were  congregations in Germany and nearly 150 churches and societies in Great Britain.
Christian Science churches built in Britain demonstrated a significant move towards the adoption of the American auditorium church plan or lecture hall, with congregants gathered around the dual pulpit used by lay Readers who perform church services. Architects focused on the need for excellent acoustics and commented on the American source of the auditorium church. Facades were characteristically non-religious, even somewhat eastern, but always respectable.

Christian Science came to Britain in 1890. Mrs. Eddy sent students to London, where fashionable West End women began to be attracted to it. By 1897, three years after the completion of the original Mother Church, the London congregation moved into an old Spanish Portuguese Jewish Synagogue. The members soon hired R. F. Chisholm to design them a new church edifice. Chisholm, having worked in eastern architectural idioms in India, provided them with what would have been a completely original Christian Science edifice (Fig. 5). A more traditional plan was asked for, and Chisholm provided them with a more traditional design, but one with some eastern elements and seven coupled windows across the façade (Fig. 6).

In 1904 the congregation laid their New Hampshire granite cornerstone. An architectural critic called the church an “Indian Reminiscence in Chelsea” and suggested that “one would not be surprised to see a Muezzin call the faithful to prayer” from the tower’s “lofty outlook.” He also told his readers that the “decorative details. . . are of an Anglo-Norman type well suited to the monumental character of the design” but, because it was a religion from America, “its projectors were under the influence of [Henry Hobson] Richardson, that architect who has invested American architecture with proportions almost Cyclopean.”31 The Architect and Contract Reporter thought differently: “The particular style of architecture for a Christian Science church should present no difficulties. The very early churches were mostly pagan temples converted into churches; when constructed as churches they exhibited many Eastern features,” implying that Christian Science was returning to the time of primitive Christianity, where both classical and Byzantine designs were historically located.

By 1907, the Christian Scientists had grown in influence enough to interest over 9000 people to attend a Christian Science lecture delivered by American Bicknell Young in London’s Albert Hall. The idea that the acoustically perfected lecture hall or theater provided the best vehicle for Christian Science churches in Britain was henceforth continually suggested in the architectural press and demonstrated in several branch church designs: Byzantine styled Second Church by Sir John Burnett (1924-25); Lanchester and Rickard’s monumental Baroque Third Church (1910) in Mayfair, which included a lamp of wisdom in its elaborate entry cartouche surmounted by a tower of Wren derivation (Fig. 7); Paul Phipps’ modern Georgian Seventh Church (1926-29); and Oswald P. Milne’s simplified Georgian Eleventh Church (1925-27).33

One of the most prominent Christian Science commissions in Europe was First Church, The Hague (Fig. 8). By 1906, a group of Christian Scientists organized as a church in The Hague.34 By early 1920, the congregation was ready to build an edifice and by 1922, the church employed the internationally recognized “Amsterdam School” architect Hendrik Berlage to provide them with a church. Berlage represented a bridge between historical Dutch architecture and decoration, and the new Modern architecture then emerging in the United States and Europe, with its emphasis on structure and function in architecture. His First Church of Christ, Scientist in The Hague, designed and erected between 1924-1926, was built as a new architectural idea for a group that Berlage believed were rational and democratic thinkers representing a new American religion in his native Holland.

Berlage turned to examples of American church architecture, particularly Sullivan’s St Paul’s Methodist Episcopal Church in Cedar Rapids, Iowa (1910-1912) that he had visited on his 1911 tour of the United States, accompanied by architect and soon-to-be a Christian Scientist William Gray Purcell. He was particularly impressed that the church differed from traditional ecclesiastical architecture (that clung to the old forms of the Catholic church) in its emphasis on gathering the congregation in an “ideal community hall where everyone can see and hear the minister from every seat.” Sullivan created an “interior of his church [in] the form of a half circle and placed the tower above . . .[giving it] a higher ethical significance.”

Purcell corresponded with Berlage about Christian Science in May 1918: “I think you will be interested to know that in America the new spirit has touched religion and produced a faith expressing itself with the simplicity of primitive Christianity but taking full account of modern intellectual equipment and world machinery. . . I connected myself with this body of spiritual workers shortly after I saw you last. . . I believe you would be interested in the type of citizens who are found associated with this movement, which is so essentially democratic in the broadest application of that word.” Purcell, who had worked with Louis Sullivan, was concerned with the proliferation of classical revival designs and expressed his strong commitment to modern non-historical principles in his 1926 Third Church of Christ, Scientist, Portland, which echoed a plan for a system of units to be built over time that he had recently addressed in an article in the Christian Science Monitor.38 He and Berlage subsequently shared plans.

By 1922 Berlage had been invited to submit a design by the congregation. He was given a copy of Science and Health for his use during the design of the edifice. He apparently “found the concepts of man’s perfection appealing.” As one member put it, Berlage sought “by means of the construction of our church, to give figure to the ideal (of Science and Health)—the evolution of man towards perfection.”42 And certainly it was a challenge for him to create a church for a group that represented a new spirit in religion.

Berlage was asked to design a church to seat 700, with a Sunday School for 200 pupils, and a caretaker’s apartment. Het Haagsche Volk reported that the new church “consists of a combination of buildings. The church itself is placed on slightly rising ground. . . The walls of the church auditorium are quite plan. The rows of benches face the raised platform with its two readers’ desks.” The final church complex was made up of an assemblage of distinct geometric masses of different sizes and heights that legibly combined triangles and squares throughout the design. Each mass was clearly delineated for a specific function, making this one of Berlage’s most modern buildings. The Christian Science Monitor reported that this first Christian Science church in Holland would be one of the “chief modern architectural monuments of the Netherlands.”

Berlage’s design followed Sullivan’s Cedar Rapid’s church, particularly with the tower placed at the apex of worship, soaring up above the Readers’ platform, and with seats for the congregants radiating out on a sloped floor, though not in as strict a semi-circle as Sullivan’s church. Architectural historian Leonard K. Eaton wondered if Berlage was simply “subconsciously reverting to the strong tradition of Dutch Protestantism as an amphitheater for preaching”47 but Het Haagsche Volk reported that the church, though unusual, “complies in every respect with the instructions received by the architect.”

As architect H. Paul Rovinelli aptly put it, “The form of the church, in a more highly abstract and intellectualized manner, arose out of the delineation of the function, overlaid with a numerical and ornamental program drawn from Christian Science texts.”49 On the stairs to the auditorium was a quotation from the Revelation of John greeting the congregation as it entered into the services.50 Above the quotation was a ceiling mosaic of a lamb, not unlike those found in some British churches. In the auditorium, quotations from the Bible and Eddy were also present on the walls. On the ceiling was a skylight with a ten-pointed star. Architectural historian Sergio Polano suggested that in this church Berlage (together with De Stijl designer Piet Zwart) proved the mastery of “Dutch decorative geometricism.”

Berlage had attempted a more traditional ornament of a cross and crown motif for the ceiling, and, though there were many examples to the contrary in branch churches throughout the United States and Europe, was told that Mrs. Eddy would have disapproved. Rovinelli states that nonetheless Berlage’s design was more subtle in its symbolism as it was based on “the use of numbers with symbolic significance in the Bible or Mrs. Eddy’s Science and Health: three, five, seven, ten, twelve, and forty.” The numerological significance of many of Berlage’s choices went un-acknowledged by the congregants, the esotericism of theosophy had been thoroughly attacked by Eddy in Science and Health, although by 1938 a numerological interpretation of Christian Science was being vetted by London Christian Science teacher John W. Doorly and his Zurich follower Dr. Max Kappeler. Berlage’s own interest in proportioning systems was strongly influenced by his theosophical colleagues.

In the plain unornamented interior, orange, green and lilac glass blocks in horizontal and vertical bands in the auditorium created diffused lighting throughout the space, punctuated by the skylight. Berlage himself had suggested that “light from above was associated with the divine” and Purcell had advised Berlage “to flood the church with daylight, and with artificial light, as this religion stands for enlightenment as opposed to the dusky mysticism of the old theology.” The overall effect produced a “cool, restful character very much in keeping with the quiet nature of the Christian Science ritual.”

Eaton noted that the Hague church was “the most striking evidence of the impact that Sullivan had on Berlage.” Other scholars have recognized multiple references to Wright’s Unity Temple, from skylights, to lamps and pulpit. To many the church “stands as a significant work illustrating the complex relationship between Berlage, Wright and rationalism.”59 Nevertheless, as the Het Haagsche Volk told its readers, the “building reminds one hardly in any respect of the traditional church edifice,” but “great satisfaction has been felt as the result of this experiment.”

Certainly to the members of the European Christian Science congregations, even to those who experimented with more modernist designs, these church edifices reflected, whether with decorative symbols, quotations, or modern materials, the true definition of Church given to them in Science and Health: “The structure of Truth and Love; whatever rests upon and proceeds from divine Principle. The Church is that institution, which affords proof of its utility and is found elevating the race, rousing the dormant understanding from material beliefs to the apprehension of spiritual ideas and the demonstration of divine Science, thereby casting out devils, or error, and healing the sick. “ As the members of the Hague church put it at the ceremony laying the cornerstone to their edifice: “This Church, ‘First Church of Christ, Scientist’, the first Christian Science temple in Holland, a symbol in stone of the spiritual building “The structure of Truth and Love,” is erected to the glory of God and in gratitude to Mary Baker Eddy, Discoverer and Founder of Christian Science.”

## [Religious Freedom and Architecture](https://www.backstoryradio.org/blog/a-chapel-on-mr-jeffersons-grounds/) ##
"Unlike all other nineteenth century institutions of higher education—like Harvard, William & Mary, and Yale—the University of Virginia was founded without a designated religious affiliation. Although Thomas Jefferson envisioned an academic village in which students enjoyed religious freedom, UVA was not a truly secular institution. According to UVA professor, Alan Taylor, 'He [Thomas Jefferson] did not want any one denomination to obtain ascendency or even for several to contest for primacy.' Rather, UVA was truly trans-denominational, not non-religious, and the establishment of the University chapel exemplified Jefferson’s vision of free worship on campus. From the words of Jefferson himself:

In conformity with the principles of our constitution which places all sects of religion on an equal footing – with the jealousies of the different sects in guarding that equality from encroachment and surprise, and with the sentiments of the legislature in favor of freedom of religion manifested on former occasions [as in the Virginia Statute for Religious Freedom] – we have proposed no Professor of Divinity.'

Despite the absence of a Professor of Divinity, religious services were held every Sunday. Alexander G. 'Sandy' Gilliam Jr, University Protocol and History Officer, claims 'Jefferson decreed that religious services be held on Sundays, the difference in UVA was that attendance wasn’t required.' The very epicenter of Jefferson’s academic village—The Rotunda—could accommodate religious worship. According to UVA’s meeting minutes of Oct. 4, 1824, 'One of it’s [the Rotunda] large elliptical rooms on it’s middle floor shall be used for annual examinations, for lectures to such schools as are too numerous for their ordinary schoolrooms, and for religious worship, under the regulations allowed to be prescribed by law.' Jefferson served as UVA’s rector during this period of time. 

When the wave of the Second Great Awakening—a religious revival of the 1840s—rippled through Virginia, attention was drawn to the lack of a chapel at UVA. Astounded and outraged by this unfortunate deficiency, an organization comprised of faculty wives initiated the process by raising funds and drawing plans for UVA’s chapel. According to Gilliam, the original plans 'stuck' the chapel '…in the middle of the lawn about half way down.' Obviously, these plans changed.

Though the Civil War prolonged construction and jeopardized the funds, Gilliam said the cornerstone of UVA’s Chapel was laid in 1885 under the supervision of Chaplin Otis Glazebrook. Construction was slow, but the Chapel was completed approximately ten years later.

The architectural style of the Chapel stands out against the Jeffersonian style seen throughout Grounds.  According to Gilliam, the Chapel’s gothic style is indicative of the architectural tastes of the mid-1800s. While the Greek Revivalist architecture was considered vaguely Pagan, Gothic architecture was the preferred style for churches.

Gilliam noted that the last University Chaplin died in 1895, the same year the UVA Chapel started withdrawing from religious affiliation. The many outside preachers who commuted to hold services in the structure eventually stopped as well.

Today, the Chapel is regularly used for a variety of things including weddings, funerals and student organization events. High in demand, the University of Virginia Chapel continues to uphold Jefferson’s vision of a unique academic village. When asked whether the chapel coincides with Jefferson’s beliefs regarding religious freedom, Jamal Millner, CLAS ‘93 alumnus responded, 'From my understanding of Jefferson as an individual, no. But as a statesmen, yes, the chapel was an interdenominational space that supported ideals of religious freedom.'

Some may deem the chapel a divergence from Jefferson’s ideals and intentions for the academic village of UVA, pointing to its past limitation to Protestant religions and even its gothic architecture. University of Virginia Professor, Emeritus, and Historical scholar, Peter Onuf points out in a Coursera lecture 'the architecture, the sensibility, the taste itself would be revolting to Jefferson.” Considering the location of the chapel, positioned beside the Rotunda, Onuf goes on, 'Jefferson would say, as he turns over in his grave, ‘Oh my God.’”

Despite opposing positions, this hallmark of University Grounds sustains the Jeffersonian model and advances our capacity for religious freedoms."

"'The relations which exist between man and his Maker – and the duties resulting from those relations – are the most interesting and important to every human being and the most incumbent on his study and investigation.'" ~ Thomas Jefferson

* Prayers in Stone: Christian Science Architecture in the United States, 1894-1930 (University of Illinois Press, 1999) 
* Faith in the Market: Religion and the Rise of Urban Commercial Culture (Rutgers University Press, 2002)

## [The Organ in the Medieval Ages](https://organhistoricalsociety.org/OrganHistory/history/hist002.htm) ##
"After the fall of Rome and the subsequent loss of the organ in western Europe, the organ continued to be used in the Eastern Empire. The re-introduction of the organ to western Europe occurred in 757, when an instrument arrived in the Court of Pepin the Short (father of Charlemagne) from Byzantium. Other references to gifts of instruments that included organs are found in the following century, and enough reports survive to make it a safe assumption that, indeed, the organ was after the ninth century a part of the cultural life of western Europe. Although that much can be assumed, we don't really know any reliable details about the organ itself or how it was used in the early years of the Middle Ages.

During the Middle Ages, the organ in western Europe developed into three different types of instrument. In looking back at the organ of that period, we generally distinguish the three types from one another on the basis of one or both of these elements:

Physical characteristics (chiefly size)
Musical function

It is the nature of the instrument, of course, that its physical characteristics have a direct effect on its musical uses. We wouldn't use a small instrument with two stops on one manual - - and no pedal division at all - - to lead congregational singing in a church that seats two thousand people. The relationship between the physical nature of the organ and its music is especially strong in organs of the Middle Ages - - even more so then, because they used the organ in a greater variety of ways than we do today.

Although surviving information is particularly weak for the early part of the period, we can draw informed conclusions about both the appearance and use of each type of instrument from the later Middle Ages. We have no surviving instruments from the Middle Ages, although there are some instruments that supposedly incorporate parts of medieval instruments. It is regrettable that before the fourteenth century, we don't even have any surviving keyboard music, because knowing the literature might make it possible for us to fill in some gaps that exist in our knowledge of medieval organs. Even with all that we don't know, with the evidence that does survive - - both written descriptions and iconography, we can make some statements about the instrument and believe we are speaking the truth, even at the distance of some one thousand years.

The Portative Organ

The smallest of the medieval organs was the Portative. Its name comes from from the Latin verb portare/to carry, and it is called that because it was small enough to be carried easily. The typical portative organ seems to have had

a single manual with less than two octaves range.
only one or two ranks of pipes.
a bellows attached to the back of the instrument, so that while one hand played, the other supplied the wind by operating the bellows.
You can see portative organs in many manuscript illustrations and paintings of the twelfth through the fifteenth centuries. Some of the most well-known examples are have been reproduced in music history textbooks, and copies are readily available there. Boethius DE MUSICA manuscriptThe manuscript illumination to the right is from the fifteenth century. It shows a personification of Musica in the center - - playing a portative organ. This use of the portative - - to symbolize music itself - - is actually fairly common in these paintings. In this case, the portative organ is an example of what art historians call an "object attribute." That means that the portative is used as a type of symbol, and that a figure of a woman holding a portative is meant to be "Musica." To look at it another way, we know that this picture represents "Music" because the woman is holding a portative organ, not a sword or a feather boa. The figure at the top of the page is another example of an object attribute; the psaltery in his hand means that he is King David.85 This use of the portative organ in manuscript illuminations and other paintings is one that is common in late medieval representations of classical concepts, and it indicates a high regard for the instrument.

Another use of the portative as a symbol is more generic, because "portraits" of musicians often show the person in question playing a portative organ. In other words, a portative organ might indicate that the person represented is a musician in the general sense, not that the person shown is the veritable personification of all music. For most music students, the illustration of this type that they find most often is a page seen at the left, which contains the score to a famous work ("Musica son," or "I am Music") by Francesco Landini, the most notable Italian composer of the fourteenth century. In this and many other manuscript illuminations that show composers of secular songs of the Middle Ages, the portative organ provides an immediate visual clue: this person is a musician. Many of these manuscripts do not have the visual clue seen here in the musical notation.87 The use of a portative organ in an illumination is also seen in manuscripts without musical notation.

A final symbolic use of the portative organ is seen in painting of "angel consorts," most of them dating from the fifteenth and sixteenth centuries. The figure used in the header of this page is reproduced to the right. This is a miniature painting by Hans Memling that is found on the reliquary of St. Ursula. Many other paintings also show an angel playing a portative organ, either as individual figures or as members of a musical ensemble of angels - - an "angel consort."

From surviving descriptions and images of the portative organ, it is possible to draw several conclusions about the instrument and its use. These are generally accepted as valid statements about the portative organ:

It played a single melodic line only.
In the early Middle Ages, it was associated with secular music.
It was used to accompany singing, probably playing an ornamented version of the vocal line.
It was used also in ensembles, where it either played an independent line in polyphonic textures or doubled other instruments.
In the late Middle Ages and early Renaissance, it was associated with angel consorts and courtly figures.
By the end of the Middle Ages, the portative organ no longer held an important place in the performance of secular music, and it is doubtful that it was used with any frequency at all. By the end of the sixteenth century, it had become largely a memory, and its use had faded with much of the music of the Middle Ages.

The Positive Organ

The Positive organ of the Middle Ages was a larger instrument than the portative. From the surviving evidence, we can safely assume that a positive organ at the end of the Middle Ages

typically had one manual and no pedal.
had a compass and keyboard that allowed the performer to use both hands, so that he or she could play polyphonic music.
had more than one rank of pipes, and stops to control which one(s) sounded.
required a second person to operate the bellows.
was built either as a free-standing instrument or as one that could be placed on top of a stand or a table.
could be moved, but not so easily that it could be considered "portable."
The positive organ appears to have had two primary uses:

The positive was used in the performance of secular music, and thus may be considered to have been a secular chamber instrument, at least in part. The earliest preserved keyboard music, from c. 1325 AD, consists of secular pieces (three dances and three intabulations), and the degree of sophistication found in them indicates a thriving keyboard practice as early as the fourteenth century.
The positive - - under several different names - - is associated with the church in the form of instruments placed at the front of the nave and used to accompany the singing of the choir. Descendents of organs of this type are found in many European churches today.
Unlike the portative organ, which faded from use without leaving a substantive legacy in the form of literature or an impact on later instruments, the positive organ of the Middle Ages provided the workplace for at least one development that became a standard element of the organ: a chest mechanism that allowed the use of different stops. By the middle of the fifteenth century, such stop controls were typical of positive organs and were in fact being found on some larger organs in churches.

Because some form of the positive remained in use after the fifteenth century, there is more information available about it than about the portative organ. Representations of positive organs can be found in manuscript illuminations, painting, stained glass, and other forms of visual representation.83 Furthermore, the evolution of the instrument provides a line of continuity to surviving instruments that is not found in the history of the portative.

The illustration to the right is a reproduction of a woodcut by Israel van Meckenem, an artist active in the last quarter of the fifteenth century. Several things can be seen in this print:

The background indicates a residence, so the organ is being played in a home, not a church.

The instrument is placed on a table, and the player is shown using both hands to play the keys.

Behind the pipes, a second person (the organist's wife) is operating the two bellows. In an arrangement like this one, the upper portion of one of the bellows is raised, and as it falls, it sends wind to the chest. A weight attached to the bellows provides the correct amount of pressure, so it both provides the wind and controls its pressure. While the first one is deflating, the second bellows is raised; the first bellows is then raised as the second falls, and the cycle continues as long as the positive is being played.

The four small shapes on the side of the pipe support, at a level between the hands of the organist and the bellows, could be merely decorations. On the other hand, it is possible that they are the ends of sliders, in which case they indicate that the positive has four stops.

The organ in the photograph to the left is an Italian instrument of the late seventeenth century. Organs similar to this one, which has one manual and six stops, represent the other common type of positive organ.

It is a church instrument.
It is a free-standing instrument with a small pedalboard. The pedals which pull down the lower keys of the manual by means of the fabric ties which are visible in the photograph.
The extension at the base of the rear of the case houses two bellows, which function as the ones in the woodcut above.
There is a stop mechanism, whose controls can be seen to the right of the manual keyboard.

The Church Organ

The organ in the medieval church presents something of a puzzle, first of all through its very association with the western European church. The church had taken a dim view of the organ, and it was not a part of Christian worship from the early years until some time during the tenth century, and then not in the Eastern Church but only in the West.93 Just how the organ came to be not only an accepted but a respected part of the church in the West is a question that does not have a clear answer. Perhaps the best explanation is that as a part of the Carolingian Renaissance, the instrument was a useful tool for both ecclesiastical and political purposes. Certainly the medieval organ produced the lowest-pitched and most powerful musical sounds of the period. The thought that it could have been used to impress the faithful with its power (found only in the church) and to reflect the glory of the ruler (who provided the means of obtaining such a wonder) is not without some basis, but it is not a point that is likely to be proved or disproved.

For the present, it is important to realize that regardless of the decisions by church and court that placed it there, the organ became associated with the church during the Middle Ages. Descriptions of the organ in churches date from the tenth century and later. There it went through a process of development that ultimately is responsible for all the great instruments that have appeared since that time. Without the encouragement of the church, it is probable that the organ would never have developed beyond the scope seen in the positive organs of the Middle Ages and Renaissance.

By the end of the Middle Ages, very large organs were being built in both abbey churches and cathedrals, and the organ appears to have been an expected part of any such new building. These instruments are most often referred to now as Blockwerk organs, and the term is used to denote a large instrument permanently installed in a church, with multiple pipes (perhaps more than 50) for each key, but no stop mechanism present to give the player control over how many pipes were to be sounded. The most detailed information we have about the late medieval Blockwerk organ comes from two sources:

The treatise of Henri Arnaut de Zwolle (c. 1440) Praetorius' Syntagma Musicum, volume two, 1619.

In both cases, however, the authors were describing instruments of an earlier time. They knew the instruments -- or knew of them, but they recognized them as "old-fashioned" for their times. From their descriptions of this type of instrument, and from scattered builders notes and contracts that have survived, we can state that in general the Blockwerk organ had windlines that connected to multiple bellows was essentially a large mixture, with multiple pipes for each note.

used primarily metal flue pipes.
had ranks of pipes that were wider in scale in the treble than in the bass, making the low notes more penetrating than the higher pitches.
had more pipes per key in the treble than in the bass.
included primarily octave and fifth-sounding pipes, with some records indicating a basis on a 32' principal.
in the late Middle Ages, could have included a set of ten or twelve trompes or bordunen -- large pipes that were played from a separate keyboard.

Unfortunately, no medieval Blockwerk organ remains intact. There are several extant instruments that date from the late Middle Ages, at least in part, but not one of them exists today as an undivided Blockwerk. Furthermore, there are no reliable representations of these instruments in manuscript illuminations or in paintings. For the most part, we must rely on the descriptions of contemporary and later writers (Arnaut of Zwolle and Praetorius, for example) to know how these large instruments sounded or looked. We can, however, think about the impact these large instruments had on the listener: The medieval church organ produced the lowest- pitched, loudest sounds produced by man in the medieval West; surely the strength and their sound -- a sound heard only in a large church -- had an impact that could not be duplicated in the secular world of the time.

## [Welcome to Medieval Organ](Welcome to Medieval Organ) ##

## [The Medieval Portative Organ: An Interview with Cristina Alís Raurich](https://earlymusicmuse.com/portative-organ/) ##

## [Medieval Organ Culture to the 15th Century, An Overview](http://www.davidrumsey.ch/Medieval%20organ%20culture.pdf) ##
There are but a few early fragments of information, including Pope Gregory’s reference to the organ as “symbolic of the sermon” by the 6thc. Later reports, not always considered credible, claim that Pope Vitalian introduced the organ into the church service in 7thc. This was at about the same time as Isidor of Seville was excommunicating organists for being “theatrical people”. Aldhelm (*639-†709) in England possibly brought organ technology from Ireland.

Later the Franks, inheritors of the hydraulis and Greco-Roman organ through the Byzantine organ and its various transformations, dominate the sparse chronicles, most notably with instruments at Aix-la-Chapelle. This organ type converted itself through a period of about 5 centuries into the organ of late-medieval Europe as the Frankish empire dwindled. Documentary evidence is found in Walahfrid Strabo’s poem, mid-9thc and, in 873, Pope John VIII requested Archbishop Hanno of Freising to send “a good organ and organist to Rome, for the purposes of music education.” An organ-builder Georgius, a priest, lived in Venice in the 9thc.

10thc

Social life in Europe was ordered around food-gathering and defense, creating a hierarchical structure. The nobility provided earthly protection and the clergy offered spiritual succor to the vassals who worked the land in this feudal system. Between physical survival and heavenly reward there was little choice, hope for improvement or possibility of escape. The few organs on record belonged to the highest noble classes, and they evoked wonder for any vassals who happened to see and hear them.

Cathedrals and fortresses (sometimes with chapels) became the sacred and secular centers of life, the monasteries providing a refuge that served both needs and also began now to create organ cultures. Of these, the Benedictines were the most securely and longest-established as a Rule.
The first treatises on pipe-scaling appear c900.

In 915 Count Antonio founded a monastery in Canusina, donating gold and silver chalices as well as an organ. In about 992, St. Oswald donated a bellows organ, possibly a small “2-stop” Blockwerk, to a church, although the terms of the bequest suggest that it was a monastery chapel under his control. This organ appears to have been used only on feast days. Important instruments were known in England, among them Abingdon, Malmesbury and Winchester, Old Minster c994, as reported by Wulfstan. Other literary evidence comes from Dunstan. Such instruments undoubtedly had pedigrees reaching back more than a century, but we have no record of them.

The crusades had helped to establish Venice, already mentioned in connection with organs in the 9thc, as a focus on the route from England, Champagne, Flanders or the Rhine to the Holy Land.

11thc

The “millenium” century saw a sudden flurry of organ activity. Aribo describes organ pipes in his treatise entitled Musica; another important treatise survives from the Anonymous of Bern, probably written in Fleury. A Benedictine establishment, Fleury Abbey is recorded as possessing an organ at this time.
The most significant contemporary source of information comes from Theophilus, a Benedictine monk living in Frankish territory, somewhere around Alsace, in south western Germany or north eastern France. He described the furnishing of monasteries, including organs with key-sliders, copper or bronze pipes and feeder systems such as the “conflatorium”. Baldric, Archbishop of Dol, later provides literary confirmation of some of these features.

Apart from the limited tenure of Palace Organs, e.g. at Aix-la-Chapelle, chronicles report instruments installed at Augsburg, St. Ulrich 1066, Weltenburg, Monastery 1077, probably early forms of Blockwerk following the prototype of the organ at Winchester, Old Minster.

Smaller organ types also existed, as illustrated in the Pommersfelden Bible from Koblenz c1070. Medieval iconography often links David (in this case playing the harp) with other musical instruments. From the 13thc onwards, he is sometimes shown with an organ rather than a harp. Commencing c1078, the Sarum Rite became favorable to liturgical music, providing a possible catalyst to the development of organ culture.

12thc

The 12thc gave new impetus to organ activity as economic power migrated from the eastern Mediterranean to western and north western Europe. Towns began to flourish, the new agriculture improved people’s diets, survival was at least more assured now than it had been. Freiburg im Breisgau’s charter of liberties dates from these centuries. It is similar to that of Lübeck and the Hanseatic states around the Baltic and North seas - interestingly where organ culture was also often enough found.

Henry V affirmed principles of freedom for all, against the Bishops’ actions, especially in treating foreigners poorly. This affected the charters for Speyer and Worms - two more southern cities soon to possess organs of note. Organs were very much part of community life - sacred or secular, as a middle high German Poem from c1155 witnesses:

They began to sing sweetly And dance with swift steps, With harps and fiddles, With organs and lyres.

Populations grew and the old feudal system lost its grip. To some extent social controls were taken over by the church, something which indirectly assured more support for organs. Civic autonomy and pride also began to encourage the construction of organs, which are always dependent to a certain degree on affluence.
   
Strife between popes and emperors sprang up. Organs played an increasing role in these dramas, particularly as authorities disputed the instrument’s acceptance into the church. They were objects of pride, symbols of power and, alongside clocks, represented the most advanced technology of their day. With the growing populations of the towns, more of the common people probably came to hear, see and marvel at organs than ever before.

Instruments are known to have existed at Freising 1158 and Abingdon. The monastery at Petershausen had an organ at about this time. Other documentation for organs is found in the Harding Bible (dated 1109); 1114-1130 a letter of Baldric; c1120 by William of Malmesbury in Vita sancti Dunstani; 1146-7 copying of the Eadwine Psalter; a1166 in Aelred’s utterances.

This century also marks the earliest chronicles of the possible existence of organ pedals. Some of these instruments, especially those used in folk festivals, must have been the small Portatives mentioned in Gottfried von Straßburg's “Tristan'” or Heinrich von Türlin's “Krone”.

13thc

Medieval civilization reached its apogee, with Gothic art and architecture as well as the social developments of guilds, civic councils, and monastic life. Intellectual life was dominated by the church, the Benedictines still playing a leading role. Scholasticism, encouraged notably by Thomas Aquinas, led to arguments about the appropriateness of organs in churches. Feudal structures further broke up with the emergence of city-states (especially in Italy) while the Hanseatic League grew strongly in the north. A consistently chronicled regional organ culture began in northern Europe

In the aftermath of Venice’s early start with the instrument, mention of it in Italy is again found in 1287, when the Council of Milan decreed that only the organ was to be used in church; Ægidius of Zamora, head of the Franciscan Order living in Spain, confirms this. Dante Alighieri also mentions organs in sacred contexts, which suggests that the instrument continued to be played in churches, despite objections. He hints at the use of alternatim. Further peripheral confirmation of the instrument’s consolidated use liturgically is found in rubrics that refer to instrumental practice.

The Rutland Psalter shows a detailed organ with keys played by fingers, probably illustrating the new playing techniques, and an impressive wind conflatorium. Other instruments are recorded in 1225 at Erfurt Marienkirche and Erfurt Peterskirche 1226 (1291 destroyed by lightning), and in 1230 at Bonn. However it was the instrument by Conrad von Scheyern at Scheyern Abbey, 1245 that stands out, not only for technical and tonal advances critical to the organ’s future development, but also because of the rare detail we have of it. It had the first certainly-known Quint ranks, variable pipe-scalings, differing pipe-forms, and an increase in size over known earlier instruments. Conrad’s Glossarium Salomonis is traditionally dated 1245. The earliest organ at Lübeck, Domkirche, 1259 was but one of a number to be placed there in the 13th-16thcs.

14thc

Economic decline now came to much of Europe. It lasted through into the 15thc. Exceptions to this included the Hanseatic League. This partially explains the flourishing of organs in the north, and the international activity of some organ builders (e.g. Sira Arngrimr Brandsson in Norway and Iceland and “Meister Werner” from Brandenburg). We also hear of organists - Francesco Landini (c1325-1397), blind Italian organist, organ consultant, composer, philosopher and poet, was one of few of the earliest named organists of consequence.

The first of the most serious outbreaks of the great plague spread throughout most of Europe in 1348, and the Inquisition (which had first been instituted in 1231) began to cast a dark shadow. The church regulated its use of organs; high festivals were the main if not only occasions they were played.
Organs inspired a complex emotional cocktail of awe, wonder and joy - textual references as far apart as Einsiedeln in 1314 in a quotation of Magister Rudolf von Radegg relating to the joy the organs gave them here at Christmas “Exspirat festum, discedunt gaudia nostra; Organa desistunt, et lyra nostra tacet“ ("when the celebration is over our joy also finishes since the organs sound no more and our lyre is silenced.")

and Geoffrey Chaucer:
His voys was murier than the murie organ / On Messedays that in the church gon. (His voice was merrier than the merry organ, that played on Sundays in the church.)

Instruments were known to have existed at Barcelona, Catedral 1345, Dijon, Notre Dame 1350, and Halberstadt 1361. Towards the end of the century, the famous Gotland organs, including that at Norrlanda (c1370-1400), were built, some containing rollerboards, critical new technology needed for the larger instruments which were being developed. An early record of an Italian organ comes from Firenze, SS Annunziato 1379. From 14thc- organ builders are chronicled in Frankfurt am Main.

Apart from the permanently installed Blockwerks, now growing in size, smaller organ types such as portatives and positives are also depicted (e.g. Peterborough Psalter). The earliest ms of extant organ music, the Robertsbridge Codex, dates from mid-14thc. If one of Peter Williams’ hypotheses is correct, then organs were simply used to provide clamor, much as bells were. Against this it might be recalled, however, that the organ was used in tuneful, secular, dance music contexts or accompanied chant or other melodic music in liturgical drama - utilizing portatives or positives. It is difficult to know how much the use of organs would change between “external” and “internal” sacred applications or completely secular events. The concept of a “dance portative” may be amusing today, but it was entirely possible then as literary sources much earlier had hinted (an 1184 account of a peoples’ festival in Mainz):

There was playing and shouting, Pushing and shoving, Piping and singing, Fiddles and dancing, Organs and strings, Amongst many joyful things.
   
A 13thc Bohemian text might support the clamor theory in an “external” context, but it also implies that the organ was the musical equal to other instrument at the time.

“The people of Bohemia delight in the performance of a dance troupe. Everyone rejoices; singing and happiness resound. There is a beating of drums and a scraping of citharas, and all the while loud blasts of the trumpet ring out. The lyre twangs, and now the dancers twirl round; the chorus proclaims its joy, the organs peal, and the king arrives, laughing with everyone gathered there.”

The century was categorized by technological and tonal development, multiple manuals appeared, even multiple organs (Rastede Klosterkirche - two by 1374), the composition of organ music, evolution of dedicated notation systems and the increasingly international operations of organ builders.

The instrument grew larger and ever more impressive, lower-pitched pipes were introduced, most notably the first known 32's. With this there was perhaps a little more awe, even fear, added to the “clamor, tunefulness and festive” organ equation. It could be that awe and fear were seen as desirable controlling techniques in the course of the Inquisition. This may have been a component in the church’s adoption of the instrument - which received its earliest more notable successes in the medieval north where some of the largest Blockwerks with the lowest (32') sounds were to be found.
th th And where a Reformation was brewing as it was also around Czechoslovakia - 13 -14 c. 15thc

In 1438 Albert of Habsburg became emperor. Thereafter the Habsburgs held the throne almost continuously until the dissolution of the Holy Roman Empire in 1806.
The 15thc presents us with a remarkable array of organ types and the further development of notated organ music. Iconographical depictions of smaller organ types are plentiful during the 15thc, including manuscript illuminations, paintings, sculptures and other media, such as the famous La Dame à la licorne tapestries. Magdeburg, St. Jakobi possessed a Blockwerk b1400. The most important extant manuscript about organ building is Arnaut de Zwolle’s treatise on organbuilding (c1440), which includes specifications for the organs that previously existed at Dijon, Notre-Dame 1350/1445/1447? and Salins b1440. It relates mainly to the further developing Blockwerk and the compositions of its now impressively-endowed Mixtures.

The century also saw major installations at Hagenau, St. Georg 1491 (Alsace) by Friedrich Krebs, another at Weimar, Castle Church in 1492 by Hieronymus Keylholtz of Bayreuth and yet another at Bamberg, Cathedral in 1493 by Conrad Rottenburger. Leonhard Mertz was active around Frankfurt am Main in the late 15thc.
These organs have all disappeared, but other organs today still contain pipework, casework or other components surviving from the 15thc, such as Sion 1435; Altenbruch, St. Nicolai 1498. Ostönnen, Andreaskirche and Krewerd, Hervormde kerk still partially date back to the 15thc. The organ previously at Basel, St. Peter (Münster) 1482-96, built by Hans Tugi, was emulated in a new instrument at Basel, Predigerkirche 1985.

One of the most important technological achievements, stop-separation, is found on innovative instruments of the time, such as those still existing at Rysum c1425-57 and Bologna, San Petronio 1474. Other notable organs were constructed at the turn of the century, some, or fragments of them still existing today. They include Old Radnor, St. Stephen c1500

Kiedrich c1500-20
Salzburg, Fortress Hohensalzburg 1502- Alkmaar, Grote of Sint Laurenskerk 1511

Collections of 15thc organ music illustrate two main approaches: “organisare”, making polyphony over a tenor pattern, and “intabulare”, arranging vocal models for the keyboard. Organists learned to create music over tenor patterns, as exemplified in the 1452 Fundamentum organisandi of Conrad Paumann, included in the Buxheimer Orgelbuch c1455. This large compilation contains many arrangements of vocal models, as well as free praeludia. The Italian Codex Faenza, c1430, demonstrates how organists created a free upper voice over plainsong in the tenor, presenting us in the process with the earliest surviving liturgical organ music. It also includes intabulations of vocal polyphony in the same two-part texture. The earliest free preludes are found in the 1448 Tablatur of Adam Ileborgh of Stendal; the rubrics to these five short pieces refer to the use of pedals. There is little else; the 1431 collection of Ludolf Wilkin of Winsem entitled “Predigtsamlung” contains a few pieces.

Antonio Squarcialupi (1416-1480), Italian organist at Firenze, S Maria del Fiore (Cathedral), organ consultant and composer, was an important figure, especially for his surviving collection of early organ music. The 15thc Codex Squarcialupi is named because it was a collection in his ownership; no composition of his has survived.

The 14th and 15thc were seminal to the development of later organ cultures throughout Europe, creating many watershed innovations for the instrument’s technology and use. Like vines cultivated from a common source, national schools grew in diverse and complex ways from the roots of late-medieval organ building and playing. Yvonne Rokseth evokes the joy and wonder aroused by organs of this era, devoting her scholarship to records of early organs and editions of the music composed for them:

"Normally a curtain made of precious metal covered the organ. We get the impression of a giant altar or shrine. But on Feast-days, when music was allowed, the curtains are drawn up, the wing-like doors which stand in front of the glistening fields of pipes are opened. At this point the golden carvings and decorated pipes, encased in the blue and red housing, are seen in all their radiance. The organist seats himself at the keys. The ornamental stars and planets at the top of the organ case begin to turn and the figures appear to come to life. A wonderful, and quite remarkable theater has commenced in the Gothic Cathedral with its columns pointing heavenward, its colorful windows, its multitude of chapels and hanging tapestries. The priests move toward the altar to the sounds of the organ. The Te Deum is sung, as in antiquity, antiphonally between priests and people - it was always done this way at those happy and joyous festivals of the people."
(Translation by Patricia Sue Fitzsimmons, University of Rochester, 1978).

## [Gregorian Chant Music - Monks of the Dark Abbey](https://www.youtube.com/watch?v=yBHg9T9j4qU) ##

## [The Essentialism of Music in Human Life and Its Roots in Nature](https://digitalcommons.linfield.edu/cgi/viewcontent.cgi?referer=https://www.google.com/&httpsredir=1&article=1005&context=muscstud_theses) ##


----------


# Thomas Jefferson #
## [Jefferson Letter to Madison: A Little Rebellion Now and Then Is A Good Thing - A Letter From Thomas Jefferson To James Madison](https://www.varsitytutors.com/earlyamerica/early-america-review/volume-1/jefferson-letter-madison) ##
"Shays' Rebellion — a sometimes-violent uprising of farmers angry over conditions in Massachusetts in 1786 — prompted Thomas Jefferson to express the view that 'a little rebellion now and then is a good thing' for America. Unlike other leaders of The Republic, Jefferson felt that the people had a right to express their grievances against the government, even if those grievances might take the form of violent action. Jefferson airs his sentiments in a letter to James Madison on January 30, 1787, expressing justification for the series of protests led by Daniel Shay and a group of 1,200 farmers. Jefferson also writes of his concern over John Jay's impending negotiations with Spain. Under consideration would be proposals to extend privileges in Spanish ports to American ships, while providing navigation rights on the Mississippi River to Spain. In his letter to Madison, Jefferson expresses his belief that the agreement might be interpreted as opening up the Mississippi to Spanish rule, thus provoking a war between settlers in the west and Spain, and eventually, dividing the nation.

Dear Sir, My last to you was of the 16th of December; since which, I have received yours of November 25 and December 4, which afforded me, as your letters always do, a treat on matters public, individual, and economical. I am impatient to learn your sentiments on the late troubles in the Eastern states. So far as I have yet seen, they do not appear to threaten serious consequences. Those states have suffered by the stoppage of the channels of their commerce, which have not yet found other issues. This must render money scarce and make the people uneasy. This uneasiness has produced acts absolutely unjustifiable; but I hope they will provoke no severities from their governments. A consciousness of those in power that their administration of the public affairs has been honest may, perhaps, produce too great a degree of indignation; and those characters, wherein fear predominates over hope, may apprehend too much from these instances of irregularity. They may conclude too hastily that nature has formed man insusceptible of any other government than that of force, a conclusion not founded in truth or experience. Societies exist under three forms, sufficiently distinguishable: (1) without government, as among our Indians; (2) under governments, wherein the will of everyone has a just influence, as is the case in England, in a slight degree, and in our states, in a great one; (3) under governments of force, as is the case in all other monarchies, and in most of the other republics.

To have an idea of the curse of existence under these last, they must be seen. It is a government of wolves over sheep. It is a problem, not clear in my mind, that the first condition is not the best. But I believe it to be inconsistent with any great degree of population. The second state has a great deal of good in it. The mass of mankind under that enjoys a precious degree of liberty and happiness. It has its evils, too, the principal of which is the turbulence to which it is subject. But weigh this against the oppressions of monarchy, and it becomes nothing. Malo periculosam libertatem quam quietam servitutem. Even this evil is productive of good. It prevents the degeneracy of government and nourishes a general attention to the public affairs. I hold it that a little rebellion now and then is a good thing, and as necessary in the political world as storms in the physical. Unsuccessful rebellions, indeed, generally establish the encroachments on the rights of the people which have produced them. An observation of this truth should render honest republican governors so mild in their punishment of rebellions as not to discourage them too much. It is a medicine necessary for the sound health of government. If these transactions give me no uneasiness, I feel very differently at another piece of intelligence, to wit, the possibility that the navigation of the Mississippi may be abandoned to Spain. I never had any interest westward of the Allegheny; and I will never have any. But I have had great opportunities of knowing the character of the people who inhabit that country; and I will venture to say that the act which abandons the navigation of the Mississippi is an act of separation between the Eastern and Western country. It is a relinquishment of five parts out of eight of the territory of the United States; an abandonment of the fairest subject for the payment of our public debts, and the chaining those debts on our own necks, in perpetuum. I have the utmost confidence in the honest intentions of those who concur in this measure; but I lament their want of acquaintance with the character and physical advantages of the people, who, right or wrong, will suppose their interests sacrificed on this occasion to the contrary interests of that part of the confederacy in possession of present power. If they declare themselves a separate people, we are incapable of a single effort to retain them. Our citizens can never be induced, either as militia or as soldiers, to go there to cut the throats of their own brothers and sons, or rather, to be themselves the subjects instead of the perpetrators of the parricide. Nor would that country quit the cost of being retained against the will of its inhabitants, could it be done. But it cannot be done. They are able already to rescue the navigation of the Mississippi out of the hands of Spain, and to add New Orleans to their own territory. They will be joined by the inhabitants of Louisiana. This will bring on a war between them and Spain; and that will produce the question with us, whether it will not be worth our while to become parties with them in the war in order to reunite them with us and thus correct our error. And were I to permit my forebodings to go one step further, I should predict that the inhabitants of the United States would force their rulers to take the affirmative of that question. I wish I may be mistaken in all these opinions."


----------


# Intellectual Disabilities #
## [Autism's Hidden Gifts](https://www.theatlantic.com/health/archive/2015/09/autism-hidden-advantages/406180/) ##
"Those accounts have contributed to a popular misconception: that when autistic people are unusually skilled, those skills are impractical and not connected to 'real' intellect.

Laurent Mottron, a psychiatrist at the University of Montreal who has studied autism for decades, led an analysis last year which suggested that the autistic brain seeks out the kinds of information it 'prefers' to process while ignoring materials—like verbal and social cues, for example—that it doesn’t like. Just as many blind people have heightened hearing, Mottron says, the brains of autistic people might be better able to understand numbers or patterns.

One of The Onion’s parody news videos is about an “autistic reporter” sent to cover a train accident that killed a man. “Luckily there was not structural damage caused to the train,” the actor says, before rattling off the train’s fascinating (to him) particulars, like its “Westinghouse E-CAM XCA448F propulsion.” That’s the cliche, of course: that an autistic person would memorize a locomotive-traction system but overlook the real, human story behind it.

Unlike when Mottron was first starting his research, it’s now more widely accepted that autistic people can be precocious at technical and visual tasks. But it’s not like they’d be great poets or artists... right?

In fact, newer studies suggest that the autism advantage might extend even to domains that are thought to be the stronghold of neurotypical people, like creativity. A paper published last month in the Journal of Autism and Developmental Disorders sought to measure the output of creative ideas in a sample of autistic and neurotypical people.

The participants were asked to think of as many non-obvious uses for a brick and a paper clip as possible. Highly autistic people in the experiment didn’t produce very many responses, but the answers they did give were highly unusual—a strong sign of creative thinking.

Neurotypical participants would think of all the easy answers—like using the paperclip to reset their iPhones—and only then move on to more innovative uses. But the autistic people jumped straight to the ingenious responses, saying they would use the paperclip as a weight for the front of a paper airplane, for example, or for heating up in order to suture a wound.

'Most people focus on one property of the object and do associations with that,' Catherine Best, health researcher at the University of Stirling and a co-author of the study, told me. 'They might say, ‘Oh, it's like a piece of wire. What else can you do with wire?’ People with autistic traits skip to the more difficult stuff.'

The idea that autistic brains are intrinsically deficient is one of the many myths Steve Silberman debunks in his recent book, Neurotribes. Think of the brain as an operating system, he writes: 'Just because a computer is not running Windows doesn’t mean that it’s broken. Not all the features of atypical human operating systems are bugs.'

Silberman said he avoids using terms like 'high-functioning' and 'low-functioning.' 'People who are classified as high-functioning are often struggling in ways that are not obvious,' he told NPR’s Terry Gross recently, 'whereas science has shown that people who are classified as low-functioning often have talents and skills that are not obvious.'

Or to borrow another famous operating-system slogan, many autistic people simply 'think different,' not worse.

This isn’t to suggest that the parents of severely autistic children—some of whom are prone to tantrums and violence—don’t face real challenges. There’s only so far someone who can’t speak can go with pattern recognition, creativity, and detail orientation.

But this and other research might signal that it’s time to rethink the way educators help young autistic children prepare for the broader world. Early childhood interventions should focus on harnessing strengths, Mottron says, rather than erasing the differences between autistic children and neurotypical kids.

'I no longer believe that intellectual disability is intrinsic to autism,' Mottron has said. And because of that, he believes, 'The limits of autistics should constantly be pushed and their educational materials should never be simplified.'"

## [Genius May Be an Abnormality: Educating Students with Asperger's Syndrome, or High Functioning Autism](https://www.iidc.indiana.edu/irca/articles/genius-may-be-an-abnormality-educating-students-with-aspergers-syndrome-or-high-functioning-autism.html) ## 
"I am becoming increasingly concerned that intellectually gifted children are being denied opportunities because they are being labeled either Asperger's or high functioning autism. Within the last year I have talked to several parents, and I was disturbed by what they said. One mother called me and was very upset that her six-year-old son had Asperger's. She then went on to tell me that his IQ was 150. I replied that before people knew about Asperger's Syndrome, their child would have received a very positive label of intellectually gifted.

In another case the parents of an Asperger teenager called and told me that they were so concerned about their son's poor social skills that they would not allow him to take computer programming. I told her that depriving him of a challenging career in computers would make his life miserable. He will get social interaction by shared interests with other computer people. In a third case, a super smart child was not allowed in the talented and gifted program in his school because he had an autism label. Educators need to become aware that intellectually satisfying work makes life meaningful.

It is essential that talented children labeled either high functioning autism or Asperger's be trained in fields such as computer programming, where they can do intellectually satisfying work.

I have been reading, with great satisfaction, the many articles in magazines about Linux free software. People in the business world are not able to comprehend why the computer people give their work away. I am unable to think about this without becoming emotional. It is no mystery to me why they download their intellectual ideas into the vast, evolving and continually improving computer operating system. It is because their thoughts will live forever as part of the "genetic code" of the computer program. They are putting themselves into the program and their 'intellectual DNA' will live forever in cyber-space. As the program evolves and changes, the code they wrote will probably remain hidden deep within it. It is almost like a living thing that is continually evolving and improving. For both me and for the programmers that contribute to Linux, we do it because it makes our lives more meaningful.

There is a continuum of personality and intellectual traits from normal to abnormal. At what point does a brilliant computer programmer or engineer get labeled with Asperger's. There is no black and white dividing line. Simon Baron-Cohen, an autism researcher at the University of Cambridge, found that there were 2 ½ times as many engineers in the family history of people with autism. I certainly fit this pattern. My grandfather was an engineer who was co-inventor of the automatic pilot for an airplane. I have second and third cousins who are engineers and mathematicians.

There is evidence that high functioning autism and Asperger's Syndrome have a strong genetic basis. G. R. DeLong and J. T. Dyer found that two thirds of families with a high functioning autistic had either a first or second degree relative with Asperger's Syndrome. Sukhelev Naragan and his co-workers wrote, in the Journal of Autism and Developmental Disorders, that educational achievement of the parents of an autistic child with good language skills were often greater than those of similar parents with normal children. Dr. Robert Plomin at Pennsylvania State University states that autism is highly heritable.

In my book, Thinking in Pictures, I devote an entire chapter to the link between intellectual giftedness and creativity to abnormality. Einstein himself had many autistic traits. He did not learn to speak until he was three, and he had a lack of concern about his appearance. His uncut hair did not match the men's hairstyles of his time.

Every thought I have is represented by a picture. When I think about a dog, I see a series of pictures of specific dogs, such as my student's dog or the dog next door. There is no generalized verbal 'dog' concept in my mind. I form my dog concept by looking for common features that all dogs have, and no cats have. For example, all of the different breeds of dogs have the same kind of nose. My thought process goes from specific pictures to general concepts, where as most people think from general to specific. I have no vague, abstract, language-based concepts in my head, only specific pictures.

talented, autistic artists assemble the whole from the parts. It is 'bottom up thinking,' instead of 'top down thinking.'

Children and teenagers with autism or Asperger's need teachers who can help them develop their talents. I cannot emphasize enough the importance of developing a talent into an employable skill. The visual thinkers like me can become experts in fields such as computer graphics, drafting, computer programming, automotive repair, commercial art, industrial equipment design, or working with animals. The music, math, and memory type children can excel in mathematics, accounting, engineering, physics, music, translating engineering and legal documents, and other technical skills. Unless the student's mathematical skills are truly brilliant, I would recommend taking courses in library science, accounting, engineering, or computers. Learning a technical skill will make the person highly employable. There are few jobs for mediocre mathematicians or physicists.

Since social skills are weak, the person can make up for them by making themselves so good at something that people will hire them. Teachers need to council individuals to go into fields where they can easily gain employment. Majoring in history is not a good choice because obtaining a job will be difficult. History could be the person's hobby instead of the main area of study in school.

Many high functioning autistic and Asperger teenagers get bored with school and misbehave. They need mentors who can teach them a field that will be beneficial to their future. I had a wonderful high school science teacher who taught me to use the scientific research library. Computers are a great field because being weird or a 'computer geek' is okay. A good programmer is recognized for his/her skills. I know several very successful autistic computer programmers. A bored high school student could enroll in programming or computer-aided drafting courses in a local community college."

## [Occupational Therapists: What Do They Do?](https://childmind.org/article/occupational-therapists-what-do-they-do/) ##
"Occupational therapy, known as OT, is designed to help children and adults acquire (or regain) the skills needed to perform the activities—or 'occupations'—of daily life. 'It’s a huge field,' says Lindsey Biel, an OT specializing in pediatrics and coauthor with Nancy Peske of Raising a Sensory Smart Child. When a child shows delays in mastering typical activities, or displays unusual or disruptive behavior, the OT is often the first professional to work with her.

OTs are found in many settings. Children up to age 3 may receive home-based therapy under EI. Some OTs, like Biel, are private service providers, visiting their young clients at home or in school. Others offer therapy in private sensory gyms. But, Biel says, the majority of OTs are found in schools, both pushing into classes to work with kids and pulling them out for one-on-one work on fine and gross motor skills, along with sensory gym time.

These master’s level health-care professionals take a holistic approach to a client’s physical well-being, explains the American Occupational Therapy Association, by also considering psychological, social and environmental factors that may affect functioning.

Biel explains that during an evaluation, the therapist uses a task analysis to figure out just what’s going on. Say a 5-year-old girl isn’t putting on her shoes. Is the issue sensory-based? Fine motor? Or maybe she just likes all the attention she gets from Mommy? What about a kindergartner who is still in pull-ups? 'Is it because the potty’s scary?' Biel asks. 'Do dangling feet make him feel like he’s falling, or is his tush uncomfortable? We also look at what muscle groups need to be recruited effectively to go to the bathroom.'

Biel breaks down a litany of issues OTs address on her site Sensory Smarts: attention span and arousal level; sensory and processing skills; fine and gross motor skills; activities of daily living (ADLs), also known as self-help skills, such as brushing teeth, dressing and toilet training; visual-perceptual skills; handwriting; and assistive technology.

What are sensory processing issues?
When it comes to attention, arousal level, and sensory and processing skills, the work OTs do is based on theories presented by occupational therapist Dr. A. Jean Ayres back in the 1970s. She posited that children and adults with sensory processing issues can’t synthesize all the information streaming in from the traditional five senses—touch, hearing, taste, smell and sight—as well as two “internal” senses, body awareness (proprioception) and movement (vestibular). Proprioception allows for motor control and posture, while vestibular receptors tell the brain where the body is in space, which links directly to balance and coordination. (Peske has made a short, fun video that introduces these seven senses.)

Children who have trouble modulating sensory input may experience over-sensitivity (hypersensitivity), under-sensitivity (hyposensitivity) or both to an impairing or overwhelming degree, at school, at home and in the world at large.

An extremely hypersensitive child tends to be withdrawn; because she’s easily overwhelmed by auditory and visual stimuli, she may want to avoid gym, recess and lunch. The buzz of fluorescent lights and anxiety about the loud fire alarm going off may distract her, making it difficult to pay attention and participate in class.

Controversy continues as to whether two widely used practices, joint compressions and a brushing of the skin, actually 'rewire' the brain so that kids can appropriately integrate and respond to sensory input, allowing them to feel more comfortable and secure as they negotiate their environment. Even Biel admits that she isn’t always sure these practices have merit but “just when I have my doubts, there’s this great intervention. I had a child making almost no eye contact who was constantly in motion. I put him on cushions and gave him a good brushing. I got eye contact through the whole session; his parents were gasping. Is he cured? No. Was it organizing? Yes.”

## [Occupational Therapy](https://www.slideshare.net/StephanvanBreenenCli/occupational-therapy-and-intellectual-disability) ##
"Intelligence": cognitive functions, "learning, reasoning, manipulating information, and identifying patterns and relationships, solving problems, recall, planning"

Even with someone with a "borderline intellectual deficit", and "no apparent deficits", there may be needs to engage "health assessment and treatment."

"People with intellectual disability": "learn and process information more slowly", have time with "money, time, and subtleties of interpersonal interactions" and "cultural nuances"


* "Usually recognizes familiar people and has strong relationships with key people in their lives."
* "Most will have little or no speech and will rely on facial expression and body language and gestures to express their needs or feelings and those interacting with and supporting them must be active and keen observers in interpreting changes in a person's demeanor or behavior"
* "Communication systems for people with this level of disability generally rely on photographs or objects to faciliate understanding, e.g. a picture of a cup, or the cup itself, may be used in conjunction with the spoken question"
* "People with severe/profound disabilities will require lifelong assistance in personal care tasks, communication, and support in accessing community facilities/services"


"Many people find the subtleties of interpersonal relationships and social rules difficult to understand (particulary as adolescents) and may inadvertently transgress social boundaries."

Recognizing that someone has intellectual disability
* Ability to identify signs that a person may have intellectual disability
* Awareness that intellectual disability affects different people in different ways
* Ability to seek information to understand each person's unique support needs


Poor Communication is a Barrier
* Better communication could increase your ability to understand and improve the mental health of your patients who have an intellectual disability.

The Significance of Good Communication
* An understanding that good communication is important when supporting someone who has an intellectual disability.
* An understanding that difficulties in communication arise due to the interaction of disability, psychological function and social context.


Communication Difficulties
* People with an intellectual disability commonly experience problems with communication.

Social Communication
* Cultural Norms, Eye Contact, Negotiating Personal Space

Intellectual Disability and Mental Illness
* Anxiety, Depression, Mood Disorders, Schizophrenia, and Other Psychoses
* Impact on Communication
* Depression, Agitation

Aggressive Behavior
* Someone's behavior can communicate an issue or need, and be a valuable source of information about their condition. The important thing is to hink about what the behavior is telling you - how can you analyze the behavior and its possible causes or meanings?

Aggressive, self-injurious behavior - a substitute for communication about psychological symptoms, emotions, or other troublesome situations, like a health problem or pain

Behavioral Presentation
* Someone's level of intellectual disability has a significant impact on their expression of underlying emotional states or psychiatric symptoms.
* Intellectual Disability, Severe, Atypical Presentations of symptoms

Training in Inter-Cultural Communication
* Using someone's first name
* Asking yes/no questions
* Listening closely

People with Intellectual Disability - Increased Risk of
* Mental Illness
* Maltreatment, Bullying, and Sexual Assault
* Lower Rates of Physical Activity
* Hospitalization
* Dental Disease (up to 8.5 times more common, and poor rate of treatment)
* Vision Impairment and Eye Disorders
* Hearing Impairment
* Thryoid Problems
* Epilepsy
* Heart Disease
* Osteoporosis

Risk Factors for Mental Illness Associated with Intellectual Disability
* Low self-esteem
* Lower autonomy and less freedom to make own decisions
* Poorer communication skills
* Fewer coping and emotional regulation skills
* Higher levels of frustration
* Greater difficulty complying with treatments
* Increased risk-taking behavior
* Higher levels of illness and other disabilities
* Having fewer interpersonal and social relationships

Intellectual Disaiblity, Behavioral Problems
The Behavior May Be a Response to Pain, or Be A Symptom of Health or Mental Health Problem
Disability, Limited Communication Ability

PsychoSocial Impact of Intellectual Disability
* Ambiguity, Limited Information, Shock
* Significant Emotional, and Practical Adjustments
* Assumptions, Expectations, Hopes, Unexpected Gifts
* Significant Financial Adjustment

Social
* Social contact and establishing a wide variety of relationships
* Having leisure and other interests
* Moving around independently
* Experiencing social milestones such as gaining employment or getting a driver's license

Communication
Cognition: the ability to process information varies across a wide range in people with an intellectual disability

Freedom from Discrimination

Privacies in Mental Health
Right to Privacy
Respect, Dignity, Duty of Care
Consent to Sharing Sensitive Information

## [Should Music Be Used in Occupational Therapy?](https://ajot.aota.org/article.aspx?articleid=1874468) ##
The healing power of music - many cultures, for many centuries

Music, dance therapy

"Nothing is more laden with emotional associations"
"Nothing is more capable of recreating situations"

Therapeutic modality

Disorders, psychoses

"Occupational therapy addresses the dysfunction found in a wide variety of psychiatric, developmental, and physical disorders."

## [Music & Sound Therapy](https://www.ot-innovations.com/music-sound-therapy/) ##
"Music is a very powerful sensory modulation tool! The therapeutic effects of music on the nervous system are well researched. Literature states that a 60 beat per minute pulse can help entrain healthy internal rhythms. Some important considerations before using music in the environment or during OT treatment sessions include the following: diagnosis, age, culture, environment, personal preferences, sensitivities, and personal history."

"Slower paced music with a consistent and predictable rhythm is known for having calming effects on the system, while upbeat & quick paced music is generally alerting and facilitates action/movement. Some popular examples are listed below:

Ambient music encompasses a variety of music; most common today are many of the 'relaxation tapes' widely available on the market. The purpose of these recordings is to produce a general state of relaxation.

Bach & Pachabel: These compositions are consistent and predictable, and have a pulse of approximately 50-70 beats per minute.

Mozart or Hayden: There is continuity, clarity, and order in these compositions – although they have greater changes in rhythm, time, and color than that of Baroque.

Tchaikovsky or Beethoven: Emotional and dynamic compositions known for their strong rhythms, emotional context changes, and unique sound textures which tend to stimulate the imagination."

## [Music as a Therapeutic Medium for Occupational Engagement: Implications for Occupational Therapy] ##
"Music is a meaningful occupation; a summary of current literature and the authors’ experiences regarding health and wellness benefits and potential for music as a therapeutic medium in occupational therapy practice is presented. An interview and a summary of the authors’ experiences illustrate the role for music and its benefits for occupational therapy. These benefits are described through three themes which emerged: (a) music as a means of increasing group cohesion toward common goals, (b) music as a means of increasing socialization, and (c) music as a meaningful occupation can empower individuals to enhance and embrace wellness and recovery."

## [Occupational Therapy](https://www.aota.org/-/media/corporate/files/practice/mentalhealth/focus-on-mental-health-booklet.pdf) ##
"Studies investigating the neurology of music show links between music and cognitive function. In a meta-analysis, music has been found to play a catalytic role in hippocampal-dependent temporal order learning, spatiotemporal reasoning, memory, recall, focus modulation, attention span, attention range in left neglect, sensory-motor learning, auditory verbal learning, emotional adjust- ment, motor/executive function, and psychosocial function (Thaut et al., 2009). With vast neuronal associations in the brain, the use of music in therapy can be individualized to facilitate cogni- tive remediation using the brain’s natural neuroplastic tendency. Experiencing music requires both cerebral and limbic involvement (Thaut et al., 2009). Because both regions are involved, music can be used to address the interconnectivity and communication between these brain areas without requiring verbal capability. Listening to music addresses sensory and emotional pathways, whereas playing music requires coordination, timing, proprioception, and memory."


----------


# Timber, Logging, and Homes #
## [Timber Industry](https://tennesseeencyclopedia.net/entries/timber-industry/) ##
"Although Tennessee’s earliest settlers appreciated the vast timber resources they discovered, the greatest timber extraction in the state’s history occurred between 1880 and 1920. Rapid deforestation by industrial loggers during this period caused long-term environmental changes and notable revision of state and federal policies.

Early European settlers extolled the wonders of the rot-resistant American chestnut trees, which made up as much as 25 percent of the forest. They proceeded to build durable homes and fences from them and to clear the woods for agriculture. By the early nineteenth century, a rudimentary iron industry also found hardwood (deciduous trees) valuable to fire small blast furnaces. A typical, eight-foot-square forge required a layer of charcoal four feet thick to melt four hundred pounds of ore in two hours. Not surprisingly, the woods around the forges were typically cut down, and slag from such operations can still be found. Demand for wood to produce charcoal encouraged an 1809 state law that permitted ironmakers to acquire large tracts of land just for harvesting wood. In the 1830s, for example, the Tellico Plains Iron Works began harvesting trees on the Tellico River for the manufacture of pig iron and, eventually, cannon balls and ammunition for Confederate troops.

Large-scale timber and mining would not be profitable, however, until the railroad moved to Tennessee. Despite repeated petitions, by the 1850s the state only had twelve hundred miles of track. This relatively slow entrance into the new transportation age probably protected Tennessee forests longer than the neighboring states of Kentucky and Virginia. Soldiers passing through the state during the Civil War frequently commented on the verdant natural resources, particularly in the eastern part of the state; some of these men later became investors and entrepreneurs in the turn-of-the-century timber boom. As railroads began carving up the state after the war, struggling farmers picked up seasonal income by cutting and selling medium-sized species such as locust to the companies for railroad ties. Others sold bark from their woodlots to the nascent tanning industry.

Beginning in the 1870s, Nashville and Memphis promoters welcomed Northeast lumbermen into the state. In 1881 Southern Lumberman, which remains the major trade association publication for southern hardwood companies, began publication in Nashville. Nashville companies got much of their hardwood from small entrepreneurs along the Cumberland River. Enterprising men cut trees during the winter and when spring rains swelled the streams that fed the Cumberland, they floated out rafts of logs and sold them to the Nashville mills. The principal species were oak and poplar, but a few mills such as Prewitt-Spurr specialized in cedar buckets and churns. In 1910, thirty-two hardwood mills operated in Memphis. Furniture makers from all over the nation bought wood in Memphis, which billed itself as the Hardwood Capital of the World.

In East Tennessee, outside capitalists such as Glasgow’s Scottish Carolina Timber and Land Company also sought specialty wood, especially cherry and walnut. The company built a mill and log boom at Newport during the 1890s but could not keep the operation solvent for long because of transportation problems. At the same time, a Michigan investor, W. E. Heyser, built a mill in Chattanooga and towed logs down the Little Tennessee to his operations. Because of the inaccessibility of the mountains, though, federal foresters Horace B. Ayres and William W. Ashe reported that the forests in the eastern part of the state remained largely intact in 1901.

The invention of steam-powered skidders and band sawmills soon improved profitability in remote locations. In Monroe County, a group of Pennsylvania businessmen operated the Tellico River Lumber Company. New York businessmen operated the Tennessee Timber Coal and Iron Company in Cumberland County. Two Cincinnati investment groups ran the Grand View Coal and Timber Company near Chattanooga and the Conasauga Lumber Company in Polk County. Wilson B. Townsend, a Pennsylvania lumberman, became interested in the Little River area after the Schlosser Leather Company financed a railroad into nearby Walland. Townsend already controlled major logging operations in Pennsylvania and coal, clay, tile, and railroad holdings in East Kentucky when he moved into Tuckaleechee Cove in 1901. He built a railroad, mill, and company town, which residents named Townsend in his honor. As a well-financed businessman, he could afford the latest technology and so switched his operations from circular saws to band saws, which allowed cutting very thick logs with less waste. Townsend invested in steam-powered skidders that could transport oak and chestnut trees as small as ten inches as far as five thousand feet. By 1910 his Townsend operations were producing 120,000 board feet per day.

Timber barons also relied on cheap, nonunion labor in Tennessee. Poor farmers moved to the temporary lumber camps and lived with their families in boxcars or “setoff” houses eight by ten feet wide that could be moved from site to site. In 1912 Tennessee lumber workers put in a sixty-hour week for fourteen cents an hour. Wages did not rise even when demand for southern hardwoods increased. When war broke out in Europe in 1914, the demands on southern forests, especially walnut for gun stocks accelerated, and did not abate with the return of peace. White County timber was especially targeted for gun stock production.

Turn-of-the-century lumbermen took so many trees so quickly that Gifford Pinchot, head of the U.S. Forest Service, predicted that all the timber in the United States would be gone in twenty years. Such dire warnings helped lead the industry toward the establishment of National Forests; indeed, many lumbermen, including Townsend, were convinced that the Forest Service would save them money in taxes and management. The depletion of forest lands resulted in a dramatic loss of wildlife as habitat was destroyed. To protect game and improve tourism, Tennessee initiated its first game laws and under Governor Austin Peay established a Department of Forestry. Careless management by timber companies allowed fire to spread in the clear-cut mountainsides, and erosion further damaged the land. This rapid deforestation and soil loss created high and low runoff patterns, and major flooding followed. Partially in response to swollen riverways and denuded land, the federal government in the 1930s initiated such major reforms as the Tennessee Valley Authority and the projects of the Civilian Conservation Corps as well as the design"

## [Standardization in the Lumber Industry: Trade Journals, Builder's Guides and the American Home](https://repository.upenn.edu/cgi/viewcontent.cgi?article=1555&context=hp_theses) ##
"Many of writings about the American home are directly or peripherally related to the American lumber industry. This body of written work ranges from scholarly theories, to historical analyses, to memoirs about one’s experience in their home, to technical manuals and trade journals, based upon the desired audience. Authors explore the American home from many angles: descriptions of personal home construction, urbanization, suburbanization, and industrialization in twentieth century construction. Many published works link stylistic changes in building construction to a wide range of factors: technological improvements to building materials, new appliances for in-home use, the expanding role of women in the home, and the proliferation of pattern books due to improvements in book printing and distribution. Similarly, home construction is explored through the lumber production and the home improvement industry.

Within of these genres, unifying themes emerge and develop into a cohesive whole that shapes the way Americans think about the idea of home.

The lumber industry is among the oldest manufacturing industries in America. Its expansion was fueled by growing cities and expansion into the great west. The industry focused on logging and timber production to meet the growing demands of northeastern cities. Lumbering was known for its extreme fragmentation, as forests, sawmills, and retail outlets were often owned by different entities. Additionally, logging operations and transportation of products to the mills and lumber yards were controlled by still more companies. This far-reaching supply network was slow to react to changes in demand for products. As new materials were invented, including gypsum wallboard and mass-produced millwork, lumberyards were reluctant to stock these goods as they feared this would detract from their lumber sales. Additionally, lumberyards were often located on the outskirts of town along rail spurs due to their demands for easy rail access and large spatial requirements. The intended audience of lumber distributors was also in flux during this time period: while they needed to maintain their core audience of home- building professionals, many lumber dealers recognized that marketing their products directly to consumers (or “home handymen”) could reap financial rewards. Their remote locations and limited audience also slowed their rate of change and insolated them from modernizations that were occurring elsewhere in society.

American Dream. In The American Family Home, 1800-1960, Clifford Edward Clarke, Jr discusses the notion of the 'American Dream,' including its history and precedents. Clarke generalizes that among the middle class, homes are a symbol of upward mobility. Specific housing types begin to dominate the landscape as features of everyday life are shared by most households. Clarke also describes that competition with one’s neighbors often accompanies the notion of home ownership. Similarly, in Where We Lived: Discovering the Places We Once Called Home: The American Home from 1775 to 1840, Jake Larkin uses photographs, drawings, and documents from the Historic American Buildings Survey to reflect on the development of American home construction. Larkin’s stated goal is to depict a house as a machine for living, while taking into account what those homes mean to the individuals or families that live there. In The Evolving House: A History of the Home, Albert Farwell Bemis and John Burchard show that homes evolve over time due changing societal expectations and inhabitant requirements.

Many authors have written scholarly books on the role of American home in society. These books place the home at the center of many societal reforms, including the women’s movement and the settlement house movement. Gwendolyn Wright’s Building the Dream: A Social History of Housing in America chronicles the American domestic environment as it evolves from the earliest colonial architecture through urban renewal schemes and mass-development projects. Wright links thirteen different kinds of dwellings to architectural and ideological models that play an important role in the development of American society and common culture. David Handlin’s The American Home: Architecture and Society, 1815-1915 analyzes the diverse impacts of the home on the development of early American society and 
popular culture. Handlin, an architect and teacher, begins with the Colonial period; and presents the role of Andrew Jackson Downing on the form of American homes as well as references to home in the writings of Walt Whitman and Henry David Thoreau. These books enrich our understanding of the home as they speak to the importance and relevance in a larger context.

Thus it is crucial that the technical ingenuity and industrial heritage of the American lumber industry is preserved before all remains are relegated to a museum and replaced by new technology. While the production of modern engineered wood products has created a niche market within the industry, new modified and augmented lumber released each year slowly replace their predecessors that contain only wood. Historians, documentarians and preservationists must soon act to record this stalwart of American manufacturing before the lumber industry ceases to exist altogether."

## [Growth of the Lumber Industry](http://mshistorynow.mdah.state.ms.us/articles/171/growth-of-the-lumber-industry-1840-to-%091930) ##
"Mississippi’s abundant virgin forest had long been a natural resource for American Indians. And to the early 19th-century settlers from Europe and America’s east coast, the softwoods and hardwoods provided material for building homes, furniture, farm implements, and tools. Even so, settlers considered the millions of acres of forests as little more than obstacles to be removed in order to start developing farms.

The few people who lived in South Mississippi’s pineland before 1840, for example, made their living by hunting and trapping, and later by raising cattle and hogs. By the 1840s, a few small mills for sawing logs had been built along the Mississippi Gulf Coast. The sawmills were located near the mouths of major rivers and streams at locations such as Pearlington and Logtown along the Pearl River, Moss Point on the Escatawpa and Pascagoula rivers, and Handsboro on the banks of Bayou Bernard near present-day Gulfport."

"These early mills depended on water transportation to ship logs to the mills. Loggers cut trees along the banks of streams. They then tied the logs together to form rafts that were then floated downstream to sawmills at the mouths of coastal rivers."


"But it was the building of railroads in Mississippi in the last quarter of the 19th-century that had the greatest impact on the timber industry. Railroads made it possible to build the large sawmills that dominated the industry by the early 1900s. The significance of railroads to loggers can be seen in the following statistics: In 1880, 295 sawmills had a total investment of less than one million dollars. Nearly twenty years later, in 1899, a capital investment of $10 million in 608 mills produced more than one billion board feet of lumber (a board foot is the equivalent of a board one foot by one foot by one inch).

The thriving timber industry during the 1904 to 1915 period ranked Mississippi in third place of lumber-producing states in the United States, behind Washington and Louisiana. In 1910, capital investment reached more than $39 million and the value of production climbed to nearly $43 million. Much of the total production was long-leaf yellow pine from the southern half of the state. In addition, many hardwood mills operated in the Delta region, and the east-central area of the state produced short-leaf pine."

"Sawmills depended on the railroads to ship finished lumber to growing markets in the north. Also, ports like Gulfport sprang up expanding the export lumber trade with foreign countries. Several railroads, such as the New Orleans and Northeastern Railroad, the Mobile, Jackson and Kansas City Railroad, and the Gulf and Ship Island Railroad, were built across South Mississippi.

Not only did railroads provide an outlet for finished products, they also opened up great areas of previously inaccessible timberland to lumber companies. As timber near the navigable streams was rapidly depleted, railroads provided mills a way to bring in logs that were far from rivers and streams.

Thus, many mills built their own rail lines into their timberlands. These rail lines, often called dummy lines, varied in length from mile-long railroads built with wooden rails to extensive railroads with steel rails that reached thirty or more miles into the virgin forests. By 1905, most sawmills cutting more than 25,000 board feet per day owned their own railroads.

Many towns and cities in Mississippi owe their existence to the railroads and sawmills built during the lumber boom. Typically, after a railroad was built, land buyers purchased timberland in the area and built sawmills. Towns quickly grew up around the sawmills. Many towns seemed to appear magically out of nowhere. Some of the towns became cities that still exist today — Hattiesburg, Laurel, Picayune, and Wiggins. Other towns — Inda, Howison, Hillsdale, Orvisburg, Deemer, and Electric Mills — quickly died after the mills closed.

Labor-saving equipment introduced soon after the turn of the century joined with railroads to spur growth. By 1905, the ancient caralog, a heavy ox-driven two-wheeled wagon, was replaced by the Lindsey Eight-Wheel Wagon invented by the Lindsey brothers of Laurel, Mississippi. In turn the skidder and steam log loader replaced the eight-wheel wagon. Skidders were huge winches with long cables. These cables were attached to logs, and the winches dragged them to the railhead. Such mechanizations cut logging costs and allowed for year-round operations."

## [Hodge-Hunt Manufacturing & Hunt Lumber Co. Story (1938-1972)](http://huntfamilyhistory.com/wpd/?page_id=1151) ##


----------


# Trucking, Industrialization, Automation, Industry Shift and Computers #
## [Trucking and Automation](https://www.usatoday.com/story/opinion/2017/06/20/rigged-system-rips-off-port-truckers-editorials-debates/103015290/) ##
"Many U.S. consumers care deeply about the way their products are made. Some insist on buying American; others press corporations for codes of conduct that forbid sweatshops in foreign lands.

"But what many might not know is that some highly deplorable conditions exist right here in America, in the transport of goods rather than their manufacture.

A huge volume of the nation's imports arrive by container ship in Southern California, where short-haul truckers take the merchandise to nearby rail yards or storage depots, a key step in the goods' journey to some of the nation's leading retail stores. A year-long investigation by the USA TODAY Network found that a good chunk of the port trucking industry relies heavily on a modern-day form of indentured servitude.

The abuse starts when a trucking company pressures its drivers to sign lease-to-own contracts on their tractor-trailer rigs. Often, these drivers speak little English and do not understand what they are getting into."


"Network reporter Brett Murphy documented hundreds of cases like this at Los Angeles ports since 2010, including 1,150 instances in which drivers had filed formal complaints, 140 trucking companies that had been accused by at least one driver of shorting drivers on pay, and more than 120 cases in which drivers said they worked 12 to 20 hours at a time, in violation of federal highway safety laws."


"Federal law has numerous workplace protections, but only for employees. The trucking companies at the Port of Los Angeles classify their drivers, incorrectly in many cases, as independent contractors rather than employees."


"If a category of worker is to exist outside of the Fair Labor Standards Act and other workplace protection laws, Congress needs to either delegate workplace authority to the states, or set minimum standards to protect contract workers against exploitation."


"The industry points to a study stating that drivers like being independent contractors. But the study is commissioned by the industry, uses data not available to outsiders, and includes long-haul drivers as well as the port truckers who are the subject of so much abuse."


## [Review: The Big Rig: Trucking and the Decline of the American Dream](https://www.labornotes.org/blogs/2017/10/review-big-rig-trucking-and-decline-american-dream) ##
"Truck drivers seem to have re-entered the public consciousness in 2017—but today our understanding of the occupation is far from the freewheeling “cowboy of the highway” image of the 1970s. It’s also no longer synonymous with “Teamster” or even seen as a desirable job.

These days most talk about truckers centers on self-driving vehicles and the prospect that more than three million professional drivers will be replaced by robots. Business writers excitedly write about how this “cost-saving” technology lies just around the corner, only briefly pausing to consider the social crisis that would be created by laying off so many workers.

As a truck driver myself, I know that so much of what we do is far too complicated to be replaced by technology any time soon. We do a lot more than just hold a steering wheel. We navigate city streets and highways that are perpetually “under construction,” deal with distracted drivers who spend more time looking at their phones than at the road, maneuver impossibly narrow spaces to make deliveries, and back trailers up to dock doors, sometimes across traffic, with no room for error—and that's just what we do from the driver’s seat, not counting time for inspections, dropping and hooking, loading and unloading."


"As 27-year driver Greg Simmons says in a recent New York Times profile of long-haul truckers, “We’re throwaway people. Nobody cares about us.” Simmons says he feels trapped in an occupation that no longer provides a decent living, thanks to corporate innovations like the pay-by-mile system, which doesn’t account for all the hours drivers get stuck in traffic or wait on trailers to be loaded or unloaded, a process that often takes hours.

For truckers at the ports who move goods from ships to warehouses, the situation is even worse. An in-depth USA Today report (June 20, 2017) exposed the terrible conditions faced by immigrants driving trucks at the ports of Los Angeles and Long Beach, describing their situation as “modern-day indentured servitude.”

Many port truckers are locked into lease agreements in which a large portion of their wages goes toward their truck and vehicle maintenance. Their bosses use these leasing agreements to force drivers into punishing schedules, threatening them with losing their truck (and forfeiting all the wages paid into the truck) if they refuse to work beyond the legal maximum hours or if they get sick and can't work. They are also often misclassified as “independent contractors,” depriving drivers of basic protections like overtime compensation, family and medical leave, and unemployment insurance."


"Deregulation, beginning with President Carter and continued by Ronald Reagan, did away with the federal permit system and encouraged thousands of new carriers to enter the industry. By dramatically increasing competition, both shipping prices and wages were driven down considerably. It became more affordable for shippers to use 'truckload' shipments, where a trailer is filled exclusively with one shipper’s freight and sent directly to its destination, instead of relying on the union-dense “less than truckload” terminals to move smaller shipments."


## [The Big Rig: Trucking and the Decline of the American Dream](https://www.ucpress.edu/book.php?isbn=9780520278127) ##
## [Alone on the Open Road: Truckers Feel Like ‘Throwaway People’](https://www.nytimes.com/2017/05/22/us/trucking-jobs.html) ##


## [Rigged](https://www.usatoday.com/pages/interactives/news/rigged-forced-into-debt-worked-past-exhaustion-left-with-nothing/) ##
"Most days, the trucker would drive more than 16 hours straight hauling LG dishwashers and Kumho tires to warehouses around Los Angeles, on their way to retail stores nationwide."


"He rarely went home to his family. At night, he crawled into the back of his cab and slept in the company parking lot."


"Talavera was a modern-day indentured servant. And there are hundreds, likely thousands more, still on the road, hauling containers for trucking companies that move goods for America’s most beloved retailers, from Costco to Target to Home Depot.

These port truckers -- many of them poor immigrants who speak little English -- are responsible for moving almost half of the nation’s container imports out of Los Angeles’ ports. They don't deliver goods to stores. Instead they drive them short distances to warehouses and rail yards, one small step on their journey to a store near you.

A yearlong investigation by the USA TODAY Network found that port trucking companies in southern California have spent the past decade forcing drivers to finance their own trucks by taking on debt they could not afford. Companies then used that debt as leverage to extract forced labor and trap drivers in jobs that left them destitute.

Using the contracts, submitted as evidence in labor complaints, and shipping manifests, reporters matched the trucking companies with the most labor violations to dozens of retail brands, including Target, Hewlett-Packard, Home Depot, Hasbro, J.Crew, UPS, Goodyear, Costco, Ralph Lauren and more.

This isn’t a case of a few bad trucking companies accused of mistreating a handful of workers.

Since 2010, at least 1,150 port truck drivers have filed claims in civil court or with the California Department of Industrial Relations’ enforcement arm, known as the labor commission."


"Prominent civil rights leader Julian Bond once called California port truckers the new black tenant farmers of the post-Civil War South. Sharecroppers from that era rented farmland to make their living and regularly fell into debt to their landlords. Widespread predatory practices made it nearly impossible for the farmers to climb out.

Through lease contracts, California’s port truckers face the same kinds of challenges in ways that experts say rarely happen in the U.S. today.

You’re working to get yourself out of the debt. You just don’t see anything like that.

Reporters tried to contact owners and managers at more than 30 trucking companies. Many did not respond or declined to comment."


"Retailers don't directly hire the truckers who move their goods at the pier. They generally hire large shipping or logistics firms that line up trucking companies through a maze of subcontractors."


"Truckers at dozens of companies describe the same basic scene. They were handed a lease-to-own contract by their employer and given a choice: Sign immediately or be fired. Many drivers who spoke little English said managers gave them no time to seek legal advice or even an interpreter to read the contract

Drivers gave their old trucks – many of which they owned outright – to their company as a down payment. And just like that they were up to $100,000 in debt to their own employer. The same guys would have had a tough time qualifying for a Hyundai days earlier."


"For years, Rene Flores regularly has driven 20 hours a day, six days a week, hauling pistachios and medical equipment into the desert from the Port of Long Beach.

'If I don’t work,” Flores says, “my kids will starve.'

He keeps a log book of fake hours in the glovebox and the real one hidden beneath his seat in case of a surprise inspection."


----------


# Egypt #
## [Agriculture and Farming in Egypt](http://www.fao.org/egypt/our-office/egypt-at-a-glance/en/) ##
"Historically Egypt has always seen itself as farming nation. Agriculture development is considered a duty of the state, as recently reaffirmed in the 2014 constitution. The Agriculture Sector provides livelihoods for 55 percent of the population and directly employs about 30 percent of the labour force. The sector accounts for about 20 percent of total exports and foreign exchange earnings. However, Egypt imports about 40 percent of its food requirements and incurs a total food import bill of USD2.5 billion per year."

## [Ancient Egyptian Agriculture]() ##
"Agriculture was the foundation of the ancient Egyptian economy and vital to the lives of the people of the land. Agricultural practices began in the Delta Region of northern Egypt and the fertile basin known as the Faiyum in the Predynastic Period in Egypt (c. 6000 - c. 3150 BCE), but there is evidence of agricultural use and overuse of the land dating back to 8000 BCE.

Egyptologist and historian Margaret Bunson defines ancient Egyptian agriculture as "the science and practice of the ancient Egyptians from predynastic times that enabled them to transform an expanse of semiarid land into rich fields after each inundation of the Nile" (4). In this, she is referring to the yearly flooding of the Nile River which rose over its banks to deposit nutrient-rich soil on the land, allowing for the cultivation of crops. Without the inundation, Egyptian culture could not have taken hold in the Nile River Valley and their civilization would never have been established. So important was the Nile flood that scholars believe many, if not most, of the best known Egyptian myths are linked to, or directly inspired by, this event. The story of the death and resurrection of the god Osiris, for example, is thought to have initially been an allegory for the life-giving inundation of the Nile, and numerous gods throughout Egypt's history are directly or indirectly linked to the river's flood.   

So fertile were the fields of Egypt that, in a good season, they produced enough food to feed every person in the country abundantly for a year and still have surplus, which was stored in state-owned granaries and used in trade or saved for leaner times. A bad growing season was always the result of a shallow inundation by the Nile, no matter the amount of rainfall or what other factors came into play.

The yearly inundation was the most important aspect of Egyptian agriculture, but the people obviously still needed to work the land. Fields had to be plowed and seed sown and water moved to different areas, which led to the invention of the ox-drawn plow and improvements in irrigation. The ox-drawn plow was designed in two gauges: heavy and light. The heavy plow went first and cut the furrows while the lighter plow came behind turning up the earth. 

Once the field was plowed, then workers with hoes broke up the clumps of soil and sowed the rows with seed. These hoes were made of wood and were short-handled (most likely because wood was scarce in Egypt and so wooden products were expensive) and so to work with them was extremely labor-intensive. A farmer could expect to spend most of a day literally bent over the hoe.
Once the ground was broken and the clods dispersed, seed was carried to the field in baskets and workers filled smaller baskets or sacks from these larger containers. The most common means of sowing the earth was to carry a basket in one arm while flinging the seed with the other hand. 

Some farmers were able to afford the luxury of a large basket one attached to the chest by hemp straps which enabled one to use two hands in sowing. To press the seed into the furrows, livestock was driven across the field and the furrows were then closed by workers with hoes. All of this work would have been for nothing, however, if the seeds were denied sufficient water and so regular irrigation of the land was extremely important.

Egyptian irrigation techniques were so effective they were implemented by the cultures of Greece and Rome. New irrigation methods were introduced during the Second Intermediate Period of Egypt (c. 1782 - c.1570 BCE) by the people known as the Hyksos, who settled in Avaris in Lower Egypt and the Egyptians would further improve upon these techniques, such the expanded use of the canal. The yearly inundation of the Nile was essential to Egyptian life, but irrigation canals were necessary to carry water to outlying farms and villages as well as to maintain even saturation of crops near the river.

Egyptologist Barbara Watterson notes how the Delta Region of Lower Egypt was far more fertile than the fields of Upper Egypt toward the south and so "the Upper Egyptian farmer had to be inventive and, at an early date, learned to cooperate with his neighbours in harnessing the river water through the building of irrigation canals and drainage ditches" (40).

These canals were carefully engineered to efficiently water the fields but, most importantly, not to interfere with anyone else's crops or canals. This aspect of canal construction was so important that it was included in the Negative Confession, the proclamation a soul would make after death when it stood in judgment. Among the Confessions are numbers 33 and 34 in which the soul claims it has never obstructed water in another's canal and has never cut into someone else's canal illegally. After receiving permission to dig a canal, estate owners and farmers were responsible for the proper construction and maintenance of it. Bunson writes:"


----------


## [Dissect](https://dissectpodcast.com) ##


----------


# Nashville, Tennesse - the Old West, the South #
## Nashville Country Music - Southern, and Western ##


----------


# Victorian Era Influences #
## [Victorian Era: Impressions and Privacy](http://design243.blogspot.com/2009/09/victorian-era-impressions-and-privacy.html) ##
"During the Victorian Era many new technologies and methods were developing allowing for more people to have access to fine furnishings. With several specializations developing in furniture design house plans changed to allow for more rooms, because people could now afford to fill them. Like “Ames” said, much of the design of the front of the house was based on first impressions. Houses developed to allow the host family to keep their guests in the front entertaining rooms and have their private living quarters hidden from view upstairs.

Many houses had what was called a front hall where guest were first received, here much consideration was given to the furnishings. The larger and more expensive your hallstand and other furnishings, the higher your social standing would seem to the guest who enter your house. The Victorians perfected the concept of controlling the first impression.

 What guests had access to was changing, the family now had some control over what other people thought when they came to visit. These new ideas on the importance of first impressions allowed for the development in the concept of privacy. Rooms could now be entered independently, you no longer had to travel through one room to the next, invading the privacy of the occupants along the way. Families could now afford for everyone to have their own bedrooms were they could go to escape in quite. They were no longer forced to all sleep in the same room.

 Having visitors became a more common occurrence. As privacy became more of a need then a luxury, designers started to incorporate it into their programming. Dumbwaiters were developed so waiters wouldn’t interrupt a private conversation, back staircases were added so the servants could move around undetected to perform their duties. Victorians at the time were very concerned with what others thought of them and didn’t want to be seem as poor or unable to afford the luxuries. People would sometimes splurge to decorate their front halls and parlors more elaborately then the rest of their houses. You might even say some people still do this today when they buy a fancy sports car they only use for work, or buy designer clothing with large obvious labels to show others what they can afford.

Was the development of privacy a much needed development or was it one of the main contribution factors to the deterioration of family structure? And did this obsession with first impressions stimulate consumerism or was it the other way around, and how can these values be seen in todays culture?


I believe that privacy was a much needed development. Privacy is something everyone needs in their lives. You wanted your alone time where no one else is around or is listening. Before the introduction of the corridor or the back stair wells for servants they were always in your business. They were constantly walking through your room and listening in on your private conversations. I think the development of privacy didn't lead to the deterioration of family. Every family needs time alone once in a while. The older kids need their own rooms separate from the younger kids and the parents need their own area no where near the company or children in the house. I think that privacy was probably the best thing that came from this time period. 

I believe that consumerism stimulated the obsession of the first impression. If all these new technologies that created all these new products were never thought of people weren't be obsessed with buying things. I believe that it was people's obsessions with buying items to make them happy is what led to the first impression fad. If people were constantly trying to out buy each other to look richer and better than everyone else then no one would have cared about first impressions. If people were so consumed in buying products we would never have to worry about what we or our houses look like. 

People in today's culture are obsessed with looks and how others perceive them. People will spend $500 on jeans, $300 on a new top, $200 on shoes and most of the time spend $200 or $300 on their hair styles. Why is this? To make people like them and think that they are very rich. Every time you walk out of the door no matter who you are are thinking about how you look and how others will perceive you. Just as the Victorians cared about their front halls that is still very relevant in today's culture. People will make sure that they have an amazing chandelier, staircase, or piece of art in their front halls to impress people as soon as they walk in. In today's world its not just the front hall as it was in the Victorian times its the whole house. Your kitchen has to have the newest and best appliances to give a good impression. You have to have media rooms, bars, billiards rooms, and lounge areas if you want to be considered top of society. People will always be judging each other from here to the end of the time probably all thanks to the Victorians.


Like many things in the Victorian time period, I believe the development of private rooms was a result of the Industrial Revolution. The main factor that allowed the Industrial Revolution to be a success was the specialization of products. Now, in the Victorian time, we have taken the same concept of specialization and applied it to our homes. There is a place for the books in the library, a place for sleeping in the bed room, and a place for greeting people in the front hall. Because of this specialization of space I believe people began to get protective of their space, thus leading to privacy. The more opportunity you have to be alone allows you to do things that would otherwise be judged by the public. And as we all know, the Victorian age was all about how other people perceived you. So in short, I believe privacy was a much needed specialization of the Victorian age to give people a chance to escape for the public’s opinion. However, I don’t see a relation between privacy and the family structure. I believe the family structure at the time was carried out based on how the people believed society should act. This can be seen in the women exchanging two cards for her husband.
From my understanding of the Victorian time period, a family’s wealth wasn’t perceived based upon what name brand of furniture they had, but rather how much. Regardless of the name brand Victorians want to own as much as they could. However, products were often bought that were conceived to be used by the wealthy. So in a sense I believe you could call this the beginning of modern day consumerism, but products were purchased based upon their decorative perception, not the name of the producer. This is much like buying a fake Rolex watch today, it looks good and accomplishes the impression, but the name of the producer doesn’t matter.
Though time has elapsed we are still as concerned about impression today as we were in the Victorian time period. Regardless, of how we convey them, through clothes, jewelry, cars, cell phone or our home, we all own something that makes us feel as though we belong to a high class. Today, high society is associated with names like Ferrari or Dolce and Gubbana so more than likely we try to own these items or something close to them. Much like Victorian times, we still strive to make a good first impression.


I agree with Kaitlyn in her view that privacy was a much-needed development, I don’t know how I would have survived high school without a bedroom door to shut and lock. There’s got to be something mentally healthy about having a moderate dose of “me time” now and then. I don’t think it’s impossible to have a close-knit family in this day and age without sleeping all together in a room either. Kitchens and dining rooms still have tables for the entire family to eat together. Living rooms still have plenty of room and comfy seating for family game night or watching a movie all together. So no, I don’t necessarily feel it was a major contributing factor to the deterioration of families. I do, however think that this time period furthered a phenomena from the Industrial Revolution that did begin a breakdown of the family bond. I feel the technological advances, leading up to today’s I-pods and I-phones, and X-boxes (weird how they all start with a single letter), alongside a newfound obsession with material culture, topped off by fads of impersonal communication like calling cards all made large contributions. I myself am guilty of allowing technology to separate me from time to time. I take advantage of e-mail and text, when there’s a time crunch to make a phone call. I plug up my ears immediately when hopping into the car for a long trip with the family. I text my friends during family functions, at least for a while. Once I get the eye from my Dad, I know I’m caught and it’s in my best interest to cease immediately. I think to a certain extent too that the selfish desire to accumulate material things and achieve status has allowed some family members to lose sight of what’s important when trying to keep a family close and strong. Parents may work more hours more often, putting work deadlines and events before soccer games and school plays. 

In response to the other part of the question stated, I think it was consumerism that stimulated an obsession with first impressions. Before the birth of the middle class, and the ability to climb ladders of social and economic status, individuals didn’t worry much about impressing people with their front hall, both because they probably didn’t have one, and because they had nothing with which to fill it. The more opportunities presented to consume, the more people of that time felt they should get to consuming! 

It seems this era may have birthed the ever-present mantra “keeping up with the Jones’s.” And just like back then, people today feel the need to spend the excessive amount of money they may or may not be making on presentation. If one only had enough money to either make the inside of their home comfortable or the outside presentable, I have no doubt most people would choose to spend on the outside. In this way Americans today resemble the Victorian people who chose to make their front hallways extravagant, while other more utilitarian areas of the house may possess the bare minimum


It seems so bizarre to me that the notion of privacy is fairly new. It seems like such a basic fact of our lives. Like Kaitlyn and Clay, I can't imagine not having my privacy.

It is interesting to me that privacy emerges during a time of rigorous rules of social etiquette. It makes me wonder if there is a correlation in that social rules helped privacy come about. For example, that it was socially acceptible to have a servant lie about whether or not you are home seems really weird to me, but it is a rule of social etiquette that protects privacy. As weird as this practice seems, upon further reflection I see a parallel between screening guests and todays version: screening telephone calls using Caller ID. I am admittedly a screener. Maybe I'm Victorian after all. Hmmm...

I, too, see a correlation between today's consumerism/materialism and that of Victorian times. It makes me wonder if some 100 years into the future, when environmental concerns outweigh convenience in our priorities, people will look back on our era with the same negative associations we attribute to the Victorian time period. 

Back on the subject of privacy for a minute, the notion that privacy has not always been a part of people's lives was kind of revolutionary one to me. I did not know that this was the case. It makes me think of the raging debate about whether the right to privacy exists within the Constitution of the United States in a slightly different light. And yes, I am talking about Pro-Life/Pro-Choice, but also about Internet Security issues, HIPAA Regulations, and the Patriot Act. It makes sense to me now that OF COURSE there is no expicit right to privacy in the Constitution, it was not something that would have occurred to the Framers. The question, then, becomes whether our rights under the constitution are limited to those specifically enumerated, or whether there are rights implicit based on the spirit of the Constitution. For that answer, I guess it depends on whether you are a strict constitutionalist or an originalist. In the interest of not igniting a big political discussion, I won't tell you which side I come down on, but I think it is some interesting food for thought.


Impression management that started during the Victorian period directly correlates to the phrase, “my home is a reflection of me”. During the Victorian period, the home reflected not only the values of individuals but of the society as a whole. What started then, still holds true today….only the values of the society as a whole, have changed. The Industrial Revolution shaped the values that emerged during the Victorian period. The newly rich people really valued possessions (what Casey referred to as, consumerism) because they had never had so many possessions before. Thus the Industrial Revolution led to a society that valued excesses, and that judged others on the basis of how much they possessed. Victorian homes reflect these values. However, societal values have shifted now, to technology. As, Katilyn pointed out, we are now judged by having hi-tech appliances, media rooms and flat screen TVs in our homes. Our homes still reflect who we are. Orkut and Facebook are great examples of impression management through technology. 

The first seedlings of individualism were sown during the Victorian period, with the concept of privacy. I strongly believe that privacy was a much needed development. Coming from India, I have great value for privacy, since I have experienced the lack of it after I got married. Having lived in the US for eight years now, I cannot imagine my life, without having “my own time”, watching TV, sipping a cup of tea and surfing the internet. It might sound culturally rude or unacceptable to “some” Indian families that are still very traditional, believing that married women in the family have no private time (not only private time with husband but also, downtime) at all. If I were in India today, the only time I would retreat to my room would be late at night, after fulfilling all my duties (or “etiquettes” is a better word here, since it involves watching TV shows that everyone else is watching at night *rolling my eyes*). However, I am glad that culture in India has changed a lot, majority of families have fewer privacy issues.

I do not think that the notion of privacy led to the deterioration of the family structure. Yes, it did make us more individualistic, but I see this kind of individualism as a positive development. The deterioration of the family structure, I think was caused by several complex and interrelated issues, which are beyond the scope of this discussion."


----------


# Relationships #
## [The True Nature of Love](https://codependentrecoveryexpert.wordpress.com) ##
"Starting to discern the difference between a codependent relationship and a healthy relationship helped me to start seeing the concepts of romance and love with more clarity – helped me start to understand the difference between a healthy interdependent relationship and a dysfunctional, codependent relationship.

“Codependence and interdependence are two very different dynamics.

Codependence is about giving away power over our self-esteem. Taking our self-definition and self-worth from outside or external sources is dysfunctional because it causes us to give power over how we feel about ourselves to people and forces which we cannot control. Any time that we give power over our self-esteem to something outside of ourselves we are making that person or thing our higher power. We are worshiping false gods.

. . . . . . . . Interdependence is about making allies, forming partnerships. It is about forming connections with other beings. Interdependence means that we give someone else some power over our welfare and our feelings.” – Codependence vs Interdependence – healthy relationship vs dysfunctional

One of the core components of Codependency is black and white thinking.  For this reason it is possible to quit drinking and using without being in recovery from codependency – because to drinking and/or using is an “either or” “black or white” issue.  Life is not black and white.  Issues with food, spending, relationships, etc. are not black and white.  These issues exist in the gray area of life.  What we are seeking is balance – and in order to find balance we need to learn to practice discernment."

"One of the core components of Codependency is black and white thinking.  For this reason it is possible to quit drinking and using without being in recovery from codependency – because to drinking and/or using is an “either or” “black or white” issue.  Life is not black and white.  Issues with food, spending, relationships, etc. are not black and white.  These issues exist in the gray area of life.  What we are seeking is balance – and in order to find balance we need to learn to practice discernment."

## [Codependepency](https://codependentrecoveryexpert.wordpress.com/tag/dysfunctional-codependent-culture/) ##
"We are attracted to people that feel familiar on an energetic level – which means (until we start clearing our emotional process) people that emotionally / vibrationally feel like our parents did when we were very little kids.  At a certain point in my process I realized that if I met a woman who felt like my soul mate, that the chances were pretty huge that she was one more unavailable woman that fit my pattern of being attracted to someone who would reinforce the message that I wasn’t good enough, that I was unlovable.  Until we start releasing the hurt, sadness, rage, shame, terror – the emotional grief energy – from our childhoods we will keep having dysfunctional relationships.”

We keep repeating patterns in an attempt to earn the love we are so starved for – on some level the little child within us is still trying to earn our parents love.  We are still trying to prove we are lovable by winning the love of someone who resonates as being similar to our parents.  Until we start learning to be discerning so that we can separate the child’s emotional truth from our adult reality, we keep looking for love in all the wrong places and wrong faces.  Until we start seeing life in a spiritual context that allows us to start understanding our powerlessness and forgiving ourselves for the “bad” choices / “mistakes” we have made in our adult relationship choices, we are blocked from Loving our self.  Discernment is necessary to start really owning our deep emotional pain from a perspective of having compassion for ourselves instead of shame and judgment.

I did not feel Loved in childhood because my parents were wounded – and because the concept of God that I was taught was a punishing one, the pain in my life felt like punishment. (The pain of life feels like punishment even to people who were taught a metaphysical, Loving concept of God in childhood, because the emotional experience of life does not match the metaphysical Truth.  Sometimes people who were taught about a Loving God in childhood have more trouble getting past their feelings of betrayal than someone who was raised in a shame based religion like I was.)  My inner radar caused me to be attracted to someone who felt on some emotionally energetic level like my parents.  The extremes of the spectrum that I experienced in childhood, dictated how I related to intimate relationships – to opening my heart to another human being.

For most of my adult life, I effectively had a relationship phobia.  The extremes I learned in childhood were completely unavailable (my father) and completely enmeshed (my mother.)  In my first sexually and emotionally intimate relationship (not any true emotional intimacy because I was incapable of it then – more accurate would be to call it emotional attachment) I got completely enmeshed with a woman I met in college.  She was the one who really initiated me into being sexual.  We got engaged to be married.  I caught her in bed with my best friend – literally, caught them in bed.

I realized in retrospect in recovery, that she had almost certainly been the victim of incest from a young age – and was a sex addict.  The pain of that experience, was to say the least, incredible.  I was so much in denial of my feelings, and so codependent, that I stayed engaged to her for another year and a half.

In Discernment 1, I mentioned that by learning discernment and peeling away the layers I was able to see the silver lining, to be grateful for, my relationship phobia – which means I came to see a silver lining to this betrayal I experienced in my early twenties.  What I realized is, that the combination of my alcoholism and the rage I was carrying towards my mother, would have made me powerless to not be abusive had I married this woman and started having kids.  I may have spent most of my adult life alone, but at least I didn’t have a family that I terrorized for those years.

Codependency is on a very simple level giving power over our feelings of self worth to external sources.  Learning to be discerning – to separate / draw boundaries in our perspective of – our issues, and the levels and layers of those issues, is vital in seeing our self and life with more clarity.   It vital in the process of learning to Love and to create the potential for having a healthy romantic relationship.

We need to start being discerning in relationship to the concepts of love and romance – and start taking action to change that programming before we start to have any chance of having a healthy relationship. 

One of the core components of Codependency is black and white thinking.  For this reason it is possible to quit drinking and using without being in recovery from codependency – because to drinking and/or using is an “either or” “black or white” issue.  Life is not black and white.  Issues with food, spending, relationships, etc. are not black and white.  These issues exist in the gray area of life.  What we are seeking is balance – and in order to find balance we need to learn to practice discernment.

The outer, and most obvious layers, have levels and layers in and of themselves, that need to be worked through to the core issues.   Each time I am at a point of needing to surrender to peeling another major layer, I get to revisit all of my old issues once more – because they are all interrelated and interconnected.   Each time my growth process takes me to a new level – I need to surrender in a major way – I attain a deeper level of honesty, a higher understanding of Truth.  So, my perspective of all of my other issues changes.

The term “old-soul” refers to the stage of consciousness evolution an individual has attained by this lifetime – it does not mean better than, or farther along than, those who do not have to do the healing. There is no hierarchy in the Truth of a Loving Great Spirit – those who appear to have low, or no, consciousness in this lifetime are simply doing their healing in another space-time illusion parallel to this one. All old-souls are born at a heart-chakra level of consciousness and therefore have more sensitivity, and less capacity for denial, than other people. In other words, the gift of having access to Truth and Love carries with it the price of greatly increased emotional sensitivity.”

## [“Chivalry” Then and Now](https://medieval.sunygeneseoenglish.org/2015/03/10/chivalry-then-and-now/) ##
"In the Middle Ages, Richard Abels explains in his NY Times article, chivalry was a code of conduct followed by the military nobility which called for them to have “skill in combat, courage and loyalty to one’s lord… [as well as] courtliness and medieval Christian values.” In modern times, “chivalry” has come to mean “‘gentlemanly’ behavior, manifested through courtesy toward the ‘fair sex’, honor, courage, loyalty, athletic prowess and fighting ‘fair'”; a definition Abels says stems from 18th century Romantics’ ideas of the Middle Ages. There is debate today over the concept’s appropriateness in a society that is striving to eliminate the idea of the “fairer sex” in order for women to achieve social, economic, and political equality. Some argue that chivalry only perpetuates the attitude that women are weak and inferior; while others say chivalry is synonymous with common courtesy, and that we need more of it in our increasingly self-centered world. The NY Times’ “Room For Debate” section online includes an introduction to this debate and a short post from each of the 6 debaters, including Abels. The main page can be found here: http://www.nytimes.com/roomfordebate/2013/07/30/can-chivalry-be-brought-back-to-life

## [Can Chivalry Be Brought Back to Life](Chivalry Is a Nod to Differences Between the Sexes) ##
"Many folks chafe at the idea of chivalry because it implies that women are weaker and more vulnerable than men and thus need special protection. It's sexism with a courteous hat tip, or so the argument goes.

Yet a few months ago Congress passed and the president signed (to great fanfare) an extension of the Violence Against Women Act, which allots federal funds to help fight violent crimes against women.

If we can have legislation that implies that men are (generally) physically stronger and women are (generally) more vulnerable and thus require federally mandated protection, is it really wrong, and could it not actually be beneficial, to have some social rituals that serve as a symbol and reminder of these differences between the sexes?

Small chivalrous acts like opening a door for a woman are symbolic ways for a man to signal that he recognizes that while men are physically stronger on a whole, he himself intends no harm. Chivalry is not about either the inferiority or the lofty superiority of women. Instead, it can foster mutual respect and remind us of our underlying biological differences and the complementary nature of the sexes. Some women will bear children, and some men will step up to be protectors should danger arise (see the boyfriends who took a bullet for their girlfriends during the Aurora shooting or the firefighters who rushed into the Twin Towers on 9/11). One need not oppose the strides toward equality we’ve taken to honestly acknowledge and appreciate this fact.

In a gender-neutral modern world, chivalric acts are non-onerous rituals that faintly echo our relationship to each other when all the layers of civilization are stripped away; they serve to remind us that we need and should respect, appreciate and quite frankly enjoy each other."

## [A Man's Gotta Do: Myth, Misogyny and Otherness in Post-9/11 America](https://etd.ohiolink.edu/apexprod/rws_etd/send_file/send?accession=bgsu1340022877&disposition=inline) ##
"In times of distress, the American man is provoked to act upon a narrative that is as old as the land on which he walks. It is a narrative that encompasses three essential elements: the hyper-masculinized hero, the helpless damsel in distress and the villain in the person of a Racial Other and that encourages man to act according to deeply rooted values, of honor, bravery and strength, against the threat. This myth however, supposes the removal of feminine agency which would threaten it, the rejection of all feminized aspects of society and the adoption of a misogynistic and nationalistic worldview. After the 9-11 attacks, this myth was called upon by a nation paralyzed with shock and fear. It rapidly caused a shift in public rhetoric and encouraged men to undertake heroic roles, while reconstructing the traditional femininity characterized by dependence and fragility. It identified a racial “other” which threatened femininity, the country, the American way of life itself and allowed men to act against them. Invisible, universal and timeless, the American myth continues to affect the everyday life and to influence the manner in which people think and act."

"9/11. September Eleventh. This date marks a time when the American people lost their innocence. For the first time since World War II the American homeland was under attack from outside forces and, for the first time, America had been unable to defend itself. Slightly more than a decade after the tragic events of that day, the time has come to reflect upon and to analyze the reaction to a national trauma. Ten years seems neither too short a time frame as to be callous in examining such a tragedy, nor too long as to have our worldview skewed by the historicity. We remain able to find relevant, objective and still fresh information regarding the subject by looking back now, and we are able to assess the aftermath of the event from a cultural point of view. Though creating an examination of the event in the immediate aftermath of the attacks would have (and indeed has) created a fascinating investigation, looking at the events as recent past offers the best methodology for carrying out a study of the kind I am proposing here, because it gives the researcher an opportunity to look dispassionately at the traumatic American moment, and the national response. It helps to give a distanced, even objective view of how the events of 9/11 coalesced into a cultural movement traversing multiple elements of American life. Examining this American moment retrospectively allows for a more nuanced and deeper understanding of the constant shifts and cultural changes that inevitably followed the event."

"One could argue that this cultural shift began the moment of the attacks, became clearly evident before the end of the attacks on September 11, and was arguably in full force no later than September 12. Though it is difficult to ascertain which came first, the shift in attitude by the citizenry or the same shift mediated by television personalities and politicians, what was clear is that a shift in cultural attitude did take place in response to the terrorist attacks, and interestingly that shift had less to do with politics or concepts of “national security” per se than it did with ideas of gender."

"More specifically this shift in cultural rhetoric was centered on the shared construction of individual, and by association national, masculine identity. Implicit in the discourse of masculine identity is, of course, feminine identity which is constructed both by contrast (i.e. what masculine is, feminine isn’t and vice versa) as well as through omission, that is to say through the symbolic annihilation of the feminine. This gendered construction of individualistic and nationalistic identity which was occurring in the cultural discourse arose on both large and small scales—taking place both in what we may refer to as mass and folk cultures— and built a masculine national ego, as Freud may have it."

"However, in order for this shift to take place, another set of qualities were required, one which would run counter to American-ness to a completely different set of cultural beliefs, wherein Americans are placed in a bipartite system where American-ness is diametrically opposed to a set of Cultural Others (e.g. those who would do us harm, those who do not agree with our policies, etc.). This, of course, is most evident in the case of militant Muslims in the immediate aftermath of the 9/11 terrorist attacks. Yet, soon after the attacks it became obvious that the category had come to encompass those who physically resembled the dominant American stereotype of 'Arabs' and, by extension, soon the entirety of the Muslim community. These ideas can also be extended in terms of the cultural Other. This rhetorical strategy creates an 'Us,' in this case a homogeneous national identity wherein the 'Us' acts as the faceless Hero within a national pseudo-narrative and is a representative embodiment of the ideals present in the then-contemporary American zeitgeist. This is opposed to an idea of 'Them,' an Other who is identified as the antithesis of the America-Hero type and represents the Antagonist.'"

"This rhetorical strategy is, of course, nothing new. Creating a hyper-masculine national identity and opposing that against an ideological Other is something that has been studied in several cultural contexts over the past fifty years, often in the context of a fear of miscegenation. Yet examining the American response to 9/11 retrospectively suggests that there was a rapid and radical shift in American ideology as a result of the terrorist attacks, because prior to the attacks this rhetoric was not evident and post-attack it clearly was. The speed at which this shift has taken place suggests to me that, in many respects, the ideological American worldviews, particularly in relation to gender and nationalism, have a default setting of sorts. That is to say the American conceptualization of identity formation that became evident after the terrorist attacks of 9/11 is not a reaction to the event per se, but instead something that has been ingrained into us culturally as a fall-back position to which we return in times of national distress."

"Remasculinization is 'a regeneration of the concepts, constructions, and definitions of masculinity in American culture and a restabilization of the gender system within and for which it is formulated.'"

"Myth - In his introduction to William Bascom’s “Forms of Folklore”, Alan Dundes asserts that: Nothing infuriates a folklorist more than to hear a colleague from an anthropology or literature department use the word myth loosely to refer to anything from an"

"obviously erroneous statement to an alleged “archetypal theme underlying a modern novel or poem"

"I mention this to note that my definition of myth for this thesis does not entirely fit within the confines of what may be considered a traditional folkloric study, and as a folklorist I must, to some degree, justify this. In the popular parlance myth has the connotation of error. “That is
just a myth!” is a common phrase in the contemporary vernacular that labels a story or statement as untrue. However, when I say myth I do not mean it in these terms; that is to say myth is not equivalent to false belief—myths are not necessarily untrue and untrue narratives or statements are not inherently myths. However, while myths may not necessarily imply false belief, myths always imply belief. Mircea Eliade, as quoted by Jack Zipes, tells us that “myth narrates a
sacred history” , while folklorist William Bascom writes that “myths are prose narratives which, in a society in which they are told, are considered to be truthful accounts of the remote past” . The very nature of a myth implies that they are contextually believed, and are told as true."

"In essence this available narrative is a metanarrative of sorts—one that disseminates the “story” of pioneers, frontiersmen and cowboys. It is a narrative that is predicated on what we can describe here as John Wayne masculinity and Doris Day femininity. It is a narrative where the man must protect his family from the barbarians at the gate—the wild Indian of the American frontier. It is a sacred narrative, regarded with awe and a type of secular reverence for the founders and settlers of the America of yesteryear. It is a narrative that reinvents and recontextualizes the American past for the American present and fundamentally explains how our world came to be in its current form.

The available narrative at the heart of the cultural reaction in the wake of 9/11 is less about the act of terrorism than it is about snapshots of the idealized American past—the earliest days of colonial America, the pioneers on the frontier roads traveling across the country, the cowboy heroes of West—all culminating in a variety of very specific ideological cultural beliefs. The American Myth, as I will be exploring it, is more a sacred process of understanding how the world and, by association, how we as individuals have come to be who and what we are in our present form."

"this mythology is essential to the American experience, and as such it speaks to the rapidity and ubiquity of its effect on the rhetoric, lifestyles and public worldviews of America in the post-9/11 condition."

the concept of “national myth”

"National myths must be unanimously accepted as part of the national spirit and important enough to be preserved and transmitted further. Most importantly, as mentioned above, they need to be believed.

I believe that it is safe to claim that an idealized version of the American past has become one such national myth. The colonizing and conquering of the West has been culturally retransmitted in an idealistic and mostly distorted manner, based on a simple narrative (the eternal fight between right and wrong and triumph of the first principle), utilizing a shared creation myth as its base."

"One of the most important myths shared within a culture is a creation myth. Whether this myth is focused on the physical creation of the world itself or the creation of man, people are always fascinated with their cultural origins and the beginning of their shared histories, particularly if the witnesses to the event are long gone, or there were none such witnesses whatsoever. By extension, the creation of new nations and new societies is often treated in the same vein as these sacred creation narratives."

"This religious behavior in respect to unknown lands continued, even in the West, down to the dawn of modem times. The Spanish and Portuguese conquistadores, discovering and conquering territories, took possession of them in the name of Jesus Christ. The raising of the Cross was who claim it) is a repetition of cosmogony, because it is still in a larval, initial state of chaos. He writes: equivalent to consecrating the country, hence in some sort to a 'new birth'.

Taking Eliade’s supposition as true, it seems safe to claim that the discovery, occupation and birth of America and American society (particularly the ideology of American Republican Democracy) has become a creation myth in and of itself, since the history of the events was denatured so as to correspond to a sacred narrative in which the colonists are the bearers of both civilization and religion, while the Indians, the cultural “Others,” needed to either be assimilated or annihilated.

a hyper-mediated society in which the individual may arguably be disconnected from direct links with his roots and myths would seem to have ceased to play an important role in his cultural environment.

However, ethnography is beyond the purview of this thesis. While examining multiple national traumas (such as Pearl Harbor, the Oklahoma City Bombings, or even various financial crises) could strengthen this analysis, such a project is beyond the scope of this study, but is one I hope to undertake in the future.

As years passed by, American culture evolved and the joined experience of the generations who shaped the country coalesced, through various authors, into the American myth. These myths were based in large part on narratives centered on the Indians wars, narratives which described the brutal fight for survival in a hostile environment, and reveled in the bravery

The men thus gave birth to a the myth of American creation, in which they occupied the central place as heroes in both a spiritual fight against the uncivilized Native devil-worshippers and a physical fight against untamed chaos represented by the barbarians and the land itself. This idealized man faced the cruel, uncivilized antagonist in the persona of the Indian and recreated a cosmogenesis by claiming and shaping a world, a new nation and a new future for human kind. He thus became an available archetypal hero within the American consciousness. From the first European landings in the New World, all men looked up to the qualities of these mythic ideals, forging the foundation for a myth predicated on pioneers of the frontier. Generation after generation this narrative of colonist as hero has been reimagined and reconstructed, reorganizing and re-envisioning their attributes, and their deeds, which are viewed as inherently masculine and ultimately heroic.

A critical analysis of the colonial period in American history raises several questions. Were settlers right to occupy the lands or did the natives have all the rights to defend it? Were the colonists driven by a sincere desire for transformation or did they have economic interests in relocating in the Americas? These questions suggest that the narrative of the American mythogenesis is far more complex than simply the narrative presented of the heroic colonist. The myth however, simplifies it by distorting the reality and transforming it in a simple, heroic story, in which the White European male figure stands in the center."

Narratively speaking, the image of the American settler was soon reimagined and transformed into the figure of the American cowboy. Based on the experiences of the first colonists and driving the concept of the American masculinity even further, the image of the confident, solitary cowboy who works, fights and adventures into the wilderness with no fear and no regret is, in some ways, an even more powerful interpretation of the same paradigmatic structure. Guided by this image, American men started to refer to the brutal attitude of cowboys as a standard of masculinity. President Roosevelt himself 'promoted the appreciation of the ‘rougher, manlier virtues’ in traditions such as rough-hewn cowboy and frontier songs, wildlife hunts and boxing matches' Furthermore, Simon Bronner argued that:

The folktype of the cowboy is recognized internationally as an American representation of a manly man and contributes to the normative or some may say, 'mainstream', construction of American masculinity, characterized by independent, competitive and aggressive behaviors and outward signs of physical 

Yet, as with the life and times of the colonial hero, the truth of the matter was far more complex that the narrative allows. Life in the West from a mythic standpoint was largely based on a romanticized version of the cowboys’ lives. In truth, the life of the American cowboy was dominated by labor and isolation. However, there remains an element of truth to the hyper- masculine, overtly sexualized cowboy character in the American mythos. Functionally a cowboy needed to have a certain amount of physical conditioning in order to be able to fulfill his duties, which led to the hard bodied stereotype that will be discussed in more detail momentarily. Their job necessitated a certain amount of isolation, where they were often alone in the wilderness, far from any contact with anyone, particularly women. According to Blake Allmendinger, their work conditions were imposed by the ranchers who preferred, in the nineteenth century, bachelors to family men. Single men had no obligations and could be sent on several months- long cattle drives far away from any human community. Furthermore, they needed lower wages and would often live together in bunkhouses."

8 Ibid, xiii
9 Blake Allmendinger. The Cowboy: Representations of Labor in an American Work Culture (New York: Oxford UP, 1992), 6.
dominance, and social ganging.
The image of the cowboy as the ideal American male crosses borders in the guise of the Western, and was key to the continued dissemination of the ideologies inherent in the American myth.

However, as opposed to being hyper-masculine, Allmendinger defines cowboys’ situation as a sort of symbolic castration, correlating their activity of castrating bull calves with their own situation: Geographically isolated and socially cut off, unmarried cowboys were temporarily and metaphorically castrated in that they were forced to abstain from engaging in relations with women for great lengths of time. They were hired because they were already unattached, deprived single men, and they were forced to stay that way or risk being fired for moving to town, getting married and fathering character of the American myth. In examining this seeming paradox, Anthony Easthope applies masculinity theories proposed by French psychoanalyst Jacques Lacan because, as the author explains, Lacan’s theory of castration sees it as a 'more radical symbolic event.' According to Easthope, 'the castration complex is an idea or meaning that arises in the gap between the two sexes, as the masculine which is not feminine and feminine not masculine. The masculine myth aims to reconstruct castration on its own grounds.' This paradigm of renegotiating castration as masculine may seem antithetical to the masculine cowboy myth; however it is key to the way Americans are able to reconstruct their identities when culturally emasculated.

Indeed, the castration myth can be more literally interpreted as a fear of being considered a castrated worker because of the restriction from female contact and sexual encounters. Being eager to reaffirm their masculinity, cowboys would often eat the testicles of a bull after castrating

Reading the cowboy as symbolically castrated male offers a subversive reading to the character of the American myth."

"Being eager to reaffirm their masculinity, cowboys would often eat the testicles of a bull after castrating
10 Ibid, 6.
11 Antony Easthope. What a Man's Gotta Do: the Masculine Myth in Popular Culture (New York: Routledge, 1992), 109.
12 Ibid, 165.
offspring.
Reading the cowboy as symbolically castrated male offers a subversive reading to the
16
 
17 it. This ritual centered on consuming the bull’s sexual organs was meant to enhance their virility
13 and to increase their sexual potency.
themselves and were not shared with “non-masculine” or effeminate men, a group formed by men such as the cooks, and ethnic ranch hands. This remasculinization process, like others to be discussed later, was predicated in violence or the threat of violence. What made castrated testicles so desirable was the danger involved in the castration of the calf, an activity in which masculine men, like the cooks, did not participate

The cowboys’ contact with women often was limited to the visits they paid to the brothels and local prostitutes when they entered cowtowns on their free days. According to Allmendinger, cowboys were seen as unscrupulous and often dangerous, particularly to the virtue of women, often resulting in people attempting to “shield” their women from cowboys who represented a threat to their decency.

Interestingly there is a disconnect between the remasculanization narrative of the cowboy and the heroic cowboy presented in the Western genre. The available narrative, which is later disseminated through literature and film, presents the cowboy as a mythical hero with countless attributes, among which honor and virtue were not lacking. It is the paradigmatic structures of this complicated narrative, informed as it was by the colonial myth, that would lay the foundation for a general myth of American masculinity that has come to be the dominant available narrative in American cultural discourses.

attacks of September 11th 2001 were a semiotic cultural castration, (not unlike that of the cowboy) of America at the hands of “Our Enemies,” it is still possible to understand 9/11 as an attack on American Manhood. Indeed, it is possible to see all times of national distress in American history, be they martial, natural or financial, as a siege on the masculine American identity. This is because much of American imagined identity is tied to the concept of American imagined masculinity due to the patriarchal influence that is the foundation for much of American sociological and ideological constructions, as shown previously in the examples of the colonial and cowboy heroes. Indeed, “human traits are [often] ascribed to the nation to put forth a certain image of what it is or should be.”16 To clarify, by imagined masculinity I mean “the set of images, values, interests and activities held important to a successful achievement of male adulthood”17 in America, and this shared conceptualization of the masculine informs and reinforces the patriarchy. For my purposes here, the patriarchy is the “manifestation and institutionalization of male dominance over women and children in the family and the extension of male dominance ... in society. [Patriarchy] implies that men hold power in all the important institutions of society.”18 The structures of a patriarchal hegemony, and so of masculine identity, have never truly been absent from American politics or cultural identity and so a threat to America, be it literal or figurative, is implicitly a threat on American masculinity. In times of
the national crises, such as the terrorist attacks of September 11 , there is implicitly a crisis in masculine identity, one that is met by a perceived necessary reaction to prove manhood on an individual and national level. This allows the male identity of the country to be regenerated, renegotiated, and reclaimed through historical mythopoeic modalities in face of outward threats, the foundations of which are evident in the colonial and cowboy hero types previously discussed.

the concept of “nation” in the shared social imaginary creates camaraderie through the implicit belief in deep horizontal relationships.

This constructed relationship wherein a chosen patriarch leads a national family creates a masculine authority to which we turn in times of national need. When a threat emerges, be it on a small scale or large, this becomes a threat to the “whole family” and necessitates a response by the Patriarch-in-Chief. A threat to the family is implicitly a threat to the father as we have culturally deemed the father the familial protector. Indeed, when the American President is elected, Robin Lakeoff suggests that we elect more than just a leader and a father figure; she says “[Americans] act modern, cool and sophisticated, but underneath, we want a daddy, a king, a god, a hero. We'll take the heel if we can get Achilles, a champion who will carry that lance and that sword into the field and fight for us.”21 However this relationship is, again, more complicated than it seems. The heroic Achilles-like father figure we adopt is problematized by the fact that American politicians are not, in fact, warriors. This is rectified through the President’s relationship as Commander-in-Chief of the U.S. Armed Services. As such our political leaders gain a certain amount of masculine rectitude by appropriating the masculinity of the American military. There is a certain amount of compensation present in this portrayal of the political structures of American national identity. R.W. Connell writes that “true masculinity is almost always thought to proceed from men’s bodies—to be inherent in a male body or to

I would modify her assertion to state that traditional masculine modes require the exclusion of feminine agency. That is to say women physically can, and indeed must, be present in traditional modes of manhood. In this form of masculinity the female is presented as antithetical to the male, so masculinity is conceptualized as directly oppositional to femininity. It is only through this juxtaposition of male and female that masculinity can be constructed, after which women—and their associated traits—are removed as agent. This removal of agency
29 forces women to be, as Laura Mulvey would put it, the bearers, not makers, of meaning. short, visible hegemonic masculinity may be best described as a culturally conceived identity created through the juxtapositional exclusion or domination of the feminine as agent. In part it is this comparative and hyper-masculine modality that allows for the reclamation of American male

To “imagine a way out of the darkness,” as Faludi puts it, necessitates the reestablishment of an immediately recognizable masculine ideology that is grounded in a sense of historical cultural normalcy. Yet, to be clear, this recognizable narrative is not predicated upon what we would call actual history. History alone is not enough to allow a nation to rebuild ideologies from chaos; history “can explain the present in terms of the past but it cannot provide an indication of how to act in the present based on the past, since by definition the past is categorically different from the present. Myths however, can use the setting of the past to create and resolve conflicts of the present.”32 This reestablishing of normalcy from a pseudo-historical mythogenesis occurs in multiple ways, including an amplified form of the cultural “father” ideology, and a hyper-exclusionary rhetoric surrounding women, yet it is arguable that both of these previously mentioned approaches are couched in another form of cultural affirmation, primarily that “[t]he means by which normalcy can be affirmed and protected is through violence.”33

"By affirming and protecting normalcy through violence on a cultural scale in the national zeitgeist I do not mean to suggest that a purely physical form of violence is necessarily thrust into the limelight, though this too does occur. There also exists the presence and reappropriation of violent rhetoric that is used on a massive scale ranging from the official (political), to the mass (popular texts), to the folk (individuals and small groups). The concept of a rhetorical reimagining and reclaiming of a cultural identity through violence is not new to the American imaginary. Many unofficial folk narratives reinforce a rhetorical strategy of masculine violence, as do available narratives. It is here we find the resurgence of the colonial and cowboy hero archetypes. Historical folk-hero figures such as Daniel Boone have become a fixed part of the American social consciousness because they recapitulate a concept of the “American spirit” that can be tied to Herbert Hoover’s ideal of rugged individualism. In Regeneration through Violence Richard Slotkin explores the use of violence in American rhetoric, culture and history, and examines how it is integral to the construction of what he calls the American mythogenesis."

"Slotkin argues that in the rhetorical narratives that shape the American mythogenesis “the founding fathers were not those eighteenth-century gentlemen who composed a nation at Philadelphia. Rather, they were those who ... tore violently a nation from implacable and opulent wilderness—the rogues, adventurers, and land-boomers; the Indian fighters, traders, missionaries, explorers and hunters who killed and were killed until they had mastered the wilderness.”34 As a result of many of America’s foundational ideologies being based on this myth, the means of “regeneration ultimately became the means of violence, and the myth of regeneration through violence became the structuring metaphor of the American experience.”35
It is important to note that the methodology of regenerating cultural myth through violence is predicated on the agency and actions of men, and the heroic structures which they adhere to. As shown in the exploration of the colonial hero above, women are symbolically annihilated as agent, and the action falls to men. Slotkin focuses clearly on the founding fathers and a variety of hero archetypes in his exploration of the American mythogenesis; and in the violent regeneration of the myth of American ideology what is ultimately being reimagined and reclaimed is the myth of American masculinity. There exists a relationship between the heroic ideal and the culture that admires those men who embody that ideal—a type of hero worship where those who become cultural idols such as the founding fathers are “used as role models for people to identify with.”36 In the reimagined post-9/11 version of this myth the reimagined American mythology breaks down the elements of the mythogenesis described by Slotkin, and
37 applies them to more popular heroes.
The news media celebrated (and continues to celebrate)"


reinvented narratives of our founders, while also uniquely forward looking. By reimagining our cultural and political leaders in the recognizable motifs of the past, we displace meaning, looking backward to the glory days of the pioneers and western settlement while simultaneously looking forward to the personified form of American centrality in geopolitics and global marketplaces. This lived myth allows historically centered mythologies to resonate in a contemporary cultural climate and allows the nation to cope with the stresses and contradictions inherent in a post-9-11 world. In a cultural moment we are able to look at our political leaders reliving the shared myths of the past and say, as the popular media repeated again and again, “here is our father, now we are safe!” 49 The presence of Bush as frontiersmen in the popular consciousness provided a calm reassurance to the American public at large; and it became not only acceptable but customary to understand the president in the context of frontier settler, as a cowboy father figure. Americans begin to recognize that “the hand that swings the ax, it seems, fits nicely on the tiller of the ship of state.”50 So in part the reconstruction of American masculinity comes full circle, from an imagined mythogenesis that is culturally shared to a violently reimagined and lived form of that masculinity in times of national distress. Culturally we recognize and embrace a hyper- masculine reconstruction of our national narratives after shared trauma. However, this is only a small part of rebuilding masculine identity.

As mentioned before, the exertion of patriarchal influence over the American people through a hegemonically constructed narrative is not the only means by which masculinity is reimagined and reclaimed in times of national distress; they are, however, perhaps some of the most visible, particularly with regard to George W. Bush post 9/11. Traditional modes of masculinity that are narrativized also require the exclusion of feminine agency. As mentioned earlier women physically can, and indeed must, be present in most of the narrative structures that form the corpus of texts which reconstruct masculine identity after nationally traumatic events. The juxtaposition of male and female is one of the primary means by which masculinity can be understood, after which women—and their associated traits—are removed as agent. That is to say, post-9/11 we begin to see the literal and symbolic annihilation of women as agent. This reassertion of a national patriarchy in the cultural rhetoric exists to help restore the normalcy in America from a political and ideological perspective.

In the first chapter I posited that the creation of traditional masculine modes in the metanarrative that is the American myth requires the exclusion of feminine agency. Paradoxically I asserted that women physically can, and must, be present in these traditional modes of manhood. In this form of masculinity the female is presented, however she is not presented as an agent, but as an idea that exists only as that which is antithetical to the male, and so masculinity is conceptualized as directly oppositional to femininity. It is only through this juxtaposition of male and female that masculinity can be constructed, and the narrative bears this out to an extent. The colonial hero and his drive for adventure and taming of the wilderness is juxtaposed against the colonial female, the cowboy hero juxtaposed by the lack of the female and the exploitation of women through the brothel/prostitute model.

However, if I am to make the claim that women are presented in this narrative without agency and are only visible in order to reinforce masculine ideology, I must further explore how women are presented in the American mythology. Specifically, in this chapter I intend to examine how women are removed as agent and relegated to the roles of mothers in need of protection. Placing women in the maternal position juxtaposes them against the patriarchal men described in Chapter I and functions to literally and symbolically annihilate them as agents in the protection of nationalistic identity, marking them as objects to be protected, signifying them as important (in terms of Motherhood), yet also demarcating them as possessions in many respects.

It would seem as though a gendered fear of wilderness and of the hostile environment kept women from adopting the same enthusiastic attitude for the adventurous as that of their male counterparts, though this admittedly ignores the heavily patriarchal and often religious European communities from which most of them emigrated. However, many of the narratives surrounding women seem to express their anxiety and fright over both their isolation and the potential threat represented by the native men. Nevertheless, much like their male counterparts, they were willing to confront these anxieties in order to establish a new home for their families and themselves, one that would fulfill their dreams of an earthly paradise.

In her diary, Elizabeth House Trist reported feeling “oppress’d with so much wood towering above [her] in every direction and such a continuation of it.”2 However, despite these feelings, Trist did manage some degree of agency. She managed to exert some degree of power by journeying along the Mississippi River, accompanied only by two family friends including another woman. Yet while she was able to exert some control within the narrative of her life, she was limited by the necessity of being accompanied by at least one male counterpart. According to Kolodny many of the narratives around early American women encouraged a type of femininity wherein women confronted their fears, providing a model of femininity that, though fearful, was not paralyzed by the wilderness that was the untamed America. Women too, it would seem, were eager to push the envelope of the American frontier, like the colonial and cowboy heroes that dominant the American mythology. However, the active type of femininity which was present in this type of narrative was impeded by the role of women in European and early American tradition. As the available narrative that is the American myth would come to take shape, women’s roles would largely be relegated to that of damsel in distress. It would be interesting to consider how a more actionable woman in the mythos would have fundamentally altered the structure of American rhetoric. Kolodny writes:

However, in early American discourse, women were removed of all agency, both literally, in terms of historic practice, and symbolically. More than heroic conquerors, like their male counterparts, they were the victims of “Indians” (in the case of white women, particularly within the American myth) or victims of white men (particularly when we discuss native or African women, though this is largely ignored by the American myth). Alternatively they were confined to the domestic space, where they were safe and could be protected (or so the narrative implies) while their men were out conquering new worlds and new enemies.

Many of the “traditional roles” that women performed were carried over from Europe, where the roles had largely been perpetuated generation after generation. These roles did not simply fade in the New World, but rather, were reimagined and reinforced by the unorganized space that the settlers found upon their arrival. Gone were the farms and town and cities of the European landscape, supplanted by an untamed wilderness spread wide before them. While the heroic nature of the masculine mythology suggests that this provided a form of stimulation for the men, who saw a new quest before them and new lands to conquer, within the narrative

Within the narrative women were pushed aside as burdensome, largely because the attributes that were set on them through this careful juxtaposition of genders, for instance that of nurturing a family, were not immediately vital in the untamed spaces of the New World.
Indeed, the patriarchal perception of femininity implied by this narrative was one of dependence, weakness and domestic grace. As mentioned previously this model of femininity emerged, not as an independent mythology in and of itself, but actually as a set of paradigmatic elements which had been established in order to conform to the mythological masculine model.

That is to say, the feminine had been constructed so as to sustain and to emphasis masculinity, not as to create an actionable model of femininity. The feminine is seen, according to Marie-Louise von Franz, through the eyes of men only (what Jung called the anima, or man’s model of
4 This idea is again explored though what Laura Mulvey called the male gaze, further suggesting that women are only ever constructed though the anima. Whether we are discussing the matter aesthetically or through a complex semiotic system, it becomes apparent that the ideal feminine model in the available narrative of the American mythos is a form of femininity women are constructed only as an object against which the men are juxtaposed.
femininity).

Von Franz posits the influence of such narrative paradigms, writing that: “women are influenced by the man’s anima projections. For instance, they behave in a certain way and then notice that the man reacts in a bewildered, or a shocked manner, because their behavior does not fit with his anima image.”5 Taking the narrative structures of dependence, weakness and domestic grace and placing them in a widely available narrative through which we continue to operate shows the power of the American mythos, particularly as the feminine ideal is largely

Separate from the female associations of weakness and fragility, femininity in this narrative has always largely been tied to their perceived biologic function, that is to say giving birth. The role of motherhood was of significant import to the early heroic myth, wherein the heroic male conqueror must protect the wife and children from the world outside, the wilderness and the barbarians both pressing against the gates of civilization. The role of the mother was to nurture and train the children; to prepare young boys to become heroic conquerors and to prepare young women to replicate themselves and become mothers who would perform the same functions ad nauseam. The narrative for women, as presented here, largely necessitates that they be powerless, agentless mothers who need to be protected by the patriarchs against whom they have been constructed.

While the perception of womanhood has been inevitably and incontestably related to motherhood, and while the narrative elements suggest that they are also tied to nurturing, dependence and ultimately weakness, there has been a complex shift in the portrayal of women over the last century, largely due to economics and the necessities created in war-time America, particularly since World War I.

Rebecca Jo Plant, in her work on modern American motherhood, creates a concise image of the pre-war clash of ideologies as it relates to American women, asserting that the traditional mode of womanhood, as was typically envisioned in American culture, was changing. She wrote that:
Throughout the 1920s and 1930s, traditional and modern conceptions of motherhood vied for dominance within mainstream American culture. Traditionalists did not think of motherhood as a job that women performed or a role they assumed, but rather, as a sacred estate they entered—a calling that would demand their attention and energy throughout their adult lives ... Modernists envisioned motherhood in far less exalted terms. Mothers, they insisted, were simply female individuals—some admirable, some not—who had
6 been through a biological experience.

As First Wave Feminism culminated with the women’s right to vote in 1920 there were some elements of the masculine mythology that had come to face challenges. As Plant mentions, some women had begun to deny their place in the American Myth, refusing to be placed on a pedestal for, or limited by, what they considered a primarily biologic function of their bodies. They refused to let the fact that they were capable to giving birth, that they had within them the capacity for motherhood, determine who, or rather what, they would be.

for many women “American motherhood was almost like a branch of government, charged with reproducing the populace and upholding the nation’s guiding principles.”7 Furthermore, they had created a new addendum to the American myth that cast the role of motherhood as a nobly heroic one, risking their lives not in the protection of the family or the conquering of the wilderness, but in the generation of the people. In this respect women became the foundation of democracy, the origin point from which the nation’s people and so the foundation from which democracy itself sprang forth. Indeed this new female–centric narrative which reimagined and reinforced traditional conceptions of the feminine suggested that “from their perspective, the male counterpart to the mother was not the father, but the soldier, who similarly risked his life for the greater good of the nation.”8 In a time when what could be called “true heroism” was forbidden to women, this gender specific reimagining of the narrative, while not altering the structure of the myth, sought to create a space in which women could find value in their performance of their roles.

Nevertheless, this heroic interpretation of the American myth was not recognized by men; instead the anima still directly impacted the very real lives of women. It was the masculine perceptions which shaped the dominant cultural viewpoints; and masculine ideologies saw pregnancy as a sign of women’s weakness and a mother’s love, particularly when too attached to a young son, a threat to masculinity itself. This resulted in available narratives which encouraged boys to distance themselves from their mothers in order to achieve the supreme stature of a real man. No “mama’s boy” could become truly masculine as the myth of American masculinity simply would not allow it. Yet, paradoxically motherhood itself was important to men. As an institution, motherhood was a necessary part of the juxtaposition which allowed for

Women as mothers would come to represent the backbone of the society, which allowed men to be the protectors of the homestead, though as the wilderness disappeared this protection came less in the form of physical protection than in financial supporter, though truly both still applied. In other words, the narrative necessitated that men symbolically, and in some cases literally, confine women to the domestic sphere and limit their value to that of mother and caregiver, allowing the masculine myth to move forward relatively unhindered. First Wave Feminism presented a direct threat to this ideology as the principles represented by this feminist paradigm shift suggest that women need not be relegated to simply being full-time mothers, but could be productive members of society, and even engaged citizens. This train of thought both implicitly and explicitly attacked the traditional model of masculinity as it suggested that men would need to abdicate the responsibility for being the sole supporters of the family.

The women’s movement of the late nineteenth and early twentieth centuries represented the first time in American discourse when the institution of motherhood was questioned on a large scale and began a time of slow but radical change in the ways femininity was addressed in American dialogues. The narrative of the American myth was facing a tacit challenge, and women started to refuse to “be saved,” preferring instead to speak for and to save themselves.
The feminist wave that swept America was, to a certain extent, the result of the continued pressure from the traditional, patriarchal culture which continued to tie women to the safety of the domestic realm, far from the threats of savage Indians and an untamed wilderness. However, as these threats were disappearing, and new challenges began to emerge, the manliness of American men could not be as easily demonstrated, and so as feminism rose, so too did the response by men, a response that reinforced and continually stressed a woman’s place in the domestic sphere, a response that continued a narrative of subjugation through dialectic juxtaposition.

Indeed this response, like most forms of cultural expression, moved its way into the realm of material and popular culture. It has been argued that the rise of popularity of the Western genre can be attributed, to a certain degree, to a cultural response to the intense feminist efforts that characterized the age and caused a certain amount of consternation as to whether or not men were able to perform their traditional, heroic role. Indeed, Lee Clark Mitchell, in analyzing the construction of masculinity in the Western, wrote:
The emergence of the western coincides with the advent of America’s second feminist movement and ... the genre’s recurrent rise and fall coincides more generally with interest aroused by feminist issues, moments when men have
9 invariably had difficulty knowing how manhood should be achieved.
The rise of femininity, and even more the rise of feminine agency, posed a direct threat to the masculine ego, which was culturally mitigated by the Western, a genre which reimagined, reinforced and enhanced the American myth by adopting the cowboy as the new colonial hero, as discussed in Chapter I, and portrayed men as heroes conquering the untamed land and fighting the savage barbarians in the form of those same Native Americans against which the colonial hero battled. Women, in this adaptation of the myth, existed either as damsels in distress, much as they had been previously, or as prostitutes who were controlled by men, used by men and had limited agency as actors within their narratives. Occasionally these two paradigms of femininity would intersect, resulting in the prostitute with the heart of gold who must be rescued from her world by the conquering hero. “The West” therefore became a symbol, one which represented what it meant to be a “real man.” The values of masculinity (such as honor, bravery, strength, aggressiveness) were reasserted in juxtaposition to feminine values (such as nurturing) as essential for survival. Moreover, this mythic narrative places manliness as essential for the survival of women who, as shown above, are inevitably in need of rescue by (and from) men, situating the values of women through the lens of the masculine anima because the narrative necessitates it. Of course, if there are no longer wild lands to tame and there is no one to protect, there can be no heroism.

The transition from an agrarian society to an industrial one during the last half of the nineteenth century, compounded by World Wars I and II during the first half of the twentieth century, saw a shift in the practical lifestyles of women. The value of a woman was augmented beyond the domestic sphere and her juxtaposition against men, as women, out of necessity, began entering the workforce en masse. Women began to enter spheres of activity that had, by and large, been the domain of men. The natural evolution of this was the Second Wave Feminist movement wherein women implicitly rejected man’s model of femininity and argued for the right to place career above family life if individual women so desired. The constant evolution of women’s rights throughout the twentieth century resulted in incremental steps toward a sort of feminine independence which posed a serious threat to masculinity. Feminine agency, particularly in the workplace, which had largely supplanted the conquering domain of the heroic myth, meant that men were left with nothing to protect and with no one in front of whom to demonstrate their masculinity. This isn’t to suggest that complete women’s liberation has actually happened, nor that a battle in ideology didn’t exist prior to the twentieth century, but the removal of feminine agency, while not reversed, was at the very least more vocally part of the cultural discourse throughout the twentieth century. As a consequence, the American myth started to fade in terms of visibility. Films had previously centered on male leads and their actions now began to focus on the male body as sexual object. As the twentieth century drew to a close psychoanalysts began encouraging men to discover their feminine side and the American the rise of the metrosexual man, the ultimate effeminized male, came to the fore in popular culture.

Of course, patriarchy had not disappeared, nor had the masculine domination of the cultural sphere, the political sphere, the financial sphere nor the home sphere waned in strength. Nevertheless, masculinity had begun to be questioned and to be highlighted, thus becoming far more overtly “visible.” As Simon Bronner suggests in his exploration of the masculine myth, becoming visible and becoming highlighted was the greatest danger for the narrative of American masculinity, because visibility causes it to lose its most powerful qualities: that
10 In the immediate aftermath of the 9/11 attacks, femininity suffered two traumas. First, in the time after the attacks, feminist discourse suddenly became ostracized. The argument that feminism and feminist ideals made for a stronger individual and a stronger culture were shunned by the culture at large. This rhetoric was largely couched in terms of creating an alternative version of masculinity, one that clashes with the American mythos and that relied heavily on the American myth, but approaching it from a subversive angle. It should come as no surprise that the discourse around femininity post-9/11 was focused more on the male form than on the female. Where traditional forms of maleness are self-sufficient, action-oriented and anti- feminine, as we have seen, the form presented in post-9/11 rhetoric was one of an emasculated male. This narrative portrayed an American male who is reliant on others, with an especial reliance on women, and is coded as feminine through, amongst other things, a lack of agency.
10 Bronner, 168.
masculinity is essential, that it universal and that it is self-understood.
Trauma Culture: The Reconstruction of Traditional Feminine Ideology in Post-9/11 America

Feminism, and the feminist ideal, became a sort of cultural punching bag, the root cause of the problem in the American man. Feminist ideology
was targeted as an “enemy” to the country’s security in the immediate aftermath of the attacks. The patriarchal society which still theoretically privileged the American myth focused its failure not internally but externally and could not tolerate feminism. The terrorist attack on September
11 , the narrative told us, is what happens when men are too close to their mothers; this is what happens when feminists get what they are after. The reaction to the attack was twofold, however. The first and most immediate reaction was to strip the feminine markers from American masculinity; to suggest Americans had grown soft, and to rectify that by reinvigorating the masculine ideology presented within the traditional model of the American mythology. This symbolic annihilation of the feminine was only the first step though. The second was to literally remove elements of female agency from American culture. The American hero, so we were told, had returned, and a cultural victim was needed to justify his fight, and so too the American woman compelled to return to her traditional role.

Indeed, this gendered blame game is heavily present in Western culture. From Eve’s sin which caused the fall of Man, to Rebecca who cut Samson’s hair, leaving him powerless, to witches in the European and American tradition, the Western masculine mythology which has informed the American myth has consistently portrayed women as a both a potential threat to the society and the cause of cultural problems. While the rhetoric surrounding women in the aftermath of 9/11 wasn’t as strictly cause and effect as the transgressions of Eve, who caused the expulsion from the garden, or witches, who were blamed for bad crops, feminism was still made indirectly responsible for the disaster. This influence of feminism, which was responsible for a great many strides toward true equality in the late twentieth century (though never actually coming near to reaching such a thing), was held accountable for the failure of men. Paradoxically the failure of men to protect the homeland caused men to insist that they would reclaim their rightful role as defenders of the land. In other words, men proclaimed that feminism as an ideology (though admittedly the narrative fails to adequately explain what feminism is and ignores anything beyond the perceived influence on masculine identity) was defeated as a productive line of thought. Within the rhetoric was an implicit thought that terrorist attacks had somehow proven that women could not fulfill manly roles, nor could their influence on men effect positive results. Instead the narrative which emerged from the rubble of the Twin Towers and the Pentagon was one which emphatically stated that only the men, and real men at that, had the power and the ability to protect the homeland and defeat the enemy.

In an America where the culture of the warrior was the order of the day, feminism no longer fit into the national narrative and, as Faludi writes, “to the old rap sheet of feminist crimes—man hating, dogmatism, humorlessness—was added a new However, this symbolic annihilation was not enough. Women, particularly those with
strong feminist voices, began to be erased from the media. Outside of the strict confines of academe it became very difficult for feminist voices to find a space in which express their own opinions, particularly with regard to the attacks. In the very serious matters of terrorism, crises and war, men were designated the cultural experts. Madeleine Bunting suggests that this erasure of feminist voices was not only deliberate, but also easy. She describes the complete removal of feminine voices from the media, writing that “despite significant advances in the number of women in the media, the crisis has exposed how many of them are in the softer areas of news,

Men were projected as more “serious” journalists, and were seen as the appropriate voices to disseminate the events as they unfolded in the days and week after the attack. Not only were they seen as more “credible sources,” after the 2001 invasion of Afghanistan and the 2003 invasion of Iraq they also became part of the heroic mythology structure in the American consciousness. Men dominated the overseas reporting of the conflicts, and it was largely men who to put their lives in danger by transmitting from the front, just as it was men who were the bearers of news from Ground Zero.

the annihilation of women’s agency happened on multiple levels and reinforced traditional ideologies of the American masculine myth:
Virtually the only female faces in the media at the [time were] the victims; women are cast as passive ... The polls seem[ed] to bear out some of the oldest gender stereotypes ... how little boys play war games and bomb their Lego buildings while little girls look after babies ... This feminized passivity could also be seen as another mechanism for silencing dissent ... This casting of north American women as passive, and in need of protection, contributes to
16
justifications for a violent American response.

Shepherd touches on an idea already present in the myth, which has been briefly touched upon already: within the narrative of American masculinity, the juxtaposition of the image of the helpless woman against the heroic conqueror is necessary in order to justify masculine superiority and violent responses to cultural Others.

However the discourse of the narrative, particularly after the invasion of Afghanistan in 2001, did not focus exclusively on the American woman who needs protection and security. Indeed, Shepherd argues that the justification of invading the Afghan nation was based, in part, or rescuing the women of the “barbarians” who were being unfairly subjugated by their oppressive men, who happened to be the enemies of America. Shepherd writes that “[t]he representations of Afghan women, congruent with the accepted image of Mohanty’s ‘average third world woman,’ can be read against the dominant representations of the US self-as-nation as a marker of US superiority, social advancement and civilization.”17 This reasoning allows for a certain amount of moral justification within the narrative, particularly when we consider the myth of American masculinity in conjunction with the invasion of Afghanistan, and again in 2003, the invasion of Iraq. After securing our women and their safety, the narrative needed to shift in these cases to protecting women (and children who are coded as feminine through maternal association) from the “barbarian horde.”

"In returning to the American woman, the reduction of women’s place in the cultural discourse to their traditional role as implied by the American myth meant symbolically and literally annihilating their existence from all but the domestic sphere. As mentioned above, heroic women, who risked their lives side by side with men, such as female first responders in New York and Washington D.C., were never showcased, or even mentioned among the heroes of the day. The women who were presented within the cultural discourse were presented with a sort of women’s heroism; those who responded to the tragedy through what could be considered support roles. Shepherd states that women:

Thus true heroism was reserved for the masculine domain and women were presented in support roles, where they could be shielded from the dangers of the world.
Susan Faludi also commented on this removal of female agency from the public discourse in the post-9/11 moment. Female heroism was further distorted into a supporting role that created a model of femininity that performed service for those who offered cultural protection. Faludi writes, “the one example of female heroism offered [in popular discourse] was a cameo of two women in the line of traditional feminine duty: they were elementary school teachers who ‘did their best to appear calm and look after their kids.’”19 Faludi quotation of elementary school teachers offers an interesting insight into the cultural rhetoric of that moment. Women, whose domain is that of the home and children, could still only “do their best” to maintain their domain, which suggests that in a time of national trauma they were only serviceable in their duties as the men of the nation were more preoccupied with defending the homeland. While men were encouraged to redefine themselves in a hyper-heroic way evoking the colonial conqueror of yester-year, women were encouraged to “do their best” to maintain the only cultural sphere left to them.

The ideologies presented in the American myth came to be embraced on a large scale within the American cultural discourse. Women were 'required' to demonstrate their need for

began to form community groups and watch the daily 'Terror-Alert' updates. These women showed their anxiety over terrorism and even, in extreme cases, over Islam. These “security moms,” as they came to be called, performed their role as victimized mother-wife on a daily basis, conforming to the mythology of the demure feminine object which needed protection from the barbarians at the gate. These women largely came to represent an image of American feminine helplessness, though the narrative avoided any mention of how many of these women were active agents in the protection of their families.

Furthermore, in the aftermath of 9/11 there was an interesting increase in career-minded women who reconsidered their work-first mentality and decided to place having and raising a family over their previous career goals. Faludi writes that this ideology was reinforced by popular discourse, saying “[t]he media [was] particularly fond of pressing the you'll-have-no- one-to-call hot button. It was unclear which the press regarded as the greater grounds for panic: that a single person would have no spouse to speed dial or no mate to conduct the posthumous publicity campaign.” Soon after September 11th women began to realize their mistake in refusing to get married and have children, and desperately tried to repair it and adopt a domestic role en masse. Stories of such repentent women were easy to find in the popular rhetoric of the time, constantly and consistently reinforcing the ideology presented in the available narrative

While much had occurred to symbolically and literally remove feminine agency in the post-9/11 moment, the most publically visible case was that of U.S. Soldier Jessica Lynch.

other experiences of the post-9/11 period are able to illustrate better the complex shift in attitudes related to gender role discourse than Jessica Lynch’s case. In the early stages of the 2003 invasion of Iraq the then nineteen-year-old private and her unit were ambushed by Iraqi forces, where she suffered injuries and was eventually captured and hospitalized in Nasiriyah. There she remained for nine days before becoming the first American POW successfully rescued since World War II. Her capture, and subsequent rescue, made headlines around the country and was treated as front page news. While Lynch was a soldier, she truly existed in a strange liminal space wherein she was not truly a soldier, but a woman soldier. Rather than be treated as an actual soldier in American discourse “she is described in such a way to be the antithesis of the warrior hero—she is portrayed as the traditional female archetype, even as she was a military supply clerk, injured in combat, became a POW, rescued from behind enemy lines.”23 Her gender, and the narrative created around her gender, was decisive for the success of her story in the American popular rhetoric. A young female private, she was portrayed in such a way as to reinforce the American myth and to emphasize the heroism of the men who rescued her. Faludi suggests that her story was the one that everyone had expected, indeed that it could have played out no other way. The narrative that became the Jessica Lynch story was one of a little, helpless maiden who was captured by the evil barbarians and rescued by American heroes from the “jaws of the evil.

In order for Lynch to be transformed from the soldier she was to the ideal American woman it became necessary for her identity to be recrafted into one that was “civilized, sexualized and victimized.”25 She was humanized in the press not as a soldier, but as a young

girl whose stories of childhood were endlessly repeated in the mainstream press and emphasized her dreams and aspirations as a youth.

It is difficult to discuss a woman in mass American rhetoric without the mention of physical appearance, and Lynch’s youth and aesthetic qualities transformed her in an ideal victim-woman of the twenty-first century: blonde, young, toned and sexually attractive. Yet this sexuality also provided an additional opportunity for her to be victimized; her sexual vulnerability was largely exposed in the media, as journalists suggested that she might have been raped during her imprisonment. In fact this story was repeated so frequently that it came to be accepted as fact. The official biography of Jessica Lynch includes an account of her rape, though Lynch fought against including such as story as she steadfastly refuted that any such thing had happened. However, her male biographer, Rick Bragg, was adamant that the story be included, and this was perhaps the ultimate form of removing her agency as a woman; since “Sleeping Beauty couldn't bring herself to remember [the trauma of her rape], so her male rescuer would remember for her.”27 Ever the victim, Lynch was portrayed as helpless even at the moment of her rescue, an event which ignored the facts of her capture and captivity and juxtaposed her as a damsel against the heroism of the men who would save her. The entire operation of her rescue was video recorded by soldiers and after the rescue Major General Victor “Gene” Renuart personally provided the press corps with what amounted to the Lynch video's narration:

The case of Jessica Lynch, and its visibility in the American discourse in the years immediately after the terrorist attacks of 9/11, allowed for the myth of American masculinity to be played out more fully than perhaps any other event in the post-9/11 moment. Men were finally able to rescue a woman from the hands of the enemy and reaffirm their stature as heroes, not unlike the Native American captivity narratives of the colonial period and cowboy heroes of the nineteenth and twentieth centuries. It is these narratives, wherein the hero rescues the woman from the clutches of the Other, that have come to represent the key model of masculinity in American discourse; and while understanding the relationship between masculinity and femininity in American discourse allows for an understanding of the construction of an American mythos, it is equally important to understand the ways in which the narrative envisions the cultural Other and juxtaposes that construct against American masculine ideologies.

In his seminal study Morphology of the Folktale, Vladimir Propp describes the form and function of typical Russian fairy tales. Propp understood that despite a seeming variety in fairy tale narratives, there was inherently a pattern that each of these narratives adhered to. In studying the Russian fairy tales, he noted that all of the narratives could be broken down into thirty-three functions. As part of this detailed and structured analysis Propp describes a
Dramatis Personae featuring several key character archetypes; one such important character in the creation of these narratives, the villain, he describes as functioning only to struggle against the hero in some way.

narrative guidelines in a very specific cultural context, it has long been practice to apply these narrative structures to texts outside of Propp’s purview. In order to be functional in the Proppian structure, the American myth needed three basic components. The first two of these are the hero and the victim, which have already been addressed in Chapters I and II of this work. However, while touched upon in previous chapters, perhaps one of the most vital components in the narrative, particularly in its use in time of national trauma, is the antagonist.

While we must consider that Propp is speaking about a specific set of

From the arrival of the first American colonists, the man as a conquering hero protected the homestead, including the helpless women who were linked so indelibly with that domestic space, from the ever present and ever dangerous wilderness beyond the gates, and its native barbarians. The First World people in the Americas became the natural opponents in this narrative, the “Others” that did not fit into the Europeans’ idea of “civilization.” Their religion, their customs and their appearance quickly demarcated them as clearly “Other,” though this narrative ignores far too much of the complicated historical relationship between First World Nations and European settlers. However, the myth of American masculinity casts these native peoples in the role of Other who performs an alternative form of masculinity, a kind that is unacceptable and must be transformed or eliminated in order to accomplish the conquest and transformation of the wilderness. As alluded to in previous chapters, the Native peoples became standard bearers in the popular representation of the barbarian at the gate whom the brave, masculine American hero must struggle against in order to protect the homestead and conquer the wilderness. However, after all but eliminating the Native American as a true “threat” near the end of the nineteenth and beginning of the twentieth centuries, the American narrative easily found replacements for this archetypical enemy. The narrative, in addition to creating masculinity through the exclusion of feminine agency, also represented a duty of protecting the land, the women and the children from the wilderness and the barbarian as essential to creating American-ness; a lack of an identifiable “Other,” would have caused the American myth to falter.

From the Native Americans, to the British, to African Americans, to Nazis, to Russians, to Vietnamese and to Arab terrorists, the available American mythology never wanted for “cultural others” against which Americans could juxtapose their masculine heroes. This seemingly constant state of comparative alarm and hyper-vigilance allowed men to maintain a dominant place within a martial American society, and to perpetuate the traditional values of patriarchy and masculine superiority. It is this constant, threat-based comparison that the American mythos, which would come to be personified in John Wayne’s particular brand of masculinity and a Doris Day demure femininity, was able to nourish and use to reinforce a male power fantasy which permeated all aspects of a now gendered society.

The Native American as the Ideological Other
As mentioned above, the portrayal of the “Indian” as an evil force to be struggled against
dates back to the arrival of some of the first colonists in the Americas. Virtually everything about the native peoples was antithetical to the traditions found in European civilization, particularly in the English colonies that would lay the foundations for America. The native peoples were pagan, from a Christian point of view, while Englishmen (with the emphasis on the men) were predominantly adherents to various denominations of Christianity. The native peoples lived in and amongst the wilderness, seeking to operate largely in harmony with their surroundings. The Englishmen sought to conquer, dominate and control those vast untamed lands. The natives appeared as barbaric: speaking different languages, wearing different clothes, and holding to customs that were shocking to the American settler. Certainly not least amongst the factors that set the native peoples apart were their apparent aesthetic differences in terms of physical appearance. However, perhaps the most important detail that established the native man as “the enemy” in the narrative of the American mythology was the fact that he was there first.

Yet the colonists did not view themselves as invaders, a key part of the paradigmatic structure of the available American myth. The colonial hero was able to offer an ethical reasoning behind their domination of the land and its people as they claimed moral superiority over the natives through the perceived religious and civilizing purpose of their mission. By using the mythology they had brought from the old continent, settlers envisioned themselves as a civilizing force and as religious messengers fighting for the right “cause” of converting and enlightening those poor savage barbarians.
The portrayal of the native man, both in colonial times and in the reimagining of the narrative for the cowboy hero, focused on the uncivilized and brutal nature of the heathen man.

Not unlike what would be seen later in Afghanistan, the moral superiority of claiming liberation and bringing enlightenment to First Nation tribes was seen as a noble endeavor perfect for the American man. Moreover, the native people and their connection to their lands, their communion with nature as the narrative would have it, was seen as a proof that the “Indian” was more similar to a wild beast than to a human being, and in need of being tamed, controlled and, if that failed, killed to protect the colonial family.

In the later portrayal of this mythos through the Western genre, the Indian’s savagery is often accentuated as much as possible. John Cawelti stresses the nature of the Indian as beast in these representations, saying “the most important racial other in the Western was the Indian ... Mythical Indians rode bareback while the cowboy had an elaborate saddle and harness, implying a relationship of control rather than similarity [as in the case of the Indian].”2 Unlike the cowboy who controlled his horse with the technology of civilization, the Indian was more similar to the animal he rode, a beast riding bareback. Furthermore, Cawelti argues that the brutal treatment of the Indian in the Western genre, and so in the available American myth, was justified by the alleged barbarism of the racial other, a narrative which culminated with the identification of the Indian as a kidnapper and rapist.
From the seventeenth century until the close of the Western frontier in the late nineteenth and early twentieth centuries American Indian captivity narratives, which described the experiences of people, predominantly young white women, who had been kidnapped by Indians, were an exceptionally popular genre. These narratives spoke to a cultural anxiety that native people would carry off settlers in the night and reinforced the American mythology that saw a need for the masculine hero to protect his family from the barbarians that surrounded the untamed lands. These narratives, as Faludi argues, were one of the first large scale

manifestations of narratives of distorted truth that reinforced the ideologies present in the American myth.

focused on the physical torture and abuse that white women would suffer at the hands of their savage captors. In truth Native Americans rarely abused their female captives4 and the vast majority of first-person narratives of women who escaped or were rescued from Indian captivity bears this truth out (again, not unlike Jessica Lynch). Regardless of the truth of the situation, the American mythology portrayed these abductions and abuses as objective truth, searing this tale of barbaric hordes at the doorstep into the American cultural consciousness.

A part of these narratives, like those of Jessica Lynch discussed in Chapter II,
One of the most widely read accounts of an Indian captivity narrative was that of Cynthia Ann Parker, who was kidnapped from her family during a Comanche raid when she was only nine years old. Once captured, the girl grew up amongst the natives and upon reaching womanhood she married a native and together they had three children. Her fate was well known to the other settlers, and her extended family often thought there was a hope to rescue her. Throughout the years, some attempts at negotiation were made, but the narrative suggests that the Indians would “rather die than give her up.”5 Years later, the now thirty-four-year-old woman was “rescued” during an attack against the Indian settlement where she had lived. Many of those killed in the attack were women, but the massacre was labeled as “a great victory” and was celebrated in the press as a heroic rescue of an innocent woman.

the American myth, the narrative that is part of the popular discourse rides the very edge of truth. Among survivors of the raid was Cynthia, who was recognized as a white woman come home, though returned with a half-breed infant daughter. While the narrative portrayed in the popular

Her story fueled the American mythology that portrayed women as helpless victims of the barbarian Indian who needed to be protected by the heroic American man. This narrative, and others like it, offered white Americans the moral justification they needed in order to continue the never ending battle against the ethnic Other who threatened their lives and culture. The narrative of Cynthia Ann, and others like her, alleged that she suffered sexual and physical abuse, torture and incomprehensible mental torments. Faludi notes that “newspaper stories told tales of the whippings and torture she had supposedly endured at the hands of the “heathen savages” and that her arms and body “bear the marks of having been cruelly treated.”

"In the events leading up to her 'rescue' it became clear that there was a narrative being played out amongst the Americans who would seek to save her. The Texas soldiers and public who were familiar with her captivity could not tolerate the idea of a white woman being happy among Indians. The idea seemed alien to them, and they assumed that clearly she had been tormented by her captors into compliance with their way of life. Indeed, the narrative focused on how the heroes who would ultimately come to save her were limited by the necessities of their position:

would not care to return to the white society, stoked the underlying racial and sexual tensions of the frontier folk.
Despite what could likely be called “objective truth” with regards to Cynthia Ann Parker’s feelings about her situation, the colonial hero narrative maintained and reinforced a distorted version of the story. This retelling of the American myth would propagate forward in the unconscious available narrative of American-ness and have deep, lasting impacts on the culture of twenty-first century men; indeed, the congruencies between narratives of Parker discussed here and those of Lynch discussed in the last chapter can hardly be coincidental.

Moving the narrative forward, World War II, perhaps more than any other conflict in the American history, parallels the trauma of September 11 . In both instances the population suffered a national trauma, and as a result there was a rise in the American myth narrative, and a reemergence of the American soldier as a true representation of the masculine hero. In both instances American males were able to claim a moral high ground, placing themselves in the position of the “good guys” because they had not been the aggressor. Furthermore, the narrative of the American myth required the construction of a new antagonist against which American masculinity could be juxtaposed. The German and Japanese forces provided just such an enemy: one that was powerful, racially different (less so for the Germans; however the cultural differences could accommodate for this) and utterly evil in the popular consciousness. Reenacting the mythological fight against the barbarian hordes at the gate, the masculine American hero was called upon to protect his land and his people from outside aggression.
The Nazis and the Japanese offered significant opportunity for racial othering, and were easily identified as “evil,” in the context of the narrative of American-ness fulfilling the archetypical void left by the Native American. This replacement was made simpler in the case of the Germans, who were less ethnically distinct from the white American ideal than would be strictly desirable within the myth, by the Nazi regime and its systems of value, which were laden with ideologies that were antithetical to values treasured by a democratic America, values which tied them more closely to the visually distinct Japanese than other white Europeans. Franz Capra offered several films of “educational” propaganda targeted at the American soldier. In one such film, the narrator explains: “Yes, in these lands [Germany and Japan] the people surrendered their liberties and threw away their human dignity ... Each system was alike in that the constitutional law-making bodies gave up their power.”10 Furthermore, as McLaughlin argues, Capra and other American propagandists drew upon the American myth of masculinity to clearly established boundaries and delineate between “Us”, the American hero and our allies, and “Them”, the axis powers who threatened our way of life. Capra skillfully makes his points by creating a bipartite model wherein “Us” is strongly associated with light, Christianity, freedom, democracy and historical progress, while “Them” is associated with the binary opposites: darkness, the suppression of religion, militarism, the denial of human freedoms, fascism and historical regression. It is in this way that the masculine myth is reimagined for a World War II trauma era where the masculine American hero is juxtaposed against the ideological and racial Other. It is through the culturally desirable qualities associated with American masculinity, and

The sort of American propaganda that was created during World War II, predominantly through media such as film and radio broadcasts, was meant to recreate and retransmit the Amerian myth for a wide audience, and to clearly demonstrate to Americans not only who the Other was, but also who “we” were, and why it was worth fighting against the Other. Furthermore, the attack against Pearl Harbor, like the attacks on the World Trade Center and the Pentagon sixty years later, represented a literal and symbolic violation of the home land; an invasion into the domestic sphere, the sphere of women in the American mythos, and so created an ideology that was not unlike that associated with Cynthia Ann Parker. A cultural interdiction had been violated by enemies from the outside, and so the order must be set right by the masculine hero. The Other who had violated the sacred boundary of the homestead didn’t require an entirely new narrative during the Second World War. The available narratives already fixed the representation of Nazi Germany and Imperial Japan in the popular consciousness of American cultures: these forces, through their actions, had come to represent the primordial evil against which the America-type hero was meant to fight.

In addition to the propaganda created during World War II, the American myth was recreated in the popular texts of the day (not unlike the Western genre or the American Indian captivity narrative in previous generations). One of the more important and popular reincarnations of the masculine American myth during the war period was Captain America, the comic book character who represents the ideal American hero, with all the values that the American myth encompasses. The hyper-masculine Captain America was one of the most popular figures in popular culture during the war, and he was often portrayed fighting America’s enemies, notably knocking out Hitler on the cover of the first issue of Captain America Comics in March of 1941. The Captain is time and again juxtaposed against Nazis and Japanese soldiers in order to display his representation of culturally important values in American discourse, namely morality, courage and hard work.

Like the colonial and cowboy heroes before him, Captain America never truly starts the fight, but he certainly does not step back from it. This idea is central to the American mythos; the role of the man is to tame the wilderness and protect the homestead; ostensibly to defend. This is not unlike the Western genre where heroic cowboys are often portrayed as men of honor who intervene in a fight to protect the innocent, or are provoked. However, Captain America’s semiotic imagery is even more focused on cultivating this myth. Unlike the colonial hero or the Cowboy hero whose symbols were often firearms, Captain America carries a shield symbolizing his duty as a defender of the land and its people.

Digging further into this representation, Dittmer points out the relationship between Captain America and the cultural Other. 

The militant, fundamental Muslim as villainous ethnic other predates the attacks on America in September of 2001 by several decades. As early as 1980 Edward Said wrote of Muslims in American discourse:
So far as the United States seems to be concerned, it is only a slight overstatement to say that Moslems and Arabs are essentially seen as either oil suppliers or potential terrorists. Very little of the detail, the human density, the passion of Arab-Moslem life has entered the awareness of even those people whose profession it is to report the Arab world. What we have instead is a series of crude, essentialized caricatures of the Islamic world presented in such a way as to
make that world vulnerable to military aggression.

Culturally speaking Americans had acknowledged the Muslim fundamentalist and the Muslim immigrant as dangerous archetype in the popular discourse as early as 1979 with the Iran Hostage Crisis, an ideology which was reaffirmed by the Iran-Contra Affair of the mid- to late- eighties; and as Said points out, it was a predominant stereotype of the late twentieth century. Elements of this character taking on significance in the American myth were present during the Persian Gulf War of the early 1990s. However, this latest in a long line of cultural and racial 'Others' who posed a threat to American security was only truly reenvisioned as a hyper- masculinized villain against which the masculine American hero must rise after the terrorist attacks of September 11.

As America was symbolically emasculated by the 9/11 attacks, the Muslim individual, regardless of age, nationality or political affiliation, became the perpetrators of that cultural castration. While there was some debate as to which countries may have been responsible for the attack, and where these men could be located, what grew to matter most in the narrative were the key elements that have been repeated in the American myth since the colonial age: that they were men and that they were outsiders. In other words, the cultural other who represented a threat was not so much al-Qaeda or their leader Osama bin Laden, at least in terms of the American myth, as it was the Islamic Man. It became unimportant where the hijackers of the four planes had come from, and was even less important what their goals were. What mattered most what that they were racially and ideologically other, that they could be distinctly demarcated from the masculine American hero and could easily assume their place as a

replacement for the Native American in the available narrative. As mentioned in Chapter II, the non-terrorist women and children of Afghanistan and Iraq, countries now labeled the home of terrorists, were represented in the media of the day as being oppressed, enslaved, and in dire need of being saved. Even those who were unrelated to terrorism, who were merely Muslim women, had this narrative imposed on them. According to Shepherd:

The popular rhetoric of the time focused the America mission not only on protecting and avenging the homeland, but also on saving the helpless wives, daughters and sisters of the barbaric Islamic antagonists. As with earlier narratives about Native Americans, the remasculated American society claimed the moral high ground by setting out to free Afghan women and bring democracy to Iraq. Within the American mythology it was necessary to expand the battlefield due to the lack of a centralized antagonist. Unlike the Cynthia Ann Parker narrative there were relatively few concrete objectives to capture, and thus the War on Terror was born, and nations were unwillingly aligned into an ethnically distinct “Axis of Evil” that would serve as a new enemy against which to juxtapose the American male.

While officially the enemy was personified by the Islamic Extremist, with Osama bin Laden as the ultimate villain, in practice all Muslims, and those who looked Muslim, suffered from a sudden shift in the American cultural discourse. Political speeches, television programs and newspaper articles aimed to reinforce American patriotism and sense of national-self, which

President George W. Bush clearly pointed out the differences between “Us” and “Them” in his 2003 State of the Union Address, thus identifying the threats to the country and allowing ordinary citizens to do the same. Throughout the speech, he variously referred to Saddam Hussein, Afghanistan and Iraq, linking them, perhaps
th 17 erroneously when taken in the context of September 11 , to “terrorism” and “terror.”
The President’s address made clear the elements of the American mythology which would play an important role in throughout his administration, and beyond. Through his speech, he not only gained support for broadening the wars in Iraq and Afghanistan, he also helped to reimagine and reconstruct masculinity for Americans, who enthusiastically embraced the idea of war in this new, remasculated environment. Men were no longer simply fathers or sons. In post-9/11 America they had been recast as warrior-heroes who would battle back the advancing barbarian hordes in the name of justice and defense of the homeland. At last, it would seem, the paradigmatic structures which shaped a reemerged American mythos had been formalized,

I began this thesis with the goal of exploring the existence and significance of an unspoken but underlying and understood American mythology that has existed and been reimagined throughout American history. In the previous chapters, I showed how this mythology has functioned historically, and how it reemerges in times of national distress, particularly in contemporary society. Central to this American myth is the creation and maintenance of a masculine hero figure, a culturally idealized “real man” who embodies quintessentially American values and establishes the ethos of the nation as a masculine one.
As the mythology plays out as an available narrative which is reinterpreted culturally over time I found it necessary to split the focus of this study into chapters that each focus on one element of the myth: the hero, the victim and the antagonist. As should be evident by this point, traditional models of femininity and otherness in the context of the American mythology are recreated and maintained to serve not as markers in and of themselves, but as a means for propping up the idea of a masculine hero. This is not to say that femininity and otherness are not exceptionally valuable in the creation of this mythology. Each of the personae that are crafted within the myth play an essential structural role to the narrative creating a tripartite narrative model where each paradigmatic element reinforces the others and the lack of any one of the persona causes the narrative to fall apart: in lack of a victim, the hero has little purpose as he would have no homestead to defend. The lack of a hero renders the existence of a victim meaningless if there is to be no rescue. In the lack of an Other acting as antagonist, he would have little to defend the homestead from. Moreover, for the American myth to reemerge, certain circumstances must occur. One of the primary ways in which these circumstantial requirements are met is to place femininity in a precarious position where it must be defended by an idealized

version of the masculine hero. Often within the American zeitgeist femininity is seen as being th under attack when national traumas, such as September 11 , occur. As shown in Chapter III, within the cultural narrative the Other must be seen as what could be called culturally deviant, if not expressly wicked from a culturally dominant point of view, and the enemy must be perceived to have attacked first. I have shown how the reemergence of this narrative in the post-9/11 moment encouraged an understanding of pre-9/11 masculinity as culturally emasculated and insisted on a cultural remasculinization. Chapters I and II explored how the remasculinization process necessitated, in part, the removal of feminine agency. I have argued that this occurred in order to have femininity and feminist ideals replaced with an artificially created hyper- masculinized national ego.

While much of the American myth is rooted in European mythology, it has been transformed through time and necessity so as to satisfy the conditions of the New World. While not to suggest the American mythos doesn’t draw from the heroic traditions present all over the world in a Jungian sense, in practice the American myth is a cosmogony that helped the process of American settlers transforming the New World into a “New Home”; this mythology is created in such a way as to be flexible within the American consciousness, so that it can be adapted to the needs of the people in times of national trauma. Though colonial settlers named the American shores an “Eden” and saw it as their own paradise, those pioneers simultaneously perceived that vast wilderness as chaotic and dangerous, and aspired to conquer and organize it.

This narrative would come to dominate the cultural discourse through much of American history. When called upon, the elements of this American narrative were utilized by the population to bring order out of chaos and to create a national identity in times of crisis. The fact that women have existed predominantly as a symbol in need of protection within the narrative

struggle between civilization and chaos, between man and wilderness, is problematic. However, while the narrative of the American myth trivializes women as active agents in the construction of America, it does not suggest that they are unimportant. This is not to justify the rampant misogyny that is evident throughout much of American discourse; however it does suggest how we can understand the ways in which misogyny is engrained into the American zeitgeist. We must understand the woman’s place in this mythic narrative before we can begin to strive toward true gender equality, for as Richard Slotkin says “[a] people unaware of its myths is likely to continue living by them, though the world around that people may change and demand changes in their psychology, their world view, their ethics, and their institutions.”

'The fact remains, even though the development of traditional American femininity was a way of to reinforce patriarchal order, women were nonetheless important to the mythic narrative: in their absence, there could be no masculine heroics as there would be no “victim” to save, no innocent to protect. Much like the tales of medieval knights of European traditions, the American myth portrays women as “damsels in distress.” As shown previously, in the numerous captivity narratives in which this myth was relayed, the portrayal of the suffering of women who had been abducted by Indians (even if such torments never truly occurred) reinforced the available myth of American femininity.

In the hyper-mediated age of the attacks on September 11 , feminism was given a distressing knockout punch. In one moment of intense trauma the national ego once again tilted toward the American mythology that is so ingrained in the cultural zeitgeist of the United States. It transformed men (particularly, but not exclusively men of action such as firefighters, police officers, soldiers, and journalists) into warrior-heroes and it removed female agency to the extent that no heroic deed of a woman would be showcased and no female experts were consulted in any field related to “serious” matters. It also transformed women into victims even though in terms of sheer numbers they were not as affected as men by the attacks. Even though far more

men than women were killed on September 11 , women were largely held to be the victims of the day. It reassigned them to their traditional spheres of the domicile—where they would be

I have sought to show how myths link people to their past, and to one another, and how these myths are reimagined in times of national trauma and reverberate into the present. Though we live in times when people have lost their innocence and myths seem to have lost their influence in the world, in actuality they shape the world around us, the way we think, the lives we live and the everyday life all around us. The American myth, as fixed as it is fluid, as ubiquitous as it is unique, is a myth of masculinity making. It is a myth that has been shaped by the experiences and necessities of the New World and the many generations of men and women who have lived in, conquered and altered its landscape. It is who Americans are as a people, at their core; and it is only in acknowledging it for what it is that we can ever hope to change it. Americans can no longer afford to be a people unaware of their myths. While these myths have some value, they retard the growth of the civilization and we can no longer afford to live by them. Hopefully this work can contribute to the larger corpus of texts which seek to shed light on the American mythology. By exploring how this narrative has worked historically and how it reemerges in times of national trauma we can begin to see the myth for what it is: the American past. If we acknowledge that, then perhaps we can begin to truly move into the future."

## [From Southern Ladies to She-Rebels](http://www.pbs.org/mercy-street/blogs/mercy-street-revealed/from-southern-ladies-to-she-rebels-young-women-in-the-confederate-south/) ##

## [From Damsel in Distress to Active Agent: Female Agency in Children's and Young Adult Fiction](https://ir.library.louisville.edu/cgi/viewcontent.cgi?article=3716&context=etd) ##

## [Woven: A (Rape) Culture of Respect](https://entropymag.org/woven-a-rape-culture-of-respect/e) ##
"In September 2018, Stockton University, the mid-size, public, liberal-arts university where I have worked since 2010 announced to its faculty, students, and staff, that it would launch a campaign called “Culture of Respect.” Beginning in July of the same year, the university had become embroiled in a total of nine lawsuits  about sexual assault, on and off campus. The suits alleged, among other things, that university staff discouraged young women who reported assaults internally from going to the police, and that they had been negligent in acting against a so-called 'unaffiliated' fraternity which called itself “Pi Kapp,” and where several of the alleged rapes were said to have occurred. One man, a 2015 graduate of the university and a member of 'Pi Kapp' was named in four separate suits. The articles, which were published in a range of places, from the local press, to NJ.com, to WHYY (Philadelphia’s NPR affiliate), to the Daily Beast, included graphic photographs of young women’s necks and chests and collarbones, studded with feminine jewelry, marked with bruises the suits alleged were the result of violent sexual assault.

The articles posted week by stifling summer week. They both shocked me, and worked to confirm things I had long suspected, which had begun to solidify in the spring 2018 semester. When you teach at a university, your life is measured out in 16-week increments—here is the spring when all those guest speakers visited my Writing Senior Seminar. Here is the fall I traveled to Belfast. And there, right there, is the spring two young women from my class showed up in the Writing Center on a mid-February morning and said, “We need to talk to you, now,” and the realities of my life, my work, and my classrooms began to painfully coalesce.

Culture of Respect is an independent curriculum specifically dedicated, and developed in response to, the crisis of sexual assault on college campuses. According to its website, it was founded in 2013, 'by the parents of college-age students who were alarmed by the high rate of sexual assault on college campuses and the lack of comprehensive resources for survivors, students, administrators, and parents.' Its board is comprised of a range of people, from (among others) the presidents of various impressive colleges to Diane L. Rosenfeld, the Director of the Gender Violence Program at Harvard Law School. It was late August when I discovered Stockton was planning to implement this as a campus-wide program. My initial skepticism at the title disappeared when I read their literature. Rather than aligning with respectability politics that undermine the work of anti-rape activists and academics—what is typically implied by words like “respect” and 'civility'— Culture of Respect is a comprehensive, nuanced response to college rape. The website hosts research and resources, and advocates for best practices in preventative campus programming, citing, 'The 2013 amendments to the Jeanne Clery Act [which]… require institutions of higher education to offer prevention programming to all incoming students.' Rather than direct institutions toward a singular approach, Culture of Respect describes itself as a 'clearinghouse to help institutions identify those programs that best meet their needs.' I breathed a tentative, proverbial sigh of relief.

Earlier that summer, many of my colleagues in the Women’s, Gender, & Sexuality Studies (WGSS) program had begun an email chain discussing how best to respond to the Stockton rape allegations. For weeks, the news had darkened the summer like sun spots, with scant official communication to faculty or staff from the administration. What was the 'party line?' What were we to say in response to students’ questions, during the rapidly approaching fall semester? Or, for that matter, to parents in our communities whose kids were about to attend, or were currently attending, Stockton?

This lack of communication was part of a larger pattern. Beginning in December 2014, higher ups at the university had begun to make sweeping changes without consulting the faculty, or even, as was the case with its purchase that month of the Showboat in nearby Atlantic City, the Board of Trustees. We went to bed on December 11 not part of a university that rashly bought defunct casinos, and woke up December 12 to the news in the Atlantic City Press that our institution had spent $18 million on a building they planned to turn into an 'island campus' and which they claimed would be open for business the coming July. By the end of the spring semester, the deal had collapsed, the faculty had voted no-confidence in then-President Herman Saatkamp, and the state was threatening to take over the university.

This led to multiple corrective actions. Notably, for faculty, a Task Force for 'shared governance' was formed, under the auspice of reclaiming clear channels of communication between administration, faculty, and staff, and, hopefully, preventing future similar disasters. The end result of the “Showboat deal,” as it came to be known around campus, was a complicated sell-back to a real estate developer; then-Provost Harvey Kesselman, who had taken a job as president of the University of Southern Maine, terminated that position before it began so he could stay on as acting President of Stockton, as part of a deal that would keep the state from taking over the university. A year later, Kesselman was hired as the president of Stockton University (which is also his alma mater), a position he still holds.

On August 6, a group of WGSS faculty gathered at my home to talk about ways to use our shared expertise about rape and rape culture to take direct action on our campus. On August 8, President Kesselman published an official response to the sexual assault allegations in the Atlantic City Press. The same day, I published a personal response to his letter on my Facebook page, which was shared by Stockton’s Gender and Sexual Violence Teaching Circle, on theirs. On August 16, I was contacted by a reporter from WHYY, who had read my response, and wanted to talk with me; we agreed to an interview that would take place at my home, the following week.

The term 'Rape culture' is broadly defined as the normalization—and sometimes, the glorification—of sexual violence against women. Derived from sociological ideas about the ways gender, sex, race, and culture interact to produce social norms and behaviors, it became enshrined in feminist theory with the publication of Susan Brownmiller’s 1975 book Against Our Will: Men, Women and Rape. Roughly a decade later, Ms. magazine, which was founded by Second-wave feminist icon Gloria Steinem, published Robin Warshaw’s I Never Called It Rape, their comprehensive study of rape on college campuses—which was also the first comprehensive study of rape, ever. I Never Called It Rape brought terms like “Date/Acquaintance Rape” and “No means no” into the American vernacular. The Ms. study noted, among other disturbing trends, that 25% of the women surveyed were the victims of a sexual assault. Most knew their attacker.

I grew up in the era of 'No Means No' I was born in 1980. I learned about rape from television. I can’t pinpoint the first time I heard the word, but my understanding of it comes into consciousness with the television show Beverly Hills, 90210, which debuted in 1990, when I was in the fifth grade. My friends and I never missed an episode, and one, in particular, shocked us. “Slumber Party,” which aired January 31, 1991, centers on a sleepover party at the teenage main character Brenda Walsh’s house. Part of the tension of the show hitches on mid-Western rubes Brenda (and her twin brother Brandon) adjusting to life in the fast lane of Beverly Hills, where they have just moved. In this episode, Brenda has a sleepover party for her new California friends; one of them, Amanda, humiliates all of them with endless bitching about how childish the evening’s proceedings are. Then, she goes after Kelly, the prettiest, most popular girl in school, by asking her, during a game they call'Skeletons in the Closet' (which is like 'Truth or Dare' on steroids) to detail when and how she lost her virginity. Kelly grins sheepishly and tells a standard, sweet story about choosing to have sex with her longtime boyfriend, Steve. When she finishes, Amanda says something like, 'That’s nice. Now tell the real story.' Staring shame-faced at the ground, Kelly details a violent rape by a senior that she says occurred when she was a freshman, during a party in the woods. 'He didn’t even use a blanket,' she says, beginning to cry.

Rape culture functions in part by clinging to outdated, hyper-gendered modes of language. In the episode I just described, this shows up in two ways. First, Kelly is asked to make a narrative out of her “virginity,” with the idea that virginity is a thing that can be captured or possessed by the person she has vaginal sex with for the first time. Virginity does not apply to oral sex—this is one of the many ways Bill Clinton’s characterization of his affair with Monica Lewinsky reeked of rape culture. Virginity is (usually) clung to by a woman and 'taken' by a man ('Is there where you got your V-Card punched?' Abby Flynn asks Liz Lemon, in the 30 Rock episode 'TGS Hates Women'). In other words, the “loss” of virginity here connects to aggression, and violence—I have something you want. To get it, you have to take it. Moreover, Amanda’s question (and persistence) sexualizes rape, which is in reality an act of violence and power—not sex. When Kelly first answers the question, she tells a story that is about consensual sex, about desire. She’s laughing and smiling. But the happiness she feels about sex is taken from her when she is forced—as we, the viewers, are forced—to identify sex with violence, rather than with love and desire.

Three years later—in another episode about rape, called 'Take Back The Night'—the character who raped Kelly shows up in the flesh. She dates him.

I didn’t start my career teaching about rape and sexual assault, although my education was largely focused on Women & Gender studies. I began teaching in 2009, after I completed my MFA in creative writing, and taught composition courses almost exclusively until the spring of 2014, when the WGSS program at Stockton hired me to teach the foundational course for Stockton’s WGSS minor. Since then, I have taught it every spring. In spring 2018, I taught two sections.

I did not design the course, but it has come to be my favorite one to teach, and the place I teach best. The students are required to design and execute an “Activism” project, in which they choose an example of campus gender inequity, and raise awareness about it through feminist activism. Some of those projects were so successful, they are now institutionalized—one group’s 2014 'SlutWalk,' for instance, is now the annual 'Stockton March to End Rape Culture.'

In 2015, I was one of the featured speakers at the March. There, I read, for the first time, an essay about my own rape. In 2005, a person I knew drugged and raped me in my home. In 2008, I wrote about this event—in the heavy, veiled language of metaphor—in a poem that I submitted as part of my master’s thesis. In 2012, while I was researching an article, I discovered that the person who raped me shared his German last name with a prominent sociological theory of power and control put forth by the sociologist Max Weber. I scribbled down two paragraphs about this. Then, I dropped the pen like it was a poison snake. In 2015, I picked the pen back up, and turned the two paragraphs into the aforementioned essay I read at the March. I published it the following year.

In other words, it took me a decade to write down the words, He raped me, without getting violently sick.

The day my students walked into the Writing Center and declared they needed to speak with me, we went to a quiet, isolated room in the Center, and they told me that a woman visiting their dorm from another university that weekend had been raped at an off-campus party. The students reporting this to me were not present at the party, but were in their rooms when she returned, with other floormates, to the dorm late that evening, intoxicated to the point of unconsciousness. They said the young women she had been out with, who were also Stockton students, were distraught. One of them had walked into the room where the rape was going on, and seen her friend unconscious beneath a young man she recognized as of her classmates. She screamed at him to stop. He bodily removed her from the room, and locked the door. By 5 am that morning, my students had convinced the young woman, who was beginning to realize something terrible had happened, to go to the hospital, which sits not a half mile from their dorms, and leases its land from the university—AtlantiCare, known locally as 'Mainland,' since it has a counterpart in Atlantic City.

'Did she have a rape kit done?' I asked.

'No,' they reported. 'They don’t do them there.'

'How is that possible, they lease land from a college campus,' I said, furious. 'So, what happened?'

'They told her they would call her a taxi to Atlantic City, where they do them. But it was six in the morning. She wanted to go home. She was really upset.' Later, as I went with them to report the incident, I would bring this fact to the attention of a Stockton staff member—they don’t do rape kits at Mainland!— expecting them to be similarly shocked and moved to action. But they blinked at me, and said, 'I know, you have to go to the city.'

Like everything else in this story, this is part and parcel of rape culture, specifically rape myths—Atlantic City is made up almost exclusively of people of color, with an historical Black working class. Its surrounding areas are largely white and privileged. Rape myths (which intersect with racism and classism) dictate that more rapes would happen, and therefore necessitate a SANE (Sexual Assault Nurse Examiners) nurse, in Atlantic City, as opposed to on, or near, a college campus.

Rape facts tell us otherwise. And tell us how much the lack of a SANE nurse in a hospital in walking distance from a dormitory would discourage a victim from getting a rape kit. And therefore, from reporting, because of a lack of evidence. Which, as it turns out, this young woman did not do.

'But, wait,' I said. 'You’re telling me someone saw this happen? Someone from your floor? So she knows who did it?'

'We all know him,' my one student replied. 'He tried to assault my sister last fall.'

An important facet of understanding and teaching about rape culture is the concept of rape myths versus rape realities: rape statistics, rape facts. In spring 2019, my students were reading and discussing Janey Williams’ podcast This Happened, which details psychosocial dynamics in the aftermath of sexual assault in a close-knit community. Rape culture, Williams says, riffing on the feminist philosopher Kate Manne’s theory of 'Himpathy' from her book Down Girl: The Logic of Misogyny (which the class also read), produces a strange phenomenon, which Williams calls 'pity for the perpetrator.' For instance, when Williams tells her own mother, with whom she has a close and loving relationship, that her ex-boyfriend and close friend has sexually assaulted her (and presumably drugged her beforehand), her mother replies, 'That poor, poor boy…'. Williams, for her part, in her own narration of her assault and its repercussions, says she, too, did not immediately speak about it because she wanted to protect her attacker, who was also—as is often the case—her friend, and former boyfriend. Kate Manne essentially says that this instinct is a pro-social skill for which we are ultimately rewarded. Women, in our society, are understood to be givers; men are doers. When we side with the doers, even if they harm us, we get a reward for it—protection, promotion. When we side with the givers, especially when they are victims of the doers’ sexual violence, we violate a social code and have to be punished.

'Does this resonate with anyone?' I asked my class. 'In either your personal or institutional experience?'

A student raised their hand. They said they had once been told by a friend that her boyfriend raped her. 'But I didn’t take her side because, well… she had her stuff.'

'What kind of stuff do you mean?' I asked.

'She cheated on him in the past, so…' The student trailed off into silence, leaving us to understand that previous acts of infidelity excused—or maybe even caused, in their mind, rape. Another student piped up from the other side of the large classroom: 'That doesn’t mean shit, man. That doesn’t make it OK.'

A third student muttered, in the front row, 'I mean, what is she hiding, though?' with their eyes cast down.

'What is who hiding?' I asked.

'Janey Williams, from the podcast,' they responded. 'There has to be something she’s not telling us.'

'What leads you to say that?' I asked back, gently.

'Because why else would he do that, if she didn’t make him think it was OK?'

Lest a reader think this kind of conversation, in the face of survivors’ testimonies and the theories of  Ivy-League philosophers’, is an unusual response, I assure you, it’s not. The mythology of rape says that it’s is an “ancient sex crime of abduction and murder,” and that the epidemic of campus sexual assault is 'wildly overblown' and 'hysterical'—to quote Camille Paglia’s 2014 article, 'The Modern Campus Cannot Comprehend Evil,' written in response to the rape and murder of University of Virginia student Hannah Graham. Rape myths promote this false dichotomy—that there is 'real' rape and 'false' rape. 'Real' rape is what happened to Anderson—an 'ancient' crime at the hands of a total stranger (despite the fact that, according to the Rape and Incest National Network, less than 20% of all rapes are committed by a stranger). 'False' rape, according to Paglia, occurs on campuses.

Rape myths are made of tropes, or genre conventions. Tropes are hugely important to communication, both interpersonal and public; they live at the heart of creating shared language and shared experience. Unfortunately, the realities of rape culture have yet to catch up with the tropes of rape mythology—have yet to make their own set of genre conventions. Rape facts tell us that most victims know their attacker; rape tropes are dark alley attacks by nameless strangers. Rape facts tell us that it does not matter what we are wearing when these assaults happen; rape tropes bandy about the length of skirts and the plunge of necklines. Rape tropes keep the crime at bay, keep it, as Paglia’s exaggerated terminology claims,'ancient,' i.e., far away. Distant. These are not the rapists you’re looking for. Move along. Rape facts point to the reality that rape is contemporary—present and accounted for. Evil lives down the road in a dilapidated house with some Greek letters carved into a tree in the backyard. Rape facts walk into your job on a Monday morning to tell you their floormate spent part of her Saturday night watching her friend sexually assaulted, and that they just saw the perpetrator in the hallway.

This past year, Paglia was proved correct about at least one thing she wrote in that article—the modern campus cannot comprehend evil. Or, at least, the one where I worked seemed incapable or unwilling to do so. My relief that the Culture of Respect would tackle, and try to prevent campus sexual violence head on disappeared when I attended the 'Culture of Respect: Town Hall Kick-Off!'

In January 2020, partly at the urging of the author and her colleague, Dr. Betsy Erbaugh, who wrote to senior administrators asking as much in March 2019, Stockton University adopted the actual Culture of Respect.

My colleagues and I sat waiting for the anyone on the stage to say the word 'rape' aloud. No one did. Instead, a long-tenured professor interviewed several administrators about their non-sexual violence related work in gushing tones, and the audience was told they could write down questions, which would be pre-screened and asked anonymously by a campus worker at the end of the event. The moderator said, 'It’s so important to talk about these things in the university setting, which has always been the place for cutting edge ideas and social movements.' Not today, it’s not, my friend and colleague, sitting next to me, texted me at precisely that moment. Behind me, multiple students from my spring 2018 section of Women, Gender, & Sexuality, who had worked the previous semester to raise awareness about sexual assault on campus, sat stony-faced, waiting for someone to talk about the lawsuits.

But no one did, and we left, deflated and depressed. In the coming weeks—and as of this writing—we received weekly emails about on-campus Culture of Respect events, and my fear—that the word 'Respect' would be used as a smoke-screen to avoid the adoption of best practices for ending rape on campus, and would instead connote broad respectability politics—came true. Yes, there was the (very) occasional event dedicated to sexual assault; but there was also the stated intention that, rather than adopt the Culture of Respect’s explicit and singular devotion to stopping campus rape, Stockton wanted us to be civil. To respect one another. This was understood by many of my students, colleagues, and by myself to mean not naming rape for what it was, and for, instead, having events like 'Coffee With Cops' and 'Domino Night,' and a screening of Selena sponsored by Los Latinos Unidos, with the implied idea that giving lip-service to diversity can somehow end sexual assault.

In fact, it cannot. There are scores of academics, activists, and educators (like Kate Manne, like Stockton’s own Elizabeth Erbaugh and Deeanna Button, like the activist group End Rape on Campus) who engage in empirical research to deduce the best practices for helping survivors and stopping perpetrators. This was part of what Stockton’s WGSS faculty wrote in our letter to President Kesselman in August 2018—we knew what we were getting into, and we wanted to help. We knew how to help. We understood seemingly small things, like the fact that the mandatory reporting statute—a federal policy that states you are required, as a campus staff or faculty member, to report a sexual assault if it happens on campus, or involves one or more students at your institution off-campus—actually discourages reporting. That student victims, when you tell them, If you tell me this thing, I have to tell the authorities, often shrink back in terror, and tell no one, get no help. Beyond the obvious moral problems that arise from this law, on campuses, it’s also a retention issue—when students are raped, they tend to fall apart: stop coming to class, fail courses, drop out, disappear.

Rape destroys lives. That’s the point. I write this as both a survivor and a witness. Rape did go a long way, all those years ago, toward destroying my life. I survived, but now, as one of the faculty members at the central locus of this culture, I watch the same thing play out in my students’ lives, semester after semester.

I now find this incredible, but when my students came to me about the sexual assault in February of 2018, I had never before heard of 'Pi Kapp,' the 'unaffiliated' fraternity where that assault—and, we would soon discover, so many other alleged rapes—took place. As in most things, my students were way ahead of me. When I broached the subject that afternoon in class, at least two dozen students began to talk openly about their experiences there. No one spoke of being sexually assaulted, or witnessing sexual assault, in class; instead, they detailed women being forced to drink different colored drinks than the men. They talked about rampant drug use. They talked about the group targeting freshman in the first six weeks of the fall semester, what sociologists call the “Red Zone,” and when, according to the National Network for Rape and Incest, almost half of all campus sexual assaults occur. They talked about flirting with older men they assumed were just seniors or graduate students, and being shocked when they whipped out pictures of their children, and turned out to be in their late twenties and early thirties. Later, I would bring that up to a staff member, whose response was, 'It’s worse than that; those guys are mostly local cops.' I never asked them how they knew this, because that, too, is how rape culture works—people make outrageous statements like they’re commonplace, and dialogue ends.

In the coming weeks, the students designed a series of projects to raise awareness about campus rape that challenged my pedagogy, the limits of my knowledge and experience, and my courage. When they decided they wanted a hashtag under which they might classify any image or Instagram post or tweet, they settled on #fuckpikapp and #sobasicallyfuckpikapp. My stomach sank as I imagined the university’s potential response to these phrases being tweeted out into eternity with images of Stockton’s woodsy campus in the background. Rape culture and respectability politics go hand in hand and dictate many things, not least of which is that, in discussing the violation of bodies and lives, we have to be polite. We don’t say things like 'Fuck Pi Kapp.'

But we also don’t take action against the individuals that evoke such responses, or the groups that harbor them. In 2014, when the Obama-Biden administration issued the findings of their campus sexual assault task force, which included detailed protocol about how to take sufficient steps to end rape on campus, many feminist academics felt we were in the midst of real change—even if changing the culture was an uphill battle. We felt that we our research, teaching, scholarship, and activism on and off campus had validation and a kind of administrative teeth we had been seeking for years. But with the election of Donald Trump—and his appointment of Betsy DeVos, a woman who has publicly stated that under the Obama-Biden era guidelines 'everyone loses'—the little headway we have made is being rapidly rolled back.

One reform, in particular, would devastate victims in a situation like the one we find ourselves in at Stockton. It states that schools would have limited responsibility, and limited liability, to investigate reported assaults that happen at off-campus locations, such as fraternity houses and off-campus apartments. If this goes into effect, the places my students—so many of them—described as intentionally dangerous to women, would have, given what we know about how few people report assault as a general rule, near impunity to operate as though these suits never happened.

In September, Joe Hernandez of WHYY published an article partly based on his interview with one of my colleagues and myself. In it, he noted that my students, as the spring 2018 semester drew to a close, had tried to involve themselves in institutional change. I had told him about how, as April turned to May and the cherry blossoms scattered from their boughs and the students were filled, as I am often filled, with the sense that, in fact, knowledge is power, that they thought they could use what they gained that semester to stop rape, or at least prevent it. Or at least make someone with relative institutional power address it, out loud. In a real way. As such, they decided to write to the some of the people responsible for orientation in the hopes that they could be involved with talking directly to entering students, with no parents or no staff or faculty present, about the dangers they faced at a place like the house I’ve described above. They talked about their fact-finding mission, and they talked about their facts. They quoted literature. At the end of those classes, 70-plus students hand-signed that letter, and sent it off. And were turned down.

When I spoke to the staff member about the lack of a SANE nurse at AtlantiCare, they told they had a meeting with President Kesselman that afternoon, and they would bring it up with him. They texted me that night, ecstatic—upon hearing this news, the president told her he would do everything he could to make sure AtlantiCare had a SANE nurse, as soon as possible. That was a year ago—February 2018.

It took a while, but as of this writing, there is now a SANE nurse at AtlantiCare.

When the WHYY piece ran, an upper-level administrator countered my narrative about Stockton refusing my students’ request to talk with entering students at orientation. In a series of emails, they denied that the students’ had been turned down. I wrote back, 'But they told them the schedule was set already, and when I pressed, they did not respond.' The administrator remained firm in their belief that words did not mean what I thought they meant, despite my terminal degree in the discipline of writing.

When President Kesselaman published his article in response to the allegations of sexual assault on Stockton’s campus this past summer, he encouraged victims to report the crime. He said, 'We stand with you.' In my response to this piece, I said that this went against best practices. I said that my own home, where I was sexually assaulted in 2005, had no back door, and that this had become 'a potent metaphor' in my own writing about that experience, in the ensuing years. Barely eight weeks later, Dr. Christine Blasey-Ford testified to Congress that after the sexual assault she alleged happened to her in high school, where she felt trapped by the configurations of doors in the room where the assault took place, she insisted during a renovation that her home have two front doors, or a second way to escape. That same month, a retired emeritus professor wrote to me that she had read my response to the university president, and that the idea of having 'no back door, no escape hatch' resonated with her, as a woman of color in the academy. In other words, the lack of public discussion about rape keeps survivors from understanding what so many of us share—it keeps us in the metaphorical dark. We crave these tropes, this shared language. But the silence that surrounds rape deprives us of that—until we begin to speak.

When Dr. Blasey Ford testified against Brett Kavanaugh, I was teaching an introductory composition course, with a unit on 'Kairos,' or the idea that persuasive language is often best employed during a precipitous historical moment. When I heard that Stockton was going to be part of a #BelieveSurvivors walk-out, I took my class there. Not, as I told them, so they would participate, but so they could witness a “Kairotic moment” in action. We attended, along with several other classes, without event.

But the same administrator was displeased, and had no problem telling my dean to discipline me for being 'inappropriate.'

No other attendant faculty receive the same warning.

I have had colleagues tell me I’m on a suicide mission by speaking out like this about sexual assault. Like the aforementioned example, it’s a potent metaphor. After all, I am still junior faculty. It would be relatively simple to find a reason to get rid of me.

But if I, if someone, doesn’t talk, who is silenced? Whose life is ruined?

It is, to quote my Irish-Catholic aunties, six of one, a half dozen of the other.

If I speak, I might end my career. If I remain silent, what might happen to these students? Who might live, maybe forever, in a dark room without an exit? A house with no back door?

Emily Van Duyne teaches at Stockton University. She writes about Sylvia Plath, who was also a rape survivor. Her book, Loving Sylvia Plath, is under contract with W.W. Norton & Co. Her essays & poems have appeared, or are forthcoming, in Literary Hub, Harvard Review, The Rumpus, & elsewhere. She lives with her family in New Jersey.

## [Portrayal of Women in the Media Propagates Sexism](https://www.jhunewsletter.com/article/2014/10/portrayal-of-women-in-the-media-propagates-sexism-85735/) ##
"It may be 2014, but the silver screen has been stuck in a temporal loop since the 1950s. Sexism in media has been normalized over time, so much so that we don’t even realize it anymore. A study from the University of Southern California captures how women are still underrepresented in the media: To begin with, only 1.9 percent of directors are female and 25 percent of all speaking roles in animated films are filled by women. Lastly, of 25,000 speaking characters in 600 top-grossing films between 2007 and 2013, only about 20-27 percent were women — what?

Why haven't the alarms been sounded? The authorities notified? Riots started in the streets? Even though this issue doesn't seem to be widely contested, we definitely are fighting battles on behalf of women in the media anyway. One of these battles has resulted in a total body image revolution. One of the primary focuses of women in the media has been to abolish the ideal of a 'perfect' body type — great news for the 99 percent of women in the world who don't look like models. I personally find it easier to face myself unashamed in the mirror nowadays. Yay. However, at the same time, how have we all failed to grasp that apparently only a third — less than a third even — of speaking roles are women? The best answer to that, my darlings, is the sad fact that this is just the status quo.

'How is this normal?' you may go onto ask. Simple. The problem has just been building like a gas leak: subtle and unassuming until you can't help but notice that it's pretty loud and inflammatory. This genteel style of sexism is not the overt discrimination that led to the 19th Amendment and the women’s suffrage movement. This type of discrimination is one of the reasons why such unflattering stereotypes have emerged around feminists. Sexism is normalized in our culture from a very young age, and the process begins with every busy parent's best friend: television sets.

To begin with, the  percentage of characters in family films wearing sexy attire by gender is 28.7 percent female and eight percent male. This fact makes you recall many characters such as Ariel from The Little Mermaid, Jasmine from Aladdin and Meg from Hercules. You pause and ask yourself why you didn’t ever question their apparel? Why are these outfits considered okay to include in a children's movie to begin with? What subliminal messages could they have planted in my brain when it was at its most pliable state? Women have been getting over their historical damsel-in-distress period, but it seems that women have traded one evil for another: Young women are being hyper sexualized, and the media has reinforced that it's normal.

Now for an even bigger shocker: The  percentage of family films with a male narrator is 73.5 percent. I can't recall there being many big family movies or coming-of-age stories with female main characters when I was growing up. I remember amazing movies such as A Christmas Story, The Princess Bride, The Perks of Being a Wallflower and Little Manhattan, in which those little boys narrated their growth and small revelations in romance, family and coming of age. When I imagine the coming of age genre with a main female lead, I can remember 13 Going on 30, Princess Diaries and... that’s it. In both films, a major part of the “growth” of the female protagonist pertains to appearance, breast development, makeup and romantic awakening. That’s angering because we, females, are more than hormone-driven mirror addicts. So why don’t we see that in the media?

Now let’s proceed to another aspect of this message: The media presentation of female leaders and women with higher education.

Amy Farrah Fowler from The Big Bang Theory is a very obvious example of how we see the unattractive educated woman. She’s socially awkward, missing obvious social cues throughout the series, and she lusts for romance. This only fuels the stereotype that as a highly educated woman, she has traded date time for lab time. In contrast, Bernadette is the quintessential attractive educated woman. Bernadette is inherently humorous because she is dating Howard, who has been a sex-orientated character from the beginning. Subsequently, Bernadette is in a way simply a pretty accessory to Howard’s character. Now Penny — what does it say about women in general for Penny to be the 'normal' one? She’s a failed actress who doesn’t appear to have much motivation to quit her waitressing job. She also puts a lot of emphasis of dressing well and is sexualized very often due to her outfits. In fact, she’s almost portrayed as a nymph, so Sheldon can comedically misinterpret any of her 'romantic' cues.

Then, when I think of female leaders in the media, I think of one particular movie: The Devil Wears Prada. Meryl Streep’s character, the 'devil,' is the boss, and there are immediate associations that come to mind when describing her character: cold, callous, stoic, yet somewhat sexy with a dominatrix twist. Female leaders, and heroines in general, always seem to take on cold, masculine attributes. Notably, Katniss Everdeen from The Hunger Games and Black Widow from The Avengers embody these attributes in order to seem "tough" enough to be believable in these action-packed stories. What does it say to young women if their strongest role models are like this? Do women have to suppress our femininity to be taken seriously?

Here is my last spiel: To start, have you ever heard of the Bechdel Test? The Bechdel Test is a test used in movies to check for gender bias. There are three parts to this test: (1) there has to be at least two women in the movie,  (2) who talk to each other, (3) about something else besides a man. I'd say that's a pretty low bar. Although 57 percent of movies do indeed pass the test, 43 percent fail! What does this tell me? That a large portion of movies still utilize a woman as a prop for the male characters. Does this surprise me? Yes. But should it? No.

It starts in the screenwriters’ room, where female writers accounted for only 15 percent of screenwriting in 2012. Women are not even fairly represented on the film set, so it shouldn’t surprise anyone that there is a theory called 'The Male Gaze Theory' where the camera is compared to being a man’s eyes. The best and one of the most notable examples I can give you is a scene involving Megan Fox in Transformers. In her introduction, the camera slides up her legs, pausing at her bottom and bosom before finally focusing on her face. No better than a prop. Now how does this all apply to Hopkins, you and me?

Many of us are women, and our portrayal in the media affects us every day. The media invades our homes, our colleagues and even our minds. I fear that if we don’t say something, we will have to deny our femininity to be recognized as a leader, to be heard and respected. The media shouldn’t force us to take on traditionally masculine attributes in order to have a voice among them. The media should be changed and the stereotypes broken, and we all need to work towards this."

## [16 things you do as a Southern Belle of Color](https://thetempest.co/2017/10/12/culture-taste/16-things-southern-belle-color/) ##
"When people think of a Southern belle, they imagine a blonde-haired, blue-eyed damsel in distress. For us Southern WOC, we’re often left out from the Belle narrative. Yet, we’re still proud of our ethnic and religious identities and embrace the good aspects of our region. Southern WOC are a diverse group, but it’s nice to appreciate the things that unite us. Whether you hail from Texas or Tennessee, Alabama or West Virginia, here’s a few things that your Southern heart knows to be true."

"You say things like 'y’all,' 'bless your heart,' and 'fixin’ to.'"

"Tailgating is life, but you stay woke on the NFL’s issues on sexism, racism, and homophobia."

"Argue with white people over Confederate monuments, race, slavery, etc."

"Constantly being surrounded by guns."

“I’ll pray on that.”

“You’re not like other *insert minority group here* girls”

## [How to Rescue The Damsels in Data Science](https://medium.com/swlh/how-to-rescue-the-damsels-in-data-science-dece09dedf26) ##
"Becoming a damsel in distress and not knowing how to send an S.O.S.

One of the first things the instructor ever said was, 'Don’t suffer in silence.' He then showed a graph of the emotional undertaking Data Science boot campers endure in the months ahead. Here’s an annotated version of said graph below:

I am a non-linear savvy enthusiast with strong soft-skills. In other words, I have worked extremely hard to alleviate my Asian parents’ concerns after I graduated with a B.A. in Comparative Literature. I’ve landed solid paying jobs since graduating. However, I recently reached a plateau which led me to sign up for a Data Science boot camp.

The first weeks were humbling, to say the least. Days filled with technical challenges, sleep-deprived presentations, and incessant existential questions.

And while I knew better than to internalize my frustrations or confusion over the course material, I chose to quietly flail for fear of being seen as incompetent or helpless. Or worst yet, hopeless.

As a result, at the end of each day, I would make my way home feeling demoralized. I would have cried more if it weren’t for the readily available salty snacks provided on campus. Fortunately (or unfortunately), I was often too dehydrated to shed any tears.

The class comprised of 5 male instructors, 11 male students and 7 female students. And as the weeks progressed, students dropped like rows with null values. Half of them being women. This broke my heart.

As a modern woman, I am independent and fierce. Or so I’m told by blaring 'strong women' anthems and tagged inspirational quotes. Admittedly, while I believe in the 'strong women' movement, I fell into isolation because of it. I didn’t want to disappoint the women in my class so I withheld asking for help. I know, newb mistake. I also exhausted my energy attempting to uphold an 'independent' persona by trying to do the assignments on my own.

It’s not like Rihanna bestowed upon me the responsibility of representing badass women in Data Science, but I felt a sense of duty. This sense of duty was further amplified after reading a recent TechRepublic report that stated,

'…only 18% of Data Scientists are women.'

Needless to say, I felt pressure to represent women in the best possible light. Of course, it gave me anxiety to not let on that I’m more of a 'black light' and 'fluorescent light' kind of woman, not so much 'best light'.

Surprisingly, the remedy for the unyielding ache of self-doubt were simple kind acts done by both men and women. I’m grateful to them for saving me from the prison I made for myself.

1. Check in with the women who aren’t asking questions.
2. Setup a co-ed study group.
3. Ask women for feedback.

I thought I must have unknowingly signed my voice away to the infamous Disney villain, Ursula, because my initial attempts to contribute in group conversations were muted. I would have to physically wave my hands in front of people’s faces to be noticed. It made me question my value and my presence.
It’s common for women to question their value as a Pew Research Center 2018 report states, '79% of women in STEM in majority-male workplaces feel the need to prove themselves most, if not all, of the time.'

Every time someone did ask for my perspective, I felt like that person trusted and valued my input. After enough times, I was able to redirect energy towards exploring innovative projects and solutions. I no longer spent time focusing on ways to prove myself.

Data Scientists uncover the stories behind the data. The more diverse the data, the greater the possibility of more stories being uncovered. More women does not necessarily mean better. More understanding and acknowledgement by both men and women does.

It’s okay to not be okay. I can be a damsel in distress one day and the next day be a determined woman. My value is continuous and the kindness I have received from people- invaluable."

## [Southern White Patriarchy](https://www.researchgate.net/publication/335328771_Southern_White_Patriarchy) ##
"The pedestal upon which southern white womanhood stands is buttressed by an equally sacred southern white masculinity characterized by a distorted notion of honor, a penchant for violence, and male righteousness and superiority. Thus, Second-Wave Feminism spurred not only a defiant anti-feminism with which many white southern men and women identified, but also a men’s rights campaign that portrayed men as victims of reverse discrimination and promoted a dominant and defensive masculinity that was very familiar to southern white audiences. This misogyny, along with a religious assertion of manhood that was popular in southern evangelical churches, provided Republicans with an opportunity to build their partisan brand among white southerners. Often masked by romanticized notions of chivalry, southern white masculinity depends upon a patriarchal system and the traditional gender roles inherent in that system. The GOP would appeal to both as it chased southern white voters throughout the Long Southern Strategy."

## [Crying Shame: The Power of White Woman's Tears](https://www.smh.com.au/entertainment/books/crying-shame-the-power-of-white-women-s-tears-20190820-p52iy7.html) ## 
"One of the earliest critiques of White Womanhood comes from one of the most underrated figures of the suffragette era. Frances Ellen Watkins Harper was a poet, journalist, fiction writer and a formidable presence on the abolitionist speakers’ circuit.

In 1866 she gave a far-sighted speech at the 11th National Women’s Rights Convention in New York City before a crowd that included key suffragist figures Elizabeth Cady Stanton and Susan B. Anthony.

'We are all bound up in one great bundle of humanity, and society can’t trample on the weakest and feeblest among its members without receiving the curse in its own soul,' she declared.

You white women speak of rights, I speak of wrongs. I do not believe that giving white women the ballot is immediately going to cure all the ills of society. I do not believe that white women are dew-drops just exhaled from the skies.

Harper argued the condition of poor white men in the South was a direct consequence of the law favouring rich slave-owners: in enslaving black men, white men paralysed the moral strength of the nation and the rights of lower-class whites. Likewise, in the cities of the North, white women were turning away when black women tried to hail streetcars only to find the conductor refused to let them ride.

'Have women nothing to do with this? While there exists this brutal element in society which tramples upon the feeble and treads down the weak, I tell you that if there is any class of people who need to be lifted out of their airy nothings and selfishness, it is the white women of America.'

The key, then, to white women’s liberation lay in whether or not they considered black women to be women like themselves, and in using this recognition as the first step in building a fairer society. Sadly, those white women didn’t and arguably many still don’t. Rather than rejecting the concept of white women as virtuous "dew-drops" inherently equipped to right the wrongs of their white male counterparts, white women have largely chosen to navigate and bolster the existing system to gain some advantages, which necessarily come at the expense of people of colour. And this has meant adopting the persona of the damsel in distress.

Perhaps no story encapsulates this more clearly and tragically than that of Emmett Till. The 14-year-old from Chicago was visiting family in 1955 Mississippi when he was accused of whistling at a white woman, Carolyn Bryant. Abducted by a group of white men including Bryant’s husband, he was beaten to death and dumped in the Tallahassee River. His killers were acquitted by an all-white jury. In 2018, Bryant recanted her testimony, admitting Till had not harassed her in any way.

This is the power of the white damsel in distress. It is a power that is not in the past.

We see this modern-day dynamic of white women’s innocence and virtue used as a justification for the oppression of brown and black bodies in the rhetoric of our politicians. Last year, US President Donald Trump invoked the protection of women as a rationale for demonising the so-called 'migrant caravan' - the dehumanising name given to the thousands of people attempting to make their way from Central America to the US border in the hope of finding safety. He conjured up the image of the white damsel, saying, ‘Women want security. Women don’t want that caravan’, echoing the messages of slavery, segregation and more recent white supremacist literature.

In 1997, sociologist Abby L. Ferber published White Man Falling, a discourse analysis of newsletters and magazines printed by white supremacist groups. What she found, along with a preoccupation with 'saving' Western civilisation and restoring the reputation of the white Western male, was an obsession with policing the bodies of white women and the borders of 'white' countries.

'America is being invaded by a deluge of legal and illegal non-White intruders: swarms of Mexican, Puerto Rican, Negro, Oriental and Jewish scum who are thronging across our wide-open borders,' thundered one publication, arguing that this 'unarmed invasion' threatened the white race because of the possibility of white women 'crossbreeding with inferior specimens', which would lead to the end of the white race through the contamination of white blood with 'inferior blood'.

The logic of policing racial boundaries is not new. It is the foundation that all settler-colonies were built on.

'I am being harassed': Damsels in distress

The white damsel has enjoyed an online resurgence in this era of viral memes, and the past couple of years have seen a proliferation of white women caught on camera in the United States calling the police on black people for simply existing.

Perhaps no meme better exposes the dangerous fiction that lies at the heart of the white damsel in distress trope than 'BBQ Becky'. In this viral video, a middle-aged white woman can be seen on her mobile phone angrily requesting police show up to eject a black family barbecuing in a park. After many words of consternation between Becky and the white woman who is filming her, a defiant Becky refuses to return a business card belonging to the other woman and storms off.

The camera follows her, and the transformation in Becky’s demeanour is remarkable to witness. In a matter of minutes, she goes from assertive to combative to aggressive to defiant, and finally, when she spots and rushes towards a bewildered-looking white male police officer, becomes the white damsel in distress. Bursting into tears when she reaches her apparent rescuer, she manages to heave out a few words between gulping sobs: 'I am being harassed.'

This incident demonstrates that white women are not only aware of their privileged status in society but use it to surreptitiously manipulate and dominate people of colour, only to resort to the damsel in distress archetype of white female innocence and victimhood when challenged.

The original damsel in distress trope was a way for white women to exercise some limited power. I say 'limited' not because it didn’t have far-reaching effects but because it required white women to adhere to strict rules to be accepted. The damsel is an infantilised woman whose purity and innocence is both inherent and sanctified, leading to her perceived reliance on men and to the obsession with virginity that persists even in a Western world that is supposedly sexually liberated.

The damsel ensured white women were at least considered human, even though it relegated them to subordinate status. But it did so by ruthlessly excluding non-white women from the construction of womanhood. It is not that non-white women were considered inferior to white women: they were not considered to be women at all. The damsel can only be white.

Only white women were considered worthy of protecting, because only white women could ensure the continuation of a 'pure white race'. Black women, Indigenous women, brown women: all colonised women were regarded as lacking in innocence because their bodies were already freely, openly and liberally transgressed by white men.

When white women invoke the damsel, they resurrect this bloody history. This is what makes white women’s tears so damaging and, yes, so violent when they are turned against people of colour. White women’s tears have little effect on white men - just ask Christine Blasey Ford, whose emotional testimony was not enough to prevent her alleged abuser being confirmed to the US Supreme Court - because they were never designed to implicate white men. This is why sexual violence by white men was rarely punished historically and why to this day so many white people still react so blithely to sexual assault and domestic violence perpetrated by white men, even when the victims are white women. This is why a self-confessed 'pussy grabber' can be elected president of the United States.

To be a white man in the white supremacist construction is to have the right to sexual access to all women, while at the same time sequestering the bodies of white women to prevent men of colour ingratiating themselves into white society.

A white man raping a white woman is not a threat to white male power. If it threatens to destroy the woman’s life then so be it. This, I believe, is why despite all our claims our society still does not take violence against women seriously. When perpetrated by white men, frequently such violence is ignored or blame heaped onto the victim. It is only when white women are violated or even imagined to be violated by non-white men that white society suddenly seems to find its moral compass.

This is not to say that men of colour never assault white women - they do - but the scale of the white fear of brown and black men raping innocent white women with no repercussions is a gross perversion of the historical reality. White fear betrays deep-seated anxieties about white men being "replaced" at the top of the racial and gender hierarchy and white society collapsing; I don’t mean the total destruction of society here - merely it no longer being solely in the control of white men and women.

White people as a collective still fear sharing power and status. They fear no longer being the special race. The Enlightened race. The civilised and civilising race. This is obvious to anyone watching the rise of right-wing 'populism', the alt-right and the resurgence of neo-Nazis. Perhaps, as people of colour half-joke, white people fear being treated the way they have long treated the minorities they have subordinated. At the very least, there appears to be a complete denial that the only thing that has made white people 'superior' is their own insistence that they are."

## [‘Truth or Dare’: If Disney Channel Made a Horror Movie](https://www.thecrimson.com/article/2018/4/17/truth-or-dare-review/) ##
"In director Jeff Wadlow’s 'Truth or Dare,' a group of friends on spring break gets pulled into a lethal game of truth or dare. The movie had the potential to turn a juvenile game into something twisted and terrifying; instead, it feels incredibly childish. The stilted acting and shallow relationships, along with the relationship drama that seems equally important to the characters as the threat of death, are reminiscent of a Disney Channel-style horror flick. One scene steps beyond teen drama towards educational children’s television, when a character reads menacingly from a piece of paper, 'Demons can possess people, places, even ideas.' I felt transported back to fifth-grade grammar class—demons, it seems, can possess nouns.

The movie makes an effort to hit not just on every classic horror movie trope, but also on every non-horror-related cliché possible, starting with the characters themselves. There is Ronnie (Sam Lerner), the completely clueless misogynist who tags along with the group in hopes of getting laid: He provides comic relief and is obviously introduced to serve as the first kill. There is Tyson (Noland Gerard Funk), the wealthy, perfectly-groomed, overconfident boy with no morals who sells fake prescriptions and only cares about getting into medical school. His perpetually drunk, doting girlfriend Penelope (Sophia Ali), is perhaps the most interesting character, as her alcoholism is at least surprising, but even that remains unexplored. There is Brad (Hayden Szeto), the problem-solving, likeable boy who is not yet out to his policeman father. And then of course, there are the two best friends Olivia (Lucy Hale) and Markie (Violette Beane)—who supposedly mean the world to each other despite constantly fighting—and the quiet, brooding boy they are both in love with, Lucas (Tyler Posey). The clichés unfortunately extend past the characters into the writing and score. It is hard to take a movie seriously when someone unironically says, “We can’t change the past but we can still have a future.” The soundtrack also screams, 'This is a horror movie,' loud and off-putting enough to be grating but not at all scary—an unexplained creepy laugh echoes even before the end of the opening credits.

At times, the stereotypes and attempts at drama move beyond the ineffective and toward the actively offensive. For instance, the friends begin their game of truth or dare in Mexico, and the demon associated with the game follows them back to the United States. It is possible, of course, that Mexico was just the natural setting for a spring break trip. But after the fifth slow pan across the green Mexican border sign, the shot begins to seem not just repetitive but also slightly pointed—of course the unfamiliar dark magic, demons, abandoned buildings, and gruesome ancient rituals are from another country.

The script shows a similar lack of sensitivity. In another scene, Olivia is dared to sleep with Lucas, Markie’s boyfriend. The pair’s feelings for each other have been obvious since the beginning of the movie, but they have not acted on them out of concern for Markie. As Lucas begins to passionately kiss Olivia, she stops him, fearing that he is faking his passion, complaining that he has to have sex for the sake of the game. 'You have to. I don’t,' he replies, in a response that is somehow framed as romantic. In a scene meant to be the pinnacle of Olivia and Lucas’s relationship, this language unnecessarily and uncomfortably recalls issues of sexual consent. This awkward and inconsiderate writing unfortunately represents a larger trend in the film.

Wadlow cannot quite seem to make up his mind about what sort of horror movie he wants “Truth or Dare” to be. It is not particularly gory, and having the characters’ faces transform into what the movie itself acknowledges looks like “a messed up Snapchat filter” before they die dulls the impact of their deaths. The plot sets the movie up to be a psychological thriller, a seventh-grade game gone wrong, but the inner workings of the characters and the demon are not particularly interesting and the truths and dares laid out not particularly disturbing. The movie could have made good use of comedic horror—making it almost enjoyable to watch, or at least to make fun of, if not for the perpetual references to rape and suicide, which felt unemotional, out of place, and unnecessary, making it instead harder to laugh at the characters without feeling guilty.

The lack of emotion in general is almost impressive. It is quite a feat, for example, to take the emotion out of a scene depicting a son as he is forced to hold his own father at gunpoint. The characters do not grieve at all as one after another of their friends die, and Olivia, the protagonist, barely reacts when her friend literally takes a bullet for her.

The one possible redeeming feature is the concept. The idea of truth or dare—a game that is slightly sadistic even in its relatively innocent seventh-grade iteration—turned deadly and inescapable is certainly interesting. But the plot of the movie gets a little ridiculous as time goes on, and when the demon—in a move that has been annoying seventh-graders for centuries—dares someone to tell the truth, it is hard not to groan. One could also read the film, albeit generously, as a critique on social media, between the main characters’ obsession with various social media platforms, the comparison of their possessed faces to a grotesque Snapchat filter, and the demons occasional communication over social media. But even then its point is unoriginal and the moral does not justify the poor execution. The twist ending is the most compelling part of the movie, equally enjoyable both because it is surprising and because it means that the movie is finally over."

 ## [Truth or Dare Progressing to a Sexual Assault. Questions about How a Court Process Will Go, All Things Considered](https://www.reddit.com/r/legaladvice/comments/6zu3jm/truth_or_dare_progressing_to_a_sexual_assault/) ##
"A few months ago my wife was raped at a party with friends. All people involved are coworkers, and usually hung out on weekends. I have so many questions about how the court proceedings will go, whats important information and what isnt. In my understanding of the law she was 100% coerced into doing something she didnt want while she was extremely intoxicated. I'll piece it together with the information I have and with what I think.
To set the social scene, three of the five people there had recently partaken in a three-way. There was a couple who was hosting this party who we now know are swingers and like to involve women in their sex life. I have met these people, they know I exist, they know my relation with my wife who was there that night.
The night started off with drinking and playing cards against humanity. As the drinking progressed my wife suggested an addition to the game. She suggested a strip-variant, explaining it to them like strip paddidle. From there it was if you lost a game you took off an article of clothing. To my wife, this is non-sexual completely and totally. She struggled with self esteem and body issues for a long time and was finally feeling comfortable with herself, so she was letting herself be seen in that way. She explained that to me after it all and I believe her. I've never had issues trusting her and never been lied to by her so I don't doubt what she says when she explains what she understands about this situation, even if she doesn't understand every aspect.
As cards against humanity became stale to the party, I guess, the third wheel in the previous threeway group suggested truth or dare. Small (non-sexual) dares was how it started but eventually the wife of the group of three dared my wife to "like "A's" leg". (third wheel of threeway relationship) My wife took the dare and immediately after she did they dared her to have sex with A. My wife took that dare as well, and made out with/gave oral to A. I know that my wife would not want to do this sober. It's my guess that it was more about the game, and keeping the 'fun' going than it was a sexual act to my wife. My wife is far younger than these people and I believe they were acting in a predatory way when asking the things they were. At this point my wife was extremely inebriated, she was only able to explain to me and investigators/nurses bits and pieces of the following sequence. At one point someone (she does not know who) started to finger her while she was with A. She said she moved away from that because it was hurting her. She said she was not turned on and any insertion while she isn't causes her pain.
The next thing she remembers is lying down on a couch with A on top of her, kissing her. The male in the previously mentioned group of 3 sexual partners was having sex with A, while she was on top of my wife. He then, without saying anything, started having sex with my wife. My wife explained to me that her only thought at the time was "this does not feel right". The male finished, his wife cleaned up my wife then everyone went to bed saying nothing.
I recognize that understanding the whole situation for what it really was is nearly impossible without being there or being in the mind of the people involved. It is my belief that the people previously engaged in sexual relationships were together in trying to convince my wife to join them. My wife never saw that coming and did not expect what happened at all. To her, She was playing a game then the next day she realized it wasn't right. Nobody asked her anything, nobody talked about doing anything previous to that night. There was never a consensual talk about any of it.
I view the actions of the male as absolutely predatory. You can't assume consent because a woman is near you and having sex with someone you have sex with regularly. That is not consent. My wife recalls stumbling around before the truth or dare games, and had bruises from falling/bumping around.
At face value, someone had sex with someone without asking or talking about it. My wife made no advancements to the man and is not flirtatious at all. I have no idea how this will pan out in court. Its been months and the investigation is still ongoing I take it, but we have not had any word from our lawyer or otherwise. I figure that the defense will focus on the fact that she was having sex with the woman, and that seemed consensual so the rest must have been. Only over the following days did my wife understand what happened to her, and stopped blaming herself for every part of it. At the time she wanted less to stop the 'fun' and 'games' than she didnt want the people to do what they were doing, even if it involved her.
Events took place in alaska."

## [Truth or Dare: How to Protect Your Privacy from Predators](https://www.psychologytoday.com/us/blog/why-bad-looks-good/201704/truth-or-dare-how-protect-your-privacy-predators) ##
"As we enter April — Sexual Assault Awareness Month — we affirm our commitment to preparedness, not paranoia. This includes an awareness of the strategies sexual predators use to infiltrate the lives of prospective victims, both on and offline. 

We begin with the caveat that most people you encounter are safe. For every predator lurking in a crowd looking for a potential victim to approach, there are scores of law-abiding, helpful citizens ready to sound the alarm and rush to assist if they witness anyone in danger. I have summoned countless good Samaritans to the witness stand to recount their sharp-eyed observations prior to a sexual assault. 

Yet because the ultimate goal is not prosecution but prevention, proactive awareness includes a working knowledge of the methods predators use to infiltrate the lives of their victims. And the reality is that the most dangerous people are often people we already know.

Truth or Dare: A Lose-Lose Proposition

Remember the rules of Truth or Dare? It is hard to call it a “game,” because there is no way to win: You either disclose personal (often embarrassing) information or engage in reckless behavior you usually regret. Sexual predators target individuals who are willing to play.

In this column, we examine how choosing “Truth” by agreeing to reveal secrets, or proactive over-sharing, can result in dangerous disclosures.

The Truth Will Not Set You Free, but It Could Set You Up for Victimization

When interacting with manipulators, the truth will not “set you free,” but it could subject you to potential victimization. Yet many people routinely over-share, especially online. Disclosing details of emotional trauma, medical conditions, relational difficulties, or, worse, private facts about your children can endanger the personal safety of you and your loved ones.

As we have seen far too often, malicious use of private information facilitates everything from identity theft to extortion. Over-sharing is unwise, even with people you trust, and potentially disastrous with those you don't trust — or shouldn't.

Here is the frightening thing: Even when you do not intentionally reveal personal information, experienced manipulators are masterful at provoking unintended admissions. They are able to solicit private facts during polite conversation before you even realize how much you have disclosed. This dynamic is particularly potent online, where research reveals that people are predisposed to self-disclose more quickly than in person.

Transparency Prompts Reciprocity

Some people are open books, over-sharing personal details from the start. Most people who routinely provide too much information are harmless. A few are not, but those few constitute a dangerous minority, because (perceived) transparency prompts reciprocity. Recognizing that you cannot always judge a book by its cover, consider the possibility, before you reciprocate a new acquaintance's self-disclosure, that what you assume to be authentic autobiography may, in fact, be fiction. 

Long gone is the “strangers on a train” phenomenon — in which people feel comfortable sharing intimate details with a stranger they do not expect to see again.[1] Today, when you meet someone new, you can expect to be tagged, friended, and followed almost immediately after the conversation is over. And that selfie you took with your seatmate? Posted on Instagram for all to see — with both of your names and your current location.

Online Reciprocity: The Open Nook[2]

Transparency prompts reciprocity online as well, where, ironically, strangers are called “fans,” “friends,” and “connections.” Virtual acquaintances often become familiar quickly based on frequency of contact, even when they have never met in person. This superficial familiarity can lead to heightened self-disclosure — which many people already find easier online, given the relative anonymity of cyberspace.[3]

In fact, research shows that people report liking others more after interacting with them online, and feel they know them better, than when they meet in person.[4] These feelings often fuel a desire to move an online relationship offline.[5]

Online Show and Tell

Another way sexual predators learn private information about prospective victims is through online "show and tell." Many people overshare on social media — both visually and verbally. Studies demonstrate that extraverts are particularly likely to go overboard, as they are more likely than introverts to upload photos and to update their status more frequently, and to display more friends on their Facebook wall.[6] Extraverts also “Like,” “Share,” and “Comment” on the News Feed more frequently less outgoing peers.[7]

Exploiting the Selfie

Selfies are another common way of showcasing ourselves online truthfully — through posting real photos taken in different contexts. Research indicates that motivations for posting selfies on social networking sites include communication, attention seeking, archiving, and entertainment.[8]

Predators capitalize on the fact that selfies are often posted in pursuit of attention — which they are more than willing to provide — all for the wrong reasons. Because selfies reveal values and interests, online reaction provides validation through affirming self-worth.[9] Selfies thus provide a method of self-promotion through impression management.[10]

Manipulators also, however, exploit the reality that selfies provide a direct route to relationship building. Selfies stimulate relationships by sparking online dialog, such as through replies to comments about one's photo postings.[11] Manipulators can then use an individual's truthful information to build a relationship designed to eventually facilitate sexual exploitation.

The bottom line is to use caution when revealing truthful information. Do not overshare, think before you tweet, and when in doubt, leave it out."


----------


# Southern Culture #
## [Southern Gothic](https://oxfordre.com/literature/view/10.1093/acrefore/9780190201098.001.0001/acrefore-9780190201098-e-304) ##
"Southern Gothic is a mode or genre prevalent in literature from the early 19th century to this day. Characteristics of Southern Gothic include the presence of irrational, horrific, and transgressive thoughts, desires, and impulses; grotesque characters; dark humor, and an overall angst-ridden sense of alienation. While related to both the English and American Gothic tradition, Southern Gothic is uniquely rooted in the South’s tensions and aberrations. During the 20th century, Charles Crow has noted, the South became “the principal region of American Gothic” in literature. The Southern Gothic brings to light the extent to which the idyllic vision of the pastoral, agrarian South rests on massive repressions of the region’s historical realities: slavery, racism, and patriarchy. Southern Gothic texts also mark a Freudian return of the repressed: the region’s historical realities take concrete forms in the shape of ghosts that highlight all that has been unsaid in the official version of southern history. Because of its dark and controversial subject matter, literary scholars and critics initially sought to discredit the gothic on a national level. Edgar Allan Poe (1809–1849) became the first Southern Gothic writer to fully explore the genre’s potential. Many of his best-known poems and short stories, while not placed in a recognizable southern setting, display all the elements that would come to characterize Southern Gothic.

While Poe is a foundational figure in Southern Gothic, William Faulkner (1897–1962) arguably looms the largest. His fictional Yoknapatawpha County was home to the bitter Civil War defeat and the following social, racial, and economic ruptures in the lives of its people. These transformations, and the resulting anxieties felt by Chickasaw Indians, poor whites and blacks, and aristocratic families alike, mark Faulkner’s work as deeply Gothic. On top of this, Faulkner’s complex, modernist, labyrinthine language creates in readers a similarly Gothic sense of uncertainty and alienation. The generation of southern writers after Faulkner continued the exploration of the clashes between Old and New South. Writers like Tennessee Williams (1911–1983), Carson McCullers (1917–1967), and Flannery O’Connor (1925–1964) drew on Gothic elements. O’Connor’s work is particularly steeped in the grotesque, a subgenre of the Gothic. African American writers like Zora Neale Hurston (1891–1960) and Richard Wright have had their own unique perspective on the Southern Gothic and the repressed racial tensions at the heart of the genre. Southern Gothic also frames the bleak and jarringly violent stories by contemporary so-called Rough South writers, such as Cormac McCarthy, Barry Hannah, Dorothy Allison, William Gay, and Ron Rash. A sense of evil lurks in their stories and novels, sometimes taking on the shape of ghosts or living dead, ghouls who haunt the New Casino South and serve as symbolic reminders of the many unresolved issues still burdening the South to this day."

"“Southern Gothic” is the label attached to a particular strain of literature from the American South. The style of writing has evolved from the American Gothic tradition, which again evolved from the English Gothic tradition. Horace Walpole’s The Castle of Otranto (1765) is considered the first Gothic novel, and Ann Radcliffe is seen as a cofounder of the genre thanks to Gothic romances such as The Mysteries of Udolpho (1794) and The Italian (1797). Several scholars have attempted to categorize the Gothic: H. L. Malchow defines it not as a genre but a discourse, “a language of panic, of unreasoning anxiety.”1 David Punter points to the themes of paranoia, the barbaric, and taboo,2 and Allan Lloyd-Smith states that the Gothic is “about the return of the past, of the repressed and denied, the buried secret that subverts and corrodes the present, whatever the culture does not want to know or admit, will not or dare not tell itself.”3 Specific definitions aside, Gothic literature generally challenged Enlightenment principles by giving voice to irrational, horrific, and transgressive thoughts, desires, and impulses, thereby conjuring an angst-ridden world of violence, sex, terror, and death. As Jerrold Hogle notes, since the 18th century, Gothic fiction has enabled readers to “address and disguise some of the most important desires, quandaries, and sources of anxiety, from the most internal and mental to the widely social and cultural.”4

The Gothic finds its footing in the United States in the early 19th century. Charles Brockden Brown, the first professional American author, is credited with inventing the American Gothic novel with Wieland (1798). According to Eric Savoy, what makes Brown’s novel stand out is the way in which it “resituate[s] ‘history’ in a pathologized return of the repressed whereby the present witnesses the unfolding and fulfillment of terrible destinies incipient in the American past.”5 Apart from Brockden Brown, scholars have found it difficult to pinpoint a foundational era or group of authors for the American Gothic. Indeed, Leslie Fiedler has argued that the American Gothic tradition is best understood as “a pathological symptom rather than a proper literary movement,”6 and Teresa Goddu has noted “the difficulty of defining the genre in national terms.”7 Some scholars have listed criteria in order to define the genre. Allan Lloyd Smith sees “four indigenous features” marking the American Gothic as distinct from the European version: “the frontier, the Puritan legacy, race, and political utopianism.”8 Yet others hesitate at using the term “genre” and talk instead of the Gothic as “a discursive field in which a metonymic national ‘self’ is undone by the return of its repressed Otherness.”9 What critics do seem to agree on, however, is the way in which American Gothic texts in general have challenged the American Dream narrative by consistently pointing out limitations and aberrations in the progressive belief in possibility and mobility. Eric Savoy points out the irony of the Gothic’s predominance in American culture. In a nation whose master narrative is grounded in rationalism, progress, and egalitarianism, Savoy points to “the odd centrality of Gothic cultural production in the United States, where the past constantly inhabits the present, where progress generates an almost unbearable anxiety about its costs, and where an insatiable appetite for spectacles of grotesque violence is part of the texture of everyday life.”10

Nowhere in the United States is the Gothic more present than in the South, which Allison Graham describes as a “repository of national repressions … the benighted area ‘down there’ whose exposure to the light is unfailingly horrifying and thrilling.”11 Flannery O’Connor famously declared that the so-called Southern school of literature conjured up “an image of Gothic monstrosities and the idea of a preoccupation with everything deformed and grotesque.”12 Add to this Benjamin Fisher’s definition of the literary Gothic as something that evokes “anxieties, fears, terrors, often in tandem with violence, brutality, rampant sexual impulses, and death,”13 and it becomes clear how the tradition of the Southern Gothic plays into already established ideas about the South as an “ill” region. This notion was established early on, as Charles Reagan Wilson has shown: the “deadly climate that nurtured diseases” and killed off early Jamestown settlers, and later colonists in Lowcountry North Carolina created an image of the South as “a death trap.”14 Centuries later, William Faulkner, arguably the greatest Southern Gothic writer, has one of his characters in As I Lay Dying (1930) echo this view of the South: “That’s the one trouble with this country: everything, weather, all, hangs on too long. Like our rivers, our land: opaque, slow, violent; shaping and creating the life of man in its implacable and brooding image.”15 Another central figure of Southern Gothic, Tennessee Williams, continues in the same vein, when he writes that, “there is something in the region, something in the blood and culture, of the Southern state[s] that has somehow made them the center of this Gothic school of writers.” These writers share “a sense, an intuition, of an underlying dreadfulness in modern experience.16

While related to both the English and American Gothic tradition, the Southern Gothic is uniquely rooted in the region’s tensions and aberrations. The United States may not have had old castles in which writers could place their Gothic romances, but after the Civil War, the many often ruined or decaying plantations and mansions in the South became uncanny locations for Gothic stories about sins, secrets, and the “haunting history” of the South.17 And while Southern Gothic can be said to fulfill the criteria set out by scholars like Punter and Smith, increasingly, Gothic in an American context has come to connote the American South. During the 20th century, the South became “the principal region of American Gothic” in literature.18 As Charles L. Crow points out, the term “Southern Gothic” “became so common in the modern period that each word came to evoke the other,”19 as southern writers increasingly explored a region burdened with contradictory images. On the one hand, the colonial and antebellum South has been constructed as a pastoral idyll, an agrarian garden free of toil. On the other hand, the South has been seen as a repository for all of America’s shortcomings: a region of sickness and backwardness symbolized by everything from yellow fever and hookworm disease to personal and societal violence.

Southern Gothic brings to light the extent to which the vision of the idyllic South rests on massive repressions of the region’s historical realities: slavery, racism, and patriarchy. In this way, Southern Gothic texts mark a Freudian return of the repressed: the region’s historical realities take concrete forms in the shape of ghosts or grotesque figures that highlight all that has been unsaid in the official version of southern history. Leslie Fiedler’s claim that the “proper subject for American gothic is the black man, from whose shadow we have not yet emerged”20 helps explain the propensity, the pull of the Gothic in southern literature. Its uncanny and haunted effects echo the old Gothic tradition but serve as a specific comment on southern life and customs."

"A subgenre or additional aspect of Southern Gothic is the grotesque, also called Southern Grotesque. Scholars have long argued about the differences between the two terms, and many simply equate the two and use them interchangeably. As Charles Crow notes, the grotesque, “is a quality that overlaps with the Gothic, but neither is necessary or sufficient for the other.”21 Characters with physical deformities, so-called freaks, feature heavily in the Southern Grotesque. Often, their physical disfigurements—limps, wooden legs, cross-eyes, crippled limbs—serve as markers of a corrupt moral compass and point to the ways in which writers of Southern Gothic engage with the discrepancy between perceived, heteronormative normalcy and the repressed realities beneath that assumption. While deformed characters may be one of the most evident markers of Southern Gothic,22 the grotesque has been credited with invoking everything from “horror and the uncanny” to “sadness, compassion or humour.”23 The apparent breadth of grotesque traits threatens to empty the term of any useful meaning. But what unites the many features of the grotesque as well as its effects is a disturbing juxtaposition of conflicting elements; a site of transgression that serves to challenge the normative status quo, which in the South has been particularly repressive when it comes to race, gender, and sexuality. This links the Southern Grotesque to Mikhail Bakhtin’s notion of the carnivalesque, which, among other things, functions as a strategy of transgression, resistance, and disruption.24 This disruption that the grotesque produces is not of the “aberrant body,” as Melissa Free argues, “but of the social body that silences and condemns deviance.”25 Flannery O’Connor is perhaps the best example of a Southern Gothic writer who relies on the grotesque in her work. In her influential essay “Some Aspects of the Grotesque in Southern Fiction” (1969), O’Connor challenged the reductive generalization of the grotesque as a term and stressed how grotesque literature pointed toward a particular kind of realism:

Rather than a sensationalist freak or horror show, grotesque literature cuts through the veil of civility, through decorum and oppressive normative fabrications to expose a harsh, confusing reality of contradictions, violence, and aberrations."

"For many of the Agrarians, Richard Gray notes, “to write of the ‘unknown people’ of the Southern countryside was not to write as a Southerner; it was doubtful if it was even to write as an American.”42 It was not only white writers who were excluded from the canon. Michael Kreyling notes how the Agrarians and their “disciples in the 1940s and 1950s” obstructed “the inclusion of black writers,” like Richard Wright.43"

"Other examples of Faulkner’s southern Gothicism can be found in many of his greatest novels. The Sound and the Fury (1929) traces the downfall of the Compson family, one of Faulkner’s many “failed dynasties of the old ascendancy … all unwitting builders of haunted houses.”49 The novel’s first three sections are narrated by the three Compson sons—the mentally handicapped Benjy, the brooding Quentin, and the malicious and patriarchal Jason—while the fourth and final section has the black maid Dilsey as the central character. This makes for a fragmented and unreliable story in the center of which is the Compson daughter, Caddy—the obsession of all three brothers, “both victim and perpetrator … [a] Gothic heroine” who “escapes her haunted mansion at a terrible price.”50 Quentin is haunted and obsessed with his failure to protect his sister’s virginity. His oppressive sense of guilt eventually drives him to suicide. As I Lay Dying (1930) features variations of the vengeful spirit and live burial themes as well as emotionally unstable characters, all supported by an overall sense of confusion and fragmentation brought on by the rapidly shifting narrators. Sanctuary (1931), Faulkner’s most sensational and scandalous novel, features a controversial rape scene where the debutante Temple Drake is penetrated with a corncob by the sadistic and impotent villain Popeye. Though initially scorned by critics, Sanctuary has more recently been re-examined in light of its mirror structure and also “revalued as symbolic of the rape of southern womanhood by outside forces.”51 Light in August (1932) has been read as “an exemplary of the traditional gothic tale of mystery, horror, and violence in America.”52 It is a novel fueled by a sense of alienation and otherness, and features marginalized characters attempting but failing to make human connections. Joe Christmas, a black man passing as white, is accused of sleeping with and murdering a white woman. After escaping from jail, he is castrated and killed. The novel’s Gothicism is significantly southern in its exploration of religious zeal, sex, and racism, including violent lynchings and the pervasive fear of miscegenation."

"American theater of the 1940s and 1950s was infused with a heavy dose of Southern Gothic sensibility thanks to the plays of Tennessee Williams (1911–1983). Characters with varying degrees of illness populate his works, and his own sexual orientation, socially unacceptable at the time, found its way into plays such as Cat on a Hot Tin Roof (1955), in which Brick, who is gay, struggles with his unhappy marriage and with his dying but domineering father, Big Daddy. In other plays, such as The Glass Menagerie (1944), A Streetcar Named Desire (1947), and Sweet Bird of Youth (1959), Williams created Gothic spaces of boundary crossings as well as other familiar tropes of the Southern Gothic, such as disintegrating southern families, alienation, loneliness, alcoholism, and physical and psychological violence. Rather than a mere freakshow, Williams uses the characters in his plays to question the notion of normalcy and to explore the discrepancies between private and public selves. His plays, as Stephen Matterson argues, point to the performative aspects of all our lives, but perhaps especially those lived in the South, a region that in Williams’s plays is presented as an incongruous site of Romantic myth and urban, modern reality.69 The struggle of his characters to come to terms with the discrepancy comes off as essentially heroic, embodied best, perhaps, in Blanche DuBois from A Streetcar Named Desire (1947): the southern belle trapped in the modern world.

While he worked in many genres, Truman Capote (1924–1984) is often placed in the school of Southern Gothic writers. Other Voices, Other Rooms (1948) relies on obvious elements of Southern Gothic, from its secluded, decaying mansion at Skull’s Landing to scenes of pedophilia and violence, as well as characters drawn from the grotesque vein of Southern Gothic: a crossdresser, a mute quadriplegic, and a dwarf. Capote’s childhood friend Harper Lee (1926–2016) wrote perhaps the most widely read and most-loved Southern Gothic of the 20th century. The Pulitzer Prize-winning To Kill a Mockingbird (1960) is told by the tomboy Scout and draws on Gothic traits to examine boundaries of race, class, and gender in the 1930s South. Gothic elements include the children’s fear of the mysterious neighbor Boo Radley, as well as a rabid dog, and a Halloween night in which fear of the supernatural pales in the face of the violent, alcoholic, and racist Bob Ewell, who attacks Scout and her brother Jem with a knife."

## [The Uncultured South](https://www.vqronline.org/essay/uncultured-south) ##
"Has the South been buffaloing America for half a century into thinking it was a second Athens wrecked by a Northern barbarian democracy, when actually the second Athens drank mint juleps, ate batter-bread, and thought up moral defenses for the institution that made life comfortable? Is the culture of the Old South a myth?

Or was the Pennsylvanian right who said: 'Why do I live in Virginia? Because Virginia once had a civilization. It hasn’t one any longer, of course. But it did have one once. And Pennsylvania never had a civilization.' Apparently, even Pennsylvanians have admitted the Old Southern culture.

There is no use asking the South. The South has been on the defensive for so many decades that it has lost the art of self-examination. And since the World War, the South has been sold on progress, with the result that under the guidance of its Young Men’s Business Clubs it has deserted its glorious bloody past for a rosy and profitable future. Its traditions are turning into points of interest. It is capitalizing the Lost Cause.

And yet, one would like to know who is right about this business of an Old Southern culture. What does intelligent America, outside the South, think? In pondering the matter, I am inclined to believe that the American attitude towards the Old South has passed through three distinct phases: the third phase, the batter-bread expos is a thing of recent years. The three phases are worth comparing.

Before 1860 the Southern planters were the greedy plutocracy of slaveholders in a day when all other civilized countries had abolished slavery, grabbing for new territories into which they might extend their 'peculiar institution,' thus holding their balance of power in a “free” republic. To that republic they were by their very nature a menace, just as the republic was a menace to conservative Europe. 'Not by, aggression,' wrote Oliver Wendell Holmes, 'but by the naked fact of existence we are an eternal danger and an unsleeping threat to every government that founds itself on anything but the will of the governed.' Similarly in a land that promised the destruction of all privilege, the Southern slaveholder was a mockery to hopeful utopists and a pledge of possible reaction. Before the Civil War, therefore, the North dreaded and vilified the Southern system.

After the Civil War the North offered cordiality in exchange for penitence. It even offered a queer kind of sentimentalized love. Now that the North had “licked” the South, it could afford to love it. Lo the poor planter, having been broken at Appomattox, had much to be said for his way of life. The South has been widely accused of slobbering about its destroyed system but actually the South has been more slobbered over than slobbering. I have never met a profounder or marshier sentimentality than the applause of certain Northern crowds when the band played 'Dixie.' All of which has been psychologically very bad for the South. She was undoubtedly sick, but an overdose of sympathy never helped sickness yet.

Lee and Jackson were traitors while McClellan’s act was on. But with Appomattox a dim memory, Lee’s stock went up in the North and the North bought in by the block. They ended up by feeling a sort of pride in a national pageant that had a happy ending.

For example: in a London theater I sat watching Drink-water’s 'Robert E. Lee.' Between acts I listened to the audience struggling with teacups and chocolates and fought to keep from crying. The lady next me was from Indiana but took me for an emotional Britisher.

'I don’t suppose,' she began informatively, 'you know much about this. We study it in School. It’s History, for us. My grandfather fought in this war—of course on the winning side.' Of course. My contention is that as the winning side the North took a generous interest in the South and that, provided the South accepted the Northern social economy, the North luxuriated in approval for the fallen tyrants whose spacious lives they almost envied.

Moreover the strings were there. The South was expected to be glad the right side won. Only last October, at Fredericksburg, Virginia, President Coolidge, in his campaign speech over the Confederate dead, congratulated the South on getting beaten and on being glad they were beaten. Assuming they really were glad, he praised Lee. I used to experiment by declaring to Northerners that I regretted the South had failed to win her independence. My remark always dried the springs of sympathy in a hurry: in short, my. experiment succeeded.

However, after the war fewer and fewer Southerners made this experiment, and the North was free to indulge a safe sympathy. The North even took to romancing about it, as industrial England romanced about feudalism. For a thousand reasons the feudal barons of Norman England and the cotton barons of the British Empire could never have tolerated each other in the flesh. But in the grave the feudal barons shed a safe and glamorous luster. Hence romanticism.

Similarly the slave system did not seem wholly bad in retrospect. Freed by Emancipation from the nightmare of Uncle Tom’s Cabin, the North took note of the Southern mammy, the pickaninnies, the leisurely life of the plantation, and wove a sweet dream about it. The plantation owner became in this dream a kindly, cultivated master, dividing his time between his acres, his library, and good conversation. Material for his portrait was drawn from three sources: the necessity to flatter, by a law of psychological compensation, what one had been compelled by morality to destroy; the inherited respect for upper-class privilege that a century’s war on privilege had not obliterated; and a vivid imagination, which read into the planter of the Old South those qualities the raw democracy was most ashamed of lacking and most wanted to acquire. The result was a very romantic portrait indeed.

But now came the realistic analysts, known in the New Age of Reason as the 'de-bunkers.' They pounced on that faded splendor of honeysuckle and magnolia and they announced, and are announcing in a palpitation of discovery, that the honeysuckle and magnolia were there but the books were not, nor were the Shakespeares and Raphaels and Mozarts. And, of course, magnolias are not culture. Just because the Old South was tragic in its ruin, there is no use romancing about it. There is more culture, more creative art, in New York today, and indeed in living Southern novelists, than the Old South ever dreamed of.

Why have these analysts only just appeared, and is there anything in what they say? There is rather obviously, in the New York sense. New York is measuring culture by creative art and comically but inevitably enough by the amount of creative art. New York wants better novelists but it also wants more of them. New York studies art output, and with growing pride. The publishers, critics, and art dealers are particularly impressed, and they cue the public. America hopes for an imminent Renaissance.

An imminent Renaissance would have mystified the planters. In the first place theirs remained a distinctly colonial culture long after the American Revolution. They were in many respects an English squirarchy more inconveniently distant from the London Season than squires in Yorkshire or Devon. But they sat down to tables of Santo Domingo mahogany turned in London, before English plate, to drink the same wines Englishmen were drinking. They frequently sent their sons to English universities. They were economically, and to a far greater extent socially, colonials.

For that reason their libraries were often astonishingly complete but ran to classics, not novelties. Anybody who has ever seen the ghost of one of those plantations knows that, living there, one would want Dryden and Pope, Fielding and the learned Doctor Samuel. And every time one of those libraries goes under the hammer I am struck afresh by the solidity of the planter’s literary digestion. They read what their class in England read.

Their portraits are frequently from European hands. I imagine this struck them as natural. Europe was in every respect a more suitable environment for an artist than young America. And I do not believe the planter’s patriotic heart ached because there was so little home talent. The cultivated class of Southern planters were part of the same cultural complex as Europe, and their geographical position and isolated manner of living condemned them to be consumers rather than producers. Most cultivated persons at any time in any place are consumers; or ought to be. It is a fairly recent thing to have everybody about to write a novel. And the line between self-expression and exhibitionism wobbles only too readily.

Culturally indeed the planters were in one line producers. They were rulers by instinct and training, and artists in war and politics. A glance at the roll call of planter statesmen from Jefferson on, and of the men who led the South’s last army, suffices to illustrate this. The South maintained what is so conspicuously absent from America today, a ruling class, bred for the purpose.

Like every genuine ruling class the planters held to a code of manners. And manners can be a very definite art. To live gracefully, harmoniously, and freely may be as creative as Russian ballet and more truly creative than a book about one’s not always interesting friends, written in a seldom interesting manner.

Or take hospitality. There has been a vast amount of twaddle talked about Southern hospitality. The fact remains that, where still practiced, it is an art as complex and as easily recognized as the weaving of real Persian rugs. By people, of course, who know good rugs. Twelve years ago a traveller told me Southern hospitality was a myth. He had visited every big town in the South and they were the most intolerably inhospitable places he knew. No theaters, no amusements, and a courtesy that nevertheless forbade intimacy. This confusion of hotelling and hospitality tells the whole story. My friend would fare better in the New South, where the Chambers of Commerce would care for him. They would make him pay for it, but he would expect that. His only trouble was wanting to buy what was not for sale. And if I had explained that he had no letters of introduction he would have snorted at Southern snobbery.

Probably the planter’s least American trait was his exquisite sense of leisure. He enjoyed life enormously and his zest was not based on externals, on money, on success. He worked to make life possible but he never made a god of occupation. And this leisure permitted him to flower as a human personality. Since flowering is the last thing a democracy will ever understand, America asks the planter if his leisure was fruitful. That depends on what we consider fruit. Shall one measure life by output or beauty? Which would an artist do?

His leisure brought the planter one of his most successful minor arts and one he most delighted in—good conversation. For in his virtues and in his vices alike he was a social animal. The best Southern conversation, even what is left of it today, has led me to believe that it may be the most delightful oral literature now alive in any civilized or semi-civilized country. And when the Southerner told a perfect anecdote and told it as perfectly as that anecdote could be told, he did not call for the printer and start figuring royalties. He told another. The truth is, an original mind that is not haunted by the awful fear of being uninformed, that is illumined by a playful humor not based on vaudeville wise-cracks or jaded slang, is as rare in America as a knowledge of good wines. Hence our very general and panicky boredom; hence the fact that we so often bore others. I am not fool enough to suppose that this good conversation and this quiet leisure would pass as cultural currency in the America that came of age. At best, they would have the value of Confederate money: they are antiques. They can be collected, but they are not the basis of America’s economy or of her culture. There is no Federal Reserve behind either one. And it is, of course, pure romanticism to think that leisure can stand up against Rusiness, or Confederate notes against greenbacks: this sort of competition is settled by “economic necessity,” which commonly plays havoc with culture. We Americans admit that leisure is good; we even subsidize research workers to study how to use it; but we will not let it interfere with Life. To the planter, leisure did not have to be studied: it was itself the basis of a life worth living.

I have been guilty here of writing what many know as well as I, and of venturing many unproved generalizations, as indeed one must if one compares two social orders at all, in an effort to see whether a case could not be made out for an Old Southern culture, whether the planter’s way of life did not imply a culture even in the absence of a stream of printed matter, canvases, and sonatas. I can both cut short and clarify my discussion by stating that the essence of the Old South was a spirit of aristocracy.

Aristocracy exists only where there is faith in the worth-whileness of some intangible values. And only where there is that faith can life have a more significant form than the form achieved in a pigsty. The Old Southerner believed in a whole list of musty-sounding intangibles that curl the lip of the democracy: courage in men, chastity in women, hatred of lying, scorn of greed, loyalty to one’s superiors, fidelity to one’s retainers, reticence in intimacy, grace in all things. He could not prove they were worthwhile; nor can the democracy prove they are not. But that is how he felt about life—which is the Law for aristocracy.

To the average American today the Southern planter is as weirdly comic as Don Quixote. But nothing whatever is proved by that except that he is growing very rare. Sometimes he is laughed at. Mostly he is just overlooked. But now and then when democracy does see him or hears one of his funny abstract words again, it challenges his claim to culture. Well, he took his another wav. He took a frank pleasure in the good things of life, including a number of world literatures. But he could never have grasped the bourgeois-proletarian concept of self-improvement. The fact of aristocracy was to him one of the most obvious facts of life. Some of his land was better than the rest and therefore better for certain crops. He had draught horses for hauling, and thoroughbreds to race. He believed his negroes were better fitted to work than to rule. Some white men were “better bred” than others and therefore better fitted to lead and direct. These were facts. Land could of course be improved; so could horses; so could people, over stretches of time. Sometimes lower breeds threw out an extraordinary individual, but mostly breeds ran true to form—a fortunate fact for a planter. The American credo that holds college courses as universally desirable and looks to correspondence schools as a means of converting ill-bred people into the other sort would have struck him as a lamentable farce. A percheron need never be ridiculous except on the track.

It is this profound cleavage between the democratic and the aristocratic sets of values that is responsible for the three successive attitudes America has adopted toward the 'South.' Before the Civil War the Southern oligarchy with all the strength of axiomatic tradition behind it threatened to wreck the American experiment. Appomattox broke that oligarchy on the wheel. It did not mean that never again should the South be powerful, but it did mean that its power must never take aristocratic form. America, at least the Eastern states, no longer afraid, wove romances around a social system still dormant in its own blood. But during the last decade the American democracy, bourgeois-proletarian in spirit, has so completely obliterated every other social form that the Old South is losing even its romance. Half amazed and half relieved, America realizes that she does not really want the things the Old South wanted, except power, which she has in increasing abundance. America wants to read more books, see more things, build more houses, acquire more culture. And the South never tried to acquire it. America doesn’t believe the South ever had a culture.

The other day as I was leaving Woolworth’s in a small Southern town, an old gentleman of the planter breed, more than a generation my senior, started to enter. Unfortunately at that very moment a number of flappers started out. The old man stood back, holding the door open. I counted over twenty people, men and women, who rushed past him without a word. I shall always treasure the memory of his smile. The pigs were in the parlor, and he had the courage to smile! It would be more worthwhile for us Americans, Northerners and Southerners, to study that smile than to read the riddle of the Sphinx. Regardless of culture."

## [The Evolving Southern Gothic: Traditions of Racial, Gender, and Sexual Horror in the Imagined American South](https://oaktrust.library.tamu.edu/bitstream/handle/1969.1/155404/COTHREN-DISSERTATION-2015.pdf?isAllowed=y&sequence=1) ##

## [Gender, Power, and Whiteness in Rodeo: Breaking Away from the Ties of Sexism and Racism](https://books.google.com/books?id=xcjq7_dG1RYC&pg=PA7&lpg=PA7&dq=cowboys+west+damsels+in+distress+south&source=bl&ots=pYgLRHxQl4&sig=ACfU3U3Zx-kziU3AmBTgdPzgksPsmq6ZwA&hl=en&sa=X&ved=2ahUKEwj1_Lj8ooHvAhU2MlkFHaWmB0UQ6AEwEXoECBAQAw#v=onepage&q=cowboys%20west%20damsels%20in%20distress%20south&f=false) ##
"When I was a little girl, in the mid-1950s, I wanted more than anything than to be a cowgirl."

"The lure of cowgirls and cowboys", "the American imagination"

"a symbolic representation of the Western United States"

"the late 1800s"

"the idea of Manifest Destiny through taming the wild"

"the popular culture story at the surface - the one that is retold, repacked, and visually revised as U. S. white and male"

"the largely all-White all-Male rodeo myth"

"the narrative of the West"

"The cowgirls of today were born of the Eastern settlers from the period of the Western settlement, or Manifest Destiny. These women came from the East to settle and establish a new life with their husbands and families, with a focused goal to 'tame' the West. The pioneer women wore prairier dresses and bonnets, focused on education, and worked long hard hours to feed, clothe, and even protect their families from danger. These women were known as 'Prairie Madonnas' who 'made great pies, babies, and flour sack curtains...She kept immaculate house under impossible conditions - floors of raw dirt or unfinished woo' and she 'could handle a gun or help with the stock if her husband were away when the Indians attacked or if the cows broke down the fence." 

"the oral histories", Teresa Jordan's book, "Cowgirls: Women of the American West"

"A popular writer from this era was Laura Ingalls Wilder"

"the Western frontier"

"the cowboy image"
"the frontier cowboys"

"culture", "a way of life"

"This book is about moving marginalized individuals in rodeo to the center; however, we cannot possibly tell the whole story. The ignorance of history, a belief in a White Western narrative that erased the contributions of Lation/as, American Indians, and African Americans, and the effects of racism and White privilege are why all those in rodeo are believed to be either White and/or White males. We are unable to resurrect those cowgirls likely that Wister saw and had knowledge of Latino, American Indian, and African American cowboys. Wister also knew that women were in the West, and yet their participation is erased, as well. In Wister's revisionist telling of the 'wild West' he recounts and admires only the hard, industrious work of White men. Through the creation of *The Virginian*, in 1902, Wister 'created the archetypal cowboy hero stamped with particular qualities that virtually all his successors would perpetuate. The creation of the archetypal cowboy and the use of the White man to be the hero to fight the villains of the West (normally seen as the 'Wild' Indian or Mexican 'Desperado'), and saving White women from the dangers of the West established rigid gender stereotypes. The establishment of these gender roles helped influence the positions that owmen and ethnic minorities have in modern rodeo, because they reifed the social norms and themes that were constructed in the United States for what was appropriate for each group of people. Wister's focus on admiration for the White race sat well with his contemporaries like Rudyard Kipling, as well as with other U.S. policy and laws of the time. For example, in 1896 the U.S. Supreme Court passed the Federal Plessy v. Ferguson law, which ushered in Jim Crow, or a 'separate but equal' policy, which segregated Black and White Americans. This Federal law remained in place through 1964. In addition, in 1900 White males in the U.S. elected William McKinley, who further popularized Kipling's 1899 poem 'The White Man's Burden,' a treatise on 'the white man's burden' belief, which focused on cultural and racial imperialism. In 1900, this policy impacted U.S. and Philippines relations and U.S. and China relations (the Boxer Rebellion in China), and in 1901 it affected U.S. and Cuban relations (the Platt Amendment). Not suprisingly, given this time period and the aforementioned U.S. laws, the myth of the West and the myth of rodeo are tied to White westward expansion. There is a parallel etween the dangers the pioneers faced during their quest of Manifest Destiny - the hostile elements, raging rivers, outlaws, Indians - and the cowboys' dnagers faced in rodeo. Later, these same racist ideals were put on film when Thomas Dixon's book, *The Clansman* (1905), was turned into the move, *Birth of A Nation*, which was directed by D. W. Griffith in 1915. Dixon was a classmate of former President Woodrow Wilson, and Wilson had a special screening of the movie at the White House, where the Supreme Court was also in attendance. As media scholar Donald Bogle noted, the film 'would work audiences into a frenzy...[I]t will make you hate.' This movie heralded the KKK as the saviors of the White race and protectors of White womanhood and virginity from the Black male brute who was no longer controlled by the system of slavery, and increased White male membership in the terrorist organization."

"legal scholar Margaret Russell"
"through a carefully constructed fusion of unprecedented technical wizadry and degrading racial stereotypes, Griffith sought to convince his audience that his was the 'true' story of the old South and that white domination was necessary for their survival. To a great extent, he succeeded: The film's enormous popularity fueled the growing influence of the Klan, and *The Birth of a Nation* remains to this day one of the highest-grossing box office successes in Hollywood history." 

"Wister's novel went through 'fifteen printings during the first eight months after its publication; by 1911 it was in its thirty-eight printing. By 1938, it had sold mroe than one and one-half million copies.'"
"While not everyone embraced Wister's East Coast take on the West, and while other novels later existed, *The Virginian* was considered a seminal work that cemented the myth of the White American West in the U.S. imagination, as well as of the iconic stoic, independent cowboy, who is always visually depicted as a White man."

"The American cowboy is idealized in folklore as masculine, independent, and an explore. Curiosity as a foundational element of human existence led to the stereotype of the cowboy myth, which continues to be embraced. Early explorers liek Coronado in 1541, and later Lewis and Clark in the early 1800s, said the American West was a vast open plain, a desert where one could conquer man, land, and beast. The untamed elements of the Western frontier remain static in the narrative of the West. Ideally, the American cowboy and the narrative of the Western frontier were painted with heroic myths worthy of 'god-like' worship, whereby the embellishment of the narrative outshone the lived reality of the frontier."

"The exclusionary dominance of the White cowboy as a representative of the West in rodeo depictions and as portrayed in dime novels, film, and folklore is that he is believed to be anyone: that person any White Anglo Saxon Protestant (WASP) male could become."

"He is not complicated in his white/black binary vision of the world; you are either good or bad and the judgment coms from his 'correct' attitudes, beliefs, and values, which are ideals found within the cowboy culture and code - the Code of the West. He symbolizes the possibility of what can be achieved thorugh a hard work ethic and through traditional gender roles that reinforce Victorian ideals of White womanhood, e.g., a helpless virginal damsel in distress who needs the protection and direction of a strong man to react against any transgression committed against her. Our hero in this Western White myth is complete with his leathered face and Western drawl. He is armed with is trusty six-shooter, while keeping an eye out for American Indians. '[The] Anglo-Saxon cowboy and the Red Indian emerged as convenient action heroes. These simplified stick figures propagated a frontier mythology that hid both the systemic violence of conquest and the modern incorporation of land and labor. Cowboy hats and warrior headdresses obscured the complex racial politics of the United States and created instead a ronatic duel of white against red.' From this duel of reductionist cowboy ideals, race, and land emerged an American iconic myth (the cowboy) that is actually a conglomeration of 'White conquering West' rhetoric, media fascination, and myths - like the explorations of Daniel Boone - which loomed larger than life. The myths of man besting beast carried over into the rodeo cowboy arena."

"The cowboy represents the taming of the forces of North American civiliziation. In the arena, these great forces clash. The cowboy hero attempts to 'tame the wild...'"

"Wister's novel went through 'fifteen printings during the first eight months after its publication; by 1911 it was in its thirty-eight printing. By 1938, it had sold more than one and one-half million copies.'"

"the histories of the American West...[of] heroci tales: stories of adventure, exploration, and conflict."

"overcome a conflict, seek adventure, and explore new territory"

"The rodeo cowboy is only one of the numbers of modern occupational folk hero types, yet he is a fascinating one. He is, after all, a modern man - he lives in industrial America...sleeps at the Holiday Inn....[Y]et on the other hand he is a cowboy - representing facets of North America's past that evoke powerful rural and pre-industrial images. This makes for a fascinating paradox."

"The rodeo cowboy embodies two different men. On one hand, he is modern and experiences all of the modern conveniences that are available, yet he is also a man whose job it is to recreate the Wild West for entertainment. He retells an age old story of good versus evil while attempting to tame the wild, even while making a career out of being a show performer. The rodeo road for our cowboy hero has been built from a diverse history, starting with the Wild West shows."

"Amazon" - "cowgirls"

"Free fromt he confines of the corset, cowgirls were seen as powerful, as talented, and with fewer restrictions placed upon them. The transition from a Victorian Ideal in the East to a free-spirited lifestyle in the West was embraced wholeheartedly by the cowgirls in the arean;a the media and the society, however, were less willing to give up on the feminine side of cowgirls. Media stories highlighted the cowgirls' achievements, but also made sure to mention their domesticity in order to appease women in the East and all men's notions of 'true' womanhood."

"the flapper", "this new woman of the 1920s"

"a true woman was a true woman"
"the Cult of True Womanhood promoted in 'women's magazines, gift annuals, and religious literature made women hostages in their home'"
"These cultural feminists promoted the belief that '[all] women occupied the private sphere and men occupied the public domain.'"
"This belief prevailed in Western society for many years, because as 'values changed frequently...fortunes rose and fell with frightening rapidity...social and economic mobility provided instability as well as hope, one thing at least remained the same - a true woman was a true woman."
"In 1976 Barbara Welter coined the term 'The Cult of True Womanhood' to encapsulate Victorian gender ideology for women. The four cardinal virtues of the cult were piety, domesticity, and submissiveness that all 'true' women were expected to manifest in the nineteenth century."

"Annie Oakley was a 'true woman' who is credited with being the first performer to promote the 'All-American' cowgirl, which allowed her the freedom to compete athletically against men in her profession. Oakley was above criticism for her chosen profession by the 1890s. If one were to criticize her, it would be comparable to attacking a national icon, as she was able to take advantage of visual markers of White skin, long blonde hair, clothing, and a gender-conservative stance that made her a darling of White male notions of femininty. Oakley possessed monolithic cultural identity markers that contributed to White normative standards of beauty. These types of identity markers seem to belie the complexity of lived experiences for individuals. Having this nomrative standard of beauty coupled with her persona also protected her from being branded a 'floozy,' a derogatory term directed toward women in typical men's sports during this time period. She also differed from the 'New Woman' who was rallying for suffrage, education, and advancement. Although Annie Oakley was able to perform amazing feats inside the arena, she still preferred to act like a Victorian lady outside the arena." 

"'The [White and ethnic minority] cowgirl did not exist. The young women [regardless of race] did not go cavorting over the prairies astride bucking bronhco [sic]....[I]t would have seemed exceedingly immodest for a young woman to get astride a horse wearing any sort of riding habit. Any woman doing so would have been classed as a bawdy house character, and every home on the plains would have been closed to her."

"This is an interesting characterization, because being 'bawdy' typically referred to a woman's sexual nature. So a cowgirl was at risk fo being labeled as having a bawdy or sexual character for riding a horse incorrectly - not sidesaddle. Ironically, the safest way for a woman to ride a horse, astride the horse, was deemed bawdy. So, even if a cowgirl tossed the corset, she was still subject to patriarchal notions regarding her sexuality, depending upon how she sat on and rode the horse. If the White cowgirl was thought not to exist because her place was in the home, and had all of these patriarchal rules attached to her, then the erasure of the ethnic minority cowgirl was expected. Ethnic minority cowgirls had to be disenfranchised in order to make place for the 'non-existent' White cowgirl."


----------


# Emotions and Psychology #
## ["Frustrated?" There's Probably Another Emotion Present Sometimes, Deeper Feelings Lie Under the Surface](https://www.psychologytoday.com/us/blog/friendship-20/201909/frustrated-theres-probably-another-emotion-present)
"Frustration is likely to be the top layer of a feeling. It speaks to a sense of stagnation or helplessness, an inability to make things happen in the way that someone wants. Merriam-Webster defines being frustrated in part as 'feeling discouragement, anger, and annoyance because of unresolved problems or unfulfilled goals, desires, or needs.'

But while this picture of frustration—the angry, sulking person who's annoyed at the futility of their efforts—is a common one, with a little emotional exploration, we can see that an additional array of possible emotions can underlie frustration. And the first step in getting through the experience in a healthy way is to figure out exactly what those deeper emotions are. Here are some common examples.

Partners to Frustration:
Anger
Anger or Fear
Sadness
Guilt
Shame"


----------


# Romanticism and Popular Political Culture, Media #
## Romanticized South and Romanticized West, Scottish Romanticism, #MakeAmericaGreatAgain ##
* [What Do We Call This?](https://www.wnycstudios.org/podcasts/otm/segments/what-call-on-the-media) 
Trump - "I alone can fix this"
Fear, "others" who he has vilified, "fear of his own demagoguery"
Infuriating bitterness
Normal, good, law-abiding citizens who want their country back and want their freedom - protesters, rioters, monsters, domestic terrorists, insurrectionists - penetrating the Capitol
How did they think this out? 
Extremists doing damage in the capitol - was it just a protest? 
QANon, White Supremacists - these people talk to each other online
The speed of the attack, breaches
Washington Memorial
"Choice of words" are crucial - "mob"
"It's a puzzle"
"A woman who was shot and killed"
"The election was stolen", "voters who were upset"
Consequences for law-breaking lies

* [The Dark Familiarity of Trump's Lost Cause](https://www.wnycstudios.org/podcasts/otm/segments/dark-familiarity-trumps-lost-cause-on-the-media) 
Facebook's Supreme Court
What users can and cannot post
Grievance, indignation, vengeance - "believed that something was stolen from them"
The Confederate Battle Flag inside the Capitol Building, 1800s 
President Donald Trump embarked on a Lost Cause, projecting on America
Historian of the Civil War, tracking the history of Lost Cause Mythology
"Dead Rebels"
1880s, 1890s - monuments are going up; diaries are being published, justifying the slave-holding South - Lost Cause Mythology - States' Rights - Stonewall Jackson, Robert E. Lee
Several generations of young children hear these stories, raised on the stories of the Lost Cause
Popular Culture - Hollywood, "Birth of a Nation"
Rapists, Reconstruction
"Gone With the Wind" - fair Southern Belles, Mammy - loyal, faithful African Americans who knew their place and didn't challenge the structure - they were members of the family - this is something that was imbibed by the entire nation
Margaret Mitchell's version of the Confederacy
Confederate Banner, Football Games, University of Mississippi
Voter Suppressions, Lynchings - using the "Confederate Flag" as an emblem
"Stop the Steel" narrative
Martyrdom, "the sense of victimization"
Confederates, Abolitionists
Reductive comparsions, misunderstanding
"Parallels between the Lost Cause"
"Confederates knew they lost", and they were "justifying that they lost"
Grew out of 200 years of chattel slavery
Political, cultural, social gains
"Trivialize slavery", glib comparisons
"America has a whole was built on a belief of white supremacy"; not just Confederates were white supremacists
A much larger, and deeper well
Professor of history at the University of Virginia

* [Why Appeasement Won't Work This Time Around](https://www.wnycstudios.org/podcasts/otm/segments/why-appeasement-wont-work-time-around-on-the-media) 
Historical parallels of white resentment
"What to do and what not to do next"
Voter Suppression of Southern Blacks
Biden's election victory
Withdraw troops from Southern slave troops
The Old South, the freedom to oppress Southern Blacks without interference
Catastrope of appeasement, politics of reconciliation
White terrorism, counter-democratic
Countless people being killed
Clues across the South
This is part of our history
"What to do about our current divide?"
"Stop the steel"
Dystopian fantasy, wrong impulse, wrong strategy, legitimate grievance
Reconciliation between the North and the South
"Men of honor defending what they believe to be their way of life"
"Thrown under the bus"
"Treasonist actions"
"You cannot negotiate with 'White Supremacy'"
Fort Sumter
"some things are not negotiable in a Democratic Republic"
White nationalism undergirding the original Lost Cause Myth ("it was a thing of the South")
"Stop the Steel" - amorphis - White Supremaicism 
Political elites, the legacy
"A failed insurrection" vs. "not a failed insurrection", "a symbol", "a fruit of the poisonous tree"
"If we can't rule the Republic, we will burn it down"
Dred Scott - "a Southern dream come true" - underlying dynamic, appeasement, "treasonist kind of behavior"

* [Why Some Hear 'The Night They Drove Old Dixie Down' As A Neo-Confederate Anthem](https://www.wnycstudios.org/podcasts/otm/segments/why-some-hear-night-they-drove-old-dixie-down-neo-confederate-anthem-on-the-media) 
Tracks, Old Dixie, Americana, "Richmond that fell"
The night that took "Good ole Dixie down" in 1969
Rock n' roll Canon, charged subject matter
"Wife in TN"
Robert E. Lee
Nostalgic re-telling of the Civil War, the Southern farmer, laden with grief
Neo-confederate
Political climate, 27 - year old Country musician in Alabama
"Revise some lyrics"
"I hope we piss off the right people"
"Telling the history of the Civil War", "Reconstruction a failure", "Myth of Confederate virtue"
W. E. B. Dubois, Reconstruction in America, "working class", "prohibited solidarity", white/black workers - W. E. B. Dubois - decades for his work to gain a foothold in Civil War History - "just pharoah singing the Blues"
Dixie was defeated
American History
"recently liberated enslaved people"
Neo-confederacy
Complex negotiation
Growing up in Alabama
"Lost Cause"
"Staying in Your Lane"
Canada, Missisippi Delta - Colored vs. White Bathrooms
Cotton farmer, accommodate these kind of things
"The south is going to rise again"
The piano - "something crept out of him" - a movie about a Southern family in the Civil War period
Rebel stand


----------


# Gender Roles, Media, Popular Political Culture #
## [Masculinity, Gender Roles, and T.V. Shows from the 1950s](https://the-artifice.com/masculinity-gender-roles-tv-1950s/) ##
"The 1950s nuclear family emerged in the post WWII era, as Americans faced the imminent threat of destruction from their Cold War enemies. The ideal nuclear family turned inward, hoping to make their home front safe, even if the world was not. The image that we recall, largely as a result of the American television shows of the time period, is the picture perfect family consisting of the bread-winning, rule-making middle-class father, the doting housewife who was thrilled to wake up every single day and clean the house and cook all of the meals, and their children who never seemed to get into any sort of trouble that could not be fixed.

For those Americans who sought reassurance of the role of the family in the Cold War era, television showed them exactly that.“…Television projected a vision of American life into the home that could easily be emulated, in part at least, in those places in society that already resembled the ideal…” (Gilbert 141). Though millions of Americans did not have the lifestyle depicted on the small screen, television show families from the 1950s reflected idealized gender roles of the time period, which set an aspirational norm, even if it did not reflect reality."


"Past scholarship has been generally uncritical of the psychological impact of these idealized images. This paper considers recent scholarship in gender and psychology, to theorize about the ways that highly masculinized norms perpetuated by television during the 1950s may have contributed to violent development in boys and young men."


"During the 1950s, television gender roles were stricter and more rigid than they ever had been. The men put on their business suits every morning, went to their conforming jobs, became part of the American rat race, and then were expected to come home and be a father figure and a husband. These were oftentimes the same men that had fought on battlefields of WWII or the Korean War, and now their duties had changed, so that they had to fight Communism at home by being the perfect American man. “…now it is time to raise legitimate children, and make money, and dress properly, and be kind to one’s wife, and admire one’s boss, and learn not to worry, and think of oneself as what? That makes no difference, he thought – I’m just a man in a gray flannel suit” (Wilson 98)."


"Through these television shows, boys were shown how “real men” were supposed to act. These shows display clear differences between men and women, with women as subordinate. For boys in the 1950s, “being a man” and never doing anything that anyone could consider feminine was a lesson taught to them by their fathers and by the popular culture of the time."


"Researchers study the link between masculinity and violence to determine how even a non-violent show, as most shows were during the 1950s, could promote violence and the devaluation of women. Psychologist Felix Amato theorized about “Gender Role Conflict” in young males who did not grow up in violent homes and were not predisposed to an excessive amount of violence. Gender Role Conflict can be defined for these purposes as the negative consequences that occur when not adhering strictly to one’s gender role. The young males in this experiment were asked to rate themselves on a Gender Role Conflict Scale from one to ten, one being the least amount of conflict and ten being the most amount of conflict.

The results of the experiment that Amato performed are discussed in his article, The Relationship of Violence to Gender Role Conflict and Conformity to Masculine Norms in a Forensic Sample, and are concluded as such: men who score higher on the Gender Role Conflict scale are more likely to be violent, and violent tendencies are more common in men who have stricter views of gender roles (Amato 190). Trying to over-fulfill one’s manliness because of the fear of not being manly enough often times leads to violence."


"Boys during the 1950s were surrounded by this rigidity of manhood. This hyper-masculine mold that they were supposed to fit into consequently meant devaluing the role of women. It is possible that such television expectations contributed to the development of violent tendencies, because these boys growing up watching the men of the 1950s were not raised to value women, but rather to devalue them to make themselves seem more masculine. The repetitive exposure to these television shows, alongside with the patriarchal society that was solidified even more during the post-WWII years, created a highly constructed identity for men in America.

The television shows of the 1950s may have encouraged such violent outcomes. There was a lot of pressure on the boys to grow up as men, being ridiculed for any behavior that was not masculine and knowing that they would one day be the primary breadwinner for their family. There was also a clear gender difference growing up as boys in the 1950s, and since they were raised in a way to devalue “women’s work” they did not see girls and women as important parts of society. The television shows of the 1950s may not have shown violence to boys but it shows that subordination of women and hyper-masculinity are normal, which is the exact mindset that can lead to violent tendencies."


"Through the 1950s television shows, boys were shown that to be real men, they had to follow rigid norms. These shows display clear differences between men and women, with women as subordinate. Some of the most popular television shows during the 1950s were The Adventures of Ozzie and Harriet, Leave it to Beaver, Father Knows Best, and I Love Lucy. The plot lines were never dramatic and the issues were mundane. There was never any stress and problems could be fixed fairly easily. Things seemed to run smoothly in the lives of these Hollywood families, because they all had a role to play. The father was a workingman who left in the morning and came back at night, ready for his wife to serve him dinner. The fathers were not depicted as frequently as the rest of the family, because the storylines centered on the home. Since men spent the majority of their lives outside of the home, and were not involved with household chores, the dominant screen space was reserved for women and children.

In the show Leave it to Beaver, the story comes from the children’s point of view and the father, Ward Cleaver, is only depicted before he leaves for work, when he comes home for dinner, or when he is solving the problems of his two sons. It is the absence of the men in the home in these television shows that reinforces that boys and men simply do not belong there. On the other hand, the mother/wife figure, who stayed at home, figured prominently. These women, such as Lucy, Harriet, and June, “Portrayed the same general character – ‘a woman with a smile on her face and a trick up her sleeve, who is submissive yet controlling’” (Gilbert 138). These were the women who knew their place in the home. On the occasion that they tried to experiment with work, it was a comedic episode, because it wasn’t the her 'place.' When young boys turned on their television sets, they would have seen the outline for what a men and women are supposed to do. It is this mindset that there is no fluidity between the two gender roles that can have negative consequences to the socialization of children."


"The gender roles presented in the popular culture of the 1950s, if viewed enough by young boys, could have led to the subordination and violence against women, even in the home. While hyper-masculinity correlates with violent behaviors, there is also support for the same correlative between these rigid gender roles and violence against women, specifically. Stephanie Coontz describes the households of the 1950s in her book titled The Way We Never Were: American Families and the Nostalgia Trap. She describes the rates of unhappy marriages that would likely have led to divorce, had that option been acceptable and accessible at the time, and she presents us with shocking information about abuse in 1950s households. Coontz theorizes that the pressure for perfection in the postwar home was too much pressure for each family member to handle and that this time period brought about sexual abuse, incest, alcoholism, and wife battering (Coontz 279).

Violence against women is directly connected to hyper-masculine socialization. If a man during the 1950s felt that he did not live up this 'ideal' type, then this failure could have led to the use of violence toward his wife, or other women. Violence and abuse makes these men feel as though they are dominant, as their gender role prescribes that they should be. Even if this dominance is through violence, it is an act that makes the man feel 'more manly' to make up for the dominance he is lacking in his life outside of the home (Pleck 4). Men who believe that the male is the more valued gender in society, and that females are subordinate, are more likely to use violence against women, not only to reassert their own dominance but because they simply do not value femininity (Hatty 69)."


----------


# Black Lives and Home, Culture, and Society #
## [Black Southern Belle](https://blacksouthernbelle.com/50-black-southern-belles-in-lifestyle-african-american-tastemakers-of-the-south/) ##
"One thing Black Southern Belles know how to do is create. From compelling stories, to captivating images, to dynamic recipes, Black women from the South are renowned for their flair and style. From Southern natives to a few who have chosen to call this region home, here's a list of 50 Black Southern Belles making the region smarter, more beautiful, more creative, and more delicious. These are African American Tastemakers of the South that will add the inspiration you need in your life!

Erika Council is the software engineer, professional cook and food writer behind the blog, Southern Souffle. The North Carolina native, who currently resides in Atlanta, Georgia, hosts biscuit pop-ups and Sunday Suppers, two traveling odes to Southern cuisine. Inspired by family tradition, Council uses food and fellowship as a form of activism. In North Carolina, her maternal grandmother, Geraldine Dortch, used the proceeds of her 1960s Sunday suppers to fund the civil rights movement. Her paternal grandmother, Mildred Cotton Council, baked biscuits for local children who couldn't afford breakfast. Erica Council fuses those two experiences with her own Sunday Suppers, donating the proceeds of her dinners to help kids learn computer science.

In 1976, Mildred Cotton Council opened Mama Dipas restaurant in North Carolina. One of seven children, Council named the restaurant after a nickname her siblings gave to her as a child– she was so tall she could a dipa into the bottom of the rain barrell. Before she opened Mama Dipas, Council cooked for years at North Carolina coffee shops and dining halls. In 1957, she cooked alongside her mother-in-law at a take out kitchen, where she built her reputation for her famous biscuits. She released her cookbook, Mama Dipas Kitchen, in 1999.

Herbalist Jovan Sage is the co-owner of The Farmer and The Larder. Based in historic Brunswick, Georgia, The Farmer and The Larder serves both international and traditional coastal- inspired dishes with local ingredients. The restaurant also offers intensive, hands-on cooking classes. In her hometown of Kansas City, Sage worked with her uncle at the City Market, where she developed her palate for herbs and spices. She studied herbalism at the Florida School of Holistic Health and The Herbal Academy. Sage also owns Sages Larder, an online store for herbal teas and bitters.

Dr. Portia Fulford is the owner of Organpi Farms Farmhouse, an organic farm-to-table eatery and grocery store in Selma, Alabama. Much of the food at Organpi Farms Farmhouse is locally sourced from the Black Belt soil. A Selma native, Fulford owns two farms in nearby Lowndes County, one of the largest farm operations in the area owned by a black woman. She spent a lot of time on farms while studying for her Ph.D in Africana Women's Studies at Clark Atlanta University, where her thesis focused on African American women and uses of folk healing medicine. Fulford also plans to launch Ritual Farmhouse, an online store for home accents, handmade goods, and rustic decor.

North Carolina native Clarissa Clifton is a food historian, living history demonstrator, and author of the cookbook One Hearth, One Pot: For Love of Food and History. Growing up, she helped her grandmother cook on an open hearth stove, which peaked her interest in Southern food history. In North Carolina, visitors can find her doing living history demonstrations at Latta Plantation in Charlotte, North Carolina or demonstrating campfire cooking at the Revolutionary War battlefield with the Royal North Carolina Re-enactors. True to her motto have pots, will travel? A. Clifton is currently doing open hearth cooking demonstrations at Smith Plantation in Roswell, Georgia.

Shirley Mae Beard opened her namesake cafe on New Year's Eve in 1988. Tucked in the heart of Smoketown, the historic restaurant is located in the oldest African American community in Louisville, Kentucky. Beard also has a passion for history. While she and her family had extensive knowledge of the legacy of the black jockeys who pioneered the Kentucky Derby, she was shocked to find out a lot of Smoketown residents hadn't heard of the equestrians. In 1999, A. Beard founded the Salute to Black Jockeys event, with the mission to educate African-Americans in the community about the contributions of black jockeys in the Kentucky Derby.

Born on South Carolinas Daufuskie Island, Sallie Ann Robinson is a chef and cultural historian. Renowned for her knowledge of Gullah culture, Robinson is the author of two cookbooks, A. Gullah Home Cooking the Daufuskie Way and Cooking the Gullah Way, Morning, Noon, and Night. A sixth generation descendant of Gullah heritage, Robinson teamed up with Tour Daufuskie in 2016 to debut the Sallie Ann Native Gullah Tour, the first time a native professional guide offered a weekly tour of Daufuskie Island.

Born in Charleston, South Carolina, Kardea Brown is a contemporary Gullah cook. Her family is from Wadmalaw Island off the coast of South Carolina. Brown kicked off her cooking career taping a pilot for The Cooking Channel, and has since appeared on both ABCs The Chew and a number of shows on Food Network. Her traveling pop-up dinner series, The New Gullah Supper Club, pays homage to Gullah recipes passed down from her mother and grandmother. She also plans to launch a low-country treats and pimento cheese company, based in Atlanta.

Tiffany Derry is a native of Beaumont, Texas. Following her graduation from culinary school, Derry rose through the ranks of the Houston and Dallas culinary scenes. She broke into the TV world when she appeared on Season 7 of Bravos Top Chef, placing in the final four. In 2011, Derry teamed up with Patrick Halbert of the Halstin Group to open the restaurant Private Social, but left her executive chef position in 2013 to launch Tiffany Derry Concepts, a company devoted to her business and TV ventures. Currently, Derry is a judge on Spike TVs Hungry Investors.

Birmingham's Eryka Perry is the executive chef at Michaela's Restaurant in Homewood. Perry is also a certified health coach, and her background in cuisine and nutrition was the inspiration for her catering company, Not Just Catering. Partnering with fitness professionals, Not Just Catering offers personal chef services, health coaching, and meal preparation. But her catering company is just the start of learning to understand how the body processes food. The head of the kitchen at Michaela's says her goal is to get her Ph.D in nutrition.

Kentucky native Shacole Henderson is lead decorator and owner of Cocoa's Cakes, a bakery for custom wedding and specialty cakes. The granddaughter of a retired pastry chef, Henderson preferred a fashion design to baking. She started decorating cakes on a whim, after opting to take a higher paying job at Kroger. Two weeks later, she was hooked. After she posted a photo of a luau-themed cake she made for her father's birthday to Facebook, the requests came pouring in. While she no longer operates her cake shop at a brick-and-mortar location, she still takes plenty of orders on the Cocoa's Cakes website.

Born and raised in Birmingham, Javacia Harris Bowser is writer and columnist, who pens features for Birmingham Magazine, USA Today, and B-metro magazine. Harris is a regular contributor to the digital lifestyle magazine Style Blueprint Birmingham where she writes the profiles for FACES, a series showcasing contributions of women around the city. In 2011, Harris launched the award-winning See Jane Write, a network for women writers, bloggers, and entrepreneurs. In 2016, Southern Living a magazine included her on its list of Innovators Changing the South."

Born in Waycross, Georgia, Sheila Pree Bright is an award-winning photographer and visual producer. Bright's work widely depicts and examines contemporary culture, and shea's widely known around art circles as asocial cultural anthropologist. In 2016, she received national attention and acclaim after winning the Santa Fe Prize for her series a Suburbia. In 2016, Bright debuted her project 1960 now, A journey documenting the evolution of activism. This year, work from the series was on display at the Center for Civil and Human Rights in Atlanta and the Gallatin Galleries at NYT. A. Bright is also a contributor to the everyday black america Instagram account.

Artist Betty Tourney Turner is the owner of A. This Little Light Creative Glass Art and Gallery. She has long been fascinated by stained glass art and, as a child, she admits to paying more attention to the stained glass windows in church than the actual service. Turner started learning the craft as an adult, and she opened the gallery in 2015 in Old Hickory, Tennessee. She yearns to see more depictions of African-Americans in stained glass art. Inspired by artist Angela Smith, her goal is to bring more affordable pieces to fans of the art form.

Quintel Gwinn is an interior designer based in Charlotte, North Carolina. In addition to running her own full-service design studio, the Columbus, Georgia native is also an urbanist and community innovator. After graduating from design school, she starting working at an architecture firm where she designed commercial spaces. As a Charlotte fellow with the League of Creative Interventionalists, Gwinn uses architecture and design as a form of civic engagement. An advocate for the arts, the designer also teachers design and urban planning to youth.

Based in Atlanta, Georgia, interior designer Erika Ward started her career as a corporate accountant, managing construction budgets. She started Erika Ward Interiors in 2006 to flex her creative muscle. Three years later, she decided to leave her job to focus full-time on her design firm. A number of publications have featured projects from Erika Ward Interiors, including JEZEBEL magazine and Better Homes and Gardens. In 2016, the Atlanta Tribune featured Erika Ward Interiors in their a�?Best In Atlanta Guide.a�? Ward also manages Blue Label Bungaloo, a newsletter and daily guide to design and style.

Khristian Howell is a designer and color pattern expert based in Atlanta, Georgia. After working for five years as a textile designer and colorist at Nordstrom, Howell decided to fly solo and start her own design company, Khristian A. Howell Color + Pattern. The independent creator designs textiles and patterns for clients including Better Homes and Gardens, REI, and Shutterfly. She also licenses her work to Target and West Elm. In addition to designing her own brand of stationery, phone cases, and home decor, Howell also penned Color and Pattern, a guide to exploring textile design.

Based in Greensboro, North Carolina, Amber Crudup is the brains behind Amber Crudup & Co, a consulting agency for creative direction, brand imaging, and photography. The agency is a neat fusion of her two previous positions. Crudup was previously the graphic designer and owner of Suite Paper design studio, where she designed custom wedding stationary. She was also a wedding coordinator at Highgrove.

Jade Carter is freelance graphic designer and art director. The Atlanta- based creative just started a new position as Brand Engagement Manager at The Gathering Spot– a private, members-only club for the city's community of innovative talent. A. Carter is no stranger to managing high-profile events. She just finished her final year as the creative director of the A3C A Festival and Conference, one of the most prominent hip-hop festivals in the country. Known around circles as Spanky the Kidd, Carter also made her art show debut this year at Facet Gallery's PROPAGANDA! design exhibit.

Florida native Cecil Hayes is the owner and founder of Cecila's Designers Unlimited. One of the world's most iconic interior designers, Hayes was one of the first African-American interior designers to manufacture her own furniture and upholstery. She was also first African American designer featured in Architectural Digest magazine. In 2004, Architectural Digest featured her on its list of 100 Top Interior Designers. Her projects include the design of Chicago's South Loop Hotel Lobby. Hayes has worked with a long list of celebrity clients including Samuel L. Jackson, who called the veteran designer to help decorate his Tudor-style home. Cecil Hayes is also the author of two interior design books: 9 Steps to Beautiful Living and The Art of Decorative Details.

Michelle Colligan Johnson is a Louisiana-based fine art photographer, best known for capturing the aesthetics of Creole culture. A member of the Professional Photographers of America, her work has received recognition from the Professional Photographers of Louisiana. New-Orleans based brand agency The Wildlife Reserve featured photos from Johnson's a Women in the Woods series in their 2016 campaign, 'But Not Broken'.

Candace Mitchell and Chanel Martin are the duo behind the beauty technology company, Myavana. Based in Atlanta, Georgia, the company analyzes hair textures to research and recommend hair products. Mitchell and Martin met at Georgia Tech while completing their engineering degrees. Chanel Martin is also a brand strategist where she teaches entrepreneurs how to launch small businesses. In 2016, Forbes featured Candace Mitchell in its annual 30 under 30 list. Myavana has been featured in a number of publications including EBONY, Essence, and Black Enterprise. Martin and Mitchell have also appeared on The Real and at Essence Fest"

## [Essence: Black Perspectives](https://www.aaihs.org/essence-as-archive-on-the-occasion-of-its-golden-anniversary/?utm_source=rss) ##

## [Creating Digital Space for Black Scholarship](https://www.aaihs.org/creating-digital-space-for-black-scholarship/) ## 

## [The Brave Black Woman Who Were African American Spies](https://msmagazine.com/2011/02/28/the-brave-black-women-who-were-civil-war-spies/) ##

## [Ladies' Pages: African American Women's Magazines and the Culture That Made Them](https://www.jstor.org/stable/j.ctt5hj55m) ## 

## [Retrieving the Black Rural Past]() ## 

## [Harper's Magazine](https://harpers.org/about/) ##
"Harper’s Magazine, the oldest general-interest monthly in America, explores the issues that drive our national conversation, through long-form narrative journalism and essays, and such celebrated features as the iconic Harper’s Index. With its emphasis on fine writing and original thought Harper’s provides readers with a unique perspective on politics, society, the environment, and culture. The essays, fiction, and reporting in the magazine’s pages come from promising new voices, as well as some of the most distinguished names in American letters, among them Annie Dillard, Barbara Ehrenreich, Jonathan Franzen, Mary Gaitskill, David Foster Wallace, and Tom Wolfe."

"Harper’s Magazine made its debut in June 1850, the brainchild of the prominent New York book-publishing firm Harper & Brothers. The initial press run of 7,500 copies sold out immediately, and within six months circulation had reached 50,000.

Although the earliest issues consisted largely of material that had already been published in England, the magazine soon began to print the work of American artists and writers—among them Horatio Alger, Stephen A. Douglas, Theodore Dreiser, Horace Greeley, Winslow Homer, William Dean Howells, Henry James, Jack London, John Muir, Frederic Remington, Booth Tarkington, and Mark Twain. Several departments served to note regularly important events of the day, such as the publication of Herman Melville’s novel Moby-Dick, the laying of the first trans-Atlantic cable, the latest discoveries from Thomas Edison’s workshop, and the progress of the crusade for women’s rights.

In more recent years, the magazine published Woodrow Wilson and Winston Churchill long before either man became a political leader. Theodore Roosevelt wrote for Harper’s, as did Henry L. Stimson when he defended the bombing of Hiroshima. In the 1970s, Harper’s Magazine broke Seymour Hersh’s account of the My Lai massacre and devoted a full issue to Norman Mailer’s “The Prisoner of Sex.”

Over the years, the magazine’s format has been revamped, its general appearance has evolved considerably, and ownership has changed hands. In 1962, Harper & Brothers merged with Row, Peterson, & Company to become Harper & Row (now HarperCollins). Some years later the magazine became a separate corporation and a division of the Minneapolis Star and Tribune Company. In 1980, when the parent company announced that Harper’s Magazine would cease publication, John R. (Rick) MacArthur and his father, Roderick, urged the boards of the John D. and Catherine T. MacArthur Foundation and the Atlantic Richfield Company to make a grant of assets and funds to form the Harper’s Magazine Foundation. The Foundation is today an entirely independent organization—unaffiliated with other philanthropies, and solely dedicated to promoting Harper’s Magazine as an independent voice in American culture.

In 1984, Harper’s Magazine was completely redesigned by editor Lewis H. Lapham and MacArthur, who had become publisher of Harper’s and president of the Foundation. Recognizing the time constraints of the modern reader, the revived magazine introduced such original journalistic forms as the Harper’s Index, Readings, and the Annotation to complement its acclaimed fiction, essays, and reporting. Over the years Harper’s has received twenty-two National Magazine Awards, among many other journalistic and literary honors.

The year 2000 marked the sesquicentennial of Harper’s Magazine and, to celebrate, the magazine introduced several new editorial inventions and restorations: Archive and the Weekly Review. It has also published An American Album: One Hundred and Fifty Years of Harper’s Magazine, a cloth-bound, 712-page illustrated anthology—with an introduction by Lewis H. Lapham and a foreword by Arthur Schlesinger, Jr.—that offers a unique perspective on American life, distilled from the pages of the nation’s oldest continuously published monthly magazine.

Read Harper’s Magazine publisher John R. MacArthur on why Harpers.org has a paywall."

## [Bennett on Hurt, 'African-American Life in the Rural South, 1900-1950'](https://networks.h-net.org/node/512/reviews/762/bennett-hurt-african-american-life-rural-south-1900-1950) ## 
"History is a product of the imagination. Facts, sources, data, and artifacts are all important, but it is imagination that shapes the remains of the past into history. This fact is plain to those who work with the scant records of the long-ago past, but is equally true for those whose sources are more recent and more voluminous. Despite its proximity to the present, the recent past is still a different country; writing its history requires no less imagination. The recent history of the rural South illustrates this well. The radical transformation of the southern countryside over the past half-century provides tangible proof of the historical distance created by even a few decades. Looking out on the region's sprawling neoplantations and multiplying McMansions, one is hard-pressed to bear in mind that the seemingly empty acres these fill were not long ago home to tens of thousands of farm families and vibrant rural communities. Further complicating attempts to envision the southern countryside as it was is the disappearance of African Americans from the rural South. At the dawn of the twentieth century, for example, African-American farm operators worked a full third of the farms in the eleven former Confederate states; in three states--Mississippi, Louisiana, and South Carolina--black operators worked more than half of the farms. A hundred years later, less than four percent of the region's farms are operated by black farmers.[1] The result of a number of factors, including outmigration, mechanization, and federal farm policy, the African-American exodus from the rural South had profound effects on not only black culture (making it more urban-centered) and the southern countryside (making it whiter than ever before), but also how the histories of both have been told.

In this collection, eminent rural historian R. Douglas Hurt brings together the work of leading scholars in rural studies and southern history to retrieve a black rural past that has remained obscured by historical narratives that have largely depicted the southern countryside as the place from which African Americans fled. The collection moves beyond traditional discussions of "sharecropping, cotton, and poverty" to explore how African Americans made lives for themselves within rural worlds where one or all of this unholy trinity held sway (p. 5). By and large, the essays cover familiar ground, but do so in a way that places people and communities, not crops or economic forces at the center, providing greater texture to our understanding of the lives of country people."


"Louis M. Kyriakoudes's study of rural migration patterns and Melissa Walker's assessment of race relations in the countryside deal largely with the structures around which rural African Americans shaped their lives. Moving, as Kyriakoudes shows by drawing from a variety of narrative and quantitative sources, was a common aspect of life for rural black southerners who moved not only to cities, but between farms and in search of seasonal farm and off-farm work. Rural African Americans often moved in search of new opportunities hoping to mitigate economic hardship and/or racial oppression, but found themselves constrained by dependence on localized credit networks that made it difficult for those without financial resources to move beyond their neighborhood or home county. Despite this, Kyriakoudes argues, rural African Americans moved with great frequency, undercutting the notion that debt bound tenants to particular places. Instead, he contends (following economist Gavin Wright's lead), it was the South's insular regional labor market that stunted rural folks' opportunities to escape the "treadmill" of sharecropping (p. 17). Once this was market was opened by the expanded employment opportunities of World War II, sharecropping was doomed and the treadmill broken."


"Melissa Walker focuses on the simultaneous elasticity and rigidity of race relations in the rural South. While Jim Crow was largely a creature of the law in the region's cities, custom largely defined the interaction of whites and blacks in the rural parts. The nature of rural life and work made the physical distance of formal segregation largely impossible, but race relations in the country were often as harsh--or harsher, depending on the location--than those in the city. Despite its regional variability, the rural social and economic order worked to reinforce the notion that African Americans were, in the words of one white Texan, "a serving race" (p. 89). Nevertheless, this order was not static, shifting time and again across the first half of the twentieth century as economic developments reshaped rural life. Understanding these shifts, Walker argues, offers an important challenge to historians seeking to understand the roots of black resistance during the classic civil rights era.

Hints to the nature of this resistance can be found in the essays on black rural culture by Lois E. Myers and Rebecca Sharpless and Valerie Grim. Myers and Sharpless explore the centrality of the black church to the lives of rural African Americans. Rural churches, nearly irrespective of denomination, provided a pole around which spiritual and secular life--can the two be so neatly separated?--revolved. Weekly meetings, homecomings, and revivals were not only times for preaching the gospel, but also for reunions, weddings, and community outreach. In time, too, the churches became centers for protest, providing meeting places for groups like the Southern Tenant Farmers Union (STFU). The churches provided opportunities for both women and men to work, and largely transcended class distinctions. While often conservative in theology--a fact that often frustrated reformers--the churches nevertheless fit the needs of the rural people who populated them.

Valerie Grim's essay similarly demonstrates the importance of black culture and tradition for mitigating the harshness of much of African-American rural life. Defining culture to include "any act, behavior, idea, value system, or activity that illustrates how blacks lived and celebrated life at work, school, church, home, and throughout the community," Grim attempts to rescue black rural life from the denigrating stereotypes that, she argues, long shaped even black scholars' depictions of country people. Exploring a number of cultural practices, from naming rituals to food production to community activities, Grim demonstrated that, far from being backward and benighted, black rural culture was "energetic and diverse and included many social, spiritual, and educational activities" that allowed rural African Americans to create "an identity that embraced their expressions and empowered their sense of blackness" (p. 128)."


"Despite this, black assessments of rural life were, as the essays by Ted Ownby and Peter Coclanis and Bryant Simon demonstrate, quite diverse. Ownby, for example, explores black conceptions of rural life in his essay on agrarianism in the African-American autobiographical tradition and finds a complex understanding of rural life as at once disturbing and appealing. Focusing on Booker T. Washington, W.E.B. Du Bois, Richard Wright, and Zora Neale Hurston, he argues that Washington was the most traditionally agrarian of these writers. Hardly a romantic when it came to rural life, he disdained what he saw as the common intellectual and cultural poverty of rural people, but nevertheless believed the rigors of farm life could provide the character needed to succeed. Du Bois, whose own relationship with the southern countryside came largely while teaching in rural Tennessee and Georgia, was equally hard-headed about the downsides of rural life, but tended to cast black rural life in more idyllic terms. For Du Bois, sharecropping was an unmitigated evil, but farm life and the bonds of community it nurtured were at the heart of the "black folk." Thus, like Washington, he believed African Americans had much to gain by nurturing their ties to the land. A generation later, Richard Wright was less convinced of the redeeming value of farming. Sharecropping, he showed in works like Black Boy and Twelve Million Black Voices, destroyed all it touched. However, Ownby argues, these works, especially the latter, displayed an agrarianism that celebrated country people's commitment to family, community, and faith. Similarly, Hurston held no brief for farm life per se, but reveled instead in the vibrancy of black life in the workcamps and rural communities that dotted the landscape."


"Where Coclanis and Simon highlight the individual rationality of rural African Americans' decisions to stay on the land, the essays by William P. Browne and Jeannie Whayne demonstrate the constraints placed on their ability to remain in agriculture. In both cases, the focus is on the importance of state actors in imposing these constraints. Whayne's detailed essay on the work of black Extension Service agents sheds important light on the impulse to modernize southern agriculture. Drawing on the model of subaltern studies developed by historians of South Asia and Latin America, Whayne argues that black agents were subalterns who served as intermediaries between the state and black farmers. Unlike the subalterns of colonial India, who often used their position to negotiate the demands of colonial authority, black farm agents found themselves increasingly in line with the state's designs for rationalized, modernized agriculture and out of touch with the demands of black agriculturalists. By rejecting calls from groups like the STFU for reform and pushing black farmers to modernize--a goal they believed would allow them to maintain a living in a modern agricultural world--agents actually set them up to fail in a world of agricultural production that demanded they get bigger or get out."

"All told, these essays provide a helpful starting point for understanding African-American life in the rural South. Those teaching undergraduate or graduate courses in southern, rural, or African-American history will find that they are useful not only for providing an understanding of rural life, but also for spurring research. For, while the essays are strong, each contains enough lacunae to warrant further, localized studies."


----------


# Black Lives Matter #
## [Black Lives Matter - Racial Politics](https://www.hf.uio.no/ilos/english/research/news-and-events/news/2020/black-lives-matter) ##
"Through their work, African American writers tell the story of how power and whiteness are connected in American politics, says Professor Rebecca Scherr.

'Racial politics are at the center of the ongoing election campaign,' says Rebecca Scherr, professor of American Literature at the University of Oslo.  

However, this is nothing new, she points out. 

'You can't really talk about American history and politics without understanding the history of race and racism in America. It is not possible to separate the history of slavery and racism and the taking over of native peoples’ lands from how America has developed as a country, or from its own ideas of itself and its own myths.'

Professor Scherr researches and teaches multicultural American literature and studies how writers of minority background, whether African American, Native American, migrants or queer, comment on American society and culture. She believes that literature contributes to a better understanding of the current tensions in the US. 

'In literature, there is a way of seeing the past, the present and the future that is in tune with reality and not a mythologizing of the nation.'

Following the murder of George Floyd on May 25th, protests against police brutality spread all over the US and to the rest of the world. The Black Lives Matter movement experienced a surge in scope and importance. Many allies of the movement seized the opportunity to promote literature as a source of knowledge about black lives.  

'This is something that has happened many times before. The history of black people and the police goes back to the founding of the United States. And literature can actually help you map that long history and to see this as not just what's happening in this moment.'

A significant contemporary black intellectual, and a writer Scherr comes back to again and again, is Ta-Nehisi Coates. He had his international breakthrough with the non-fictional book Between the world and me in 2015. In it, he addresses police violence in the aftermath of the killing of 18-year old Michael Brown in 2014. 

'Coates writes to his son, a young black American male whose life could be taken by the police at any moment just because of the color of his skin. He shows how police brutality and police killing of African American people especially affects men, and that class status doesn’t matter' 

Scherr thinks Coates hit a nerve in the American public.  

'He is able to communicate in such a beautiful way the psychological depths that create this American system of inequality that has been going on for a very long time.' 

When Ta-Nehisi Coates was invited to be the guest editor of the September issue of the magazine Vanity Fair, he dedicated the entire edition to texts on Black Lives Matter. The cover features Breonna Taylor, the 26-year old African American woman who was killed by the police in March 2020.

'A lot of areas are now being critiqued for making black lives invisible, from the fashion industry to school curricula. This is bringing up dozens of discussions about representation. The connection between representation and politics is super interesting, because of how power intersects with who gets represented, and in what way.'

Coates’ title Between the world and me is a quote from James Baldwin, a writer central to the civil rights movement. Black Lives Matter has spurred a renewed interest in Baldwin. According to Scherr, he holds a special place in American literature. 

'First of all, he is an astonishing writer. No one can write like him, in terms of skill. He speaks to the heart of the matter and uses rhetoric, sentences, words, imagery in the most powerful way. He is also incredibly quotable, and you don't forget what he has to say,' she says. 

In his novels Another Country and Go tell it on the mountain, but even more vividly in essay collections such as The fire next time, Baldwin, like Coates, conveys the visceral experience of racism. As a black gay man, he can address oppression along several lines. However, according to Scherr, his most important project is to identify a racist societal structure. 

'He was really one of the first to beautifully turn the logic around and show white people that racism is about their fear and their hatred. That it is really about them and their power and that black people suffer because of that.'  

Scherr believes that Baldwin’s public persona still inspires today.  

'He embodied fearlessness in what he chose to talk and write about: not just about race, but about sexuality. I think that kind of fearlessness represents something that people want to emulate today.'

In turning the mirror on white Americans, Baldwin showed the power of whiteness. This is central in critical race studies, a tradition Rebecca Scherr applies in her research and teaching. Within this field, especially within the sub-field Whiteness studies, she finds tools to explain how racism works.  

'Oftentimes, when we think about racism, especially here in Norway, we think of individual acts of racism. So, I say something to you that's really stupid and racist. There is not necessarily a discussion about why what I'm saying is racist, where it comes from and how it comes from a larger system.' 

Scherr believes that tools from critical race theory can be used to reflect on these structures, in order to see the bigger picture. She highlights Peggy McIntosh’ famous essay 'White Privilege: Unpacking the invisible knapsack' from 1989. 

'What McIntosh shows, is that the entire system is predicated on sometimes a very visible whiteness and sometimes a very invisible whiteness. It is created in ways that are made to privilege people of a certain color up against others. If whiteness becomes the norm against which other things are measured, the thing that's not remarked upon - that's how power perpetuates itself.'

When teaching about race and critical race theory, Scherr often sees a lot of uncomfortable emotions and guilt welling up.  

'I think that speaking about whiteness as part of a system is also a way of removing guilt. It is important to be aware of privilege and to see how it functions in a multicultural society. Once you know about it, you can address it and do something about it.' 

In the US, ideas of individual freedom and the ideal of the self-made man are strong. Anyone can reach the top as long as he or she works hard enough. Critical race theory can help crush what McIntosh calls the myth of meritocracy, Scherr argues. 

'A lot of people have criticized the idea of meritocracy and pointed out that it helps to be white. You will have more barriers to moving into certain spaces and places based on your skin color, your gender, your country of origin and so forth.'

When Barack Obama was elected president in 2008, he both confirmed and challenged this myth.  

'He had to be four times as good to be able to get to where he got. If Obama had done even the tiniest sliver of a fraction of anything that Trump has done, I cannot imagine he would have had a chance.' 

She refers to Ta-Nehisi Coates’ essay 'The first white president', where he comments that what Trump can get away with and still be president, emphasizes the connection between whiteness and power.  

'It is so obvious now that Trump is a representative of white supremacy. He is not even subtle about it any longer. From saying that there are good people on both sides after Charlottesville, to how he is now calling protesters violent extremists and Antifa-people, and sending federal troops into local areas, basically to put down black people.' 

Trumps opponent, Joe Biden, also represents white America, but according to Professor Scherr he is a completely different candidate.  

'He is clearly not the best or most representative candidate for African Americans. However, he has eight years’ experience of working close to Obama, and at least he did choose Kamala Harris as his running mate. He is also trying, in his way, to show that he is aware of the conversation on race that is happening now.'

Rebecca Scherr believes Black Lives Matter has been instrumental in putting race at the center of the election campaign. Today’s movement is supported by a majority of the voters, unlike the civil rights movement in the 1960s.  

'In 68, white people were against the movement. Today, there are black people, other people of color, as well as white people, who are participating in unprecedented numbers and across the world, not just in America. Hopefully, that can translate to an increased awareness of the systemic racism in America and in other parts of the world.'

'If enough people will step up and get out to vote, I think that something can happen. With this kind of momentum, I hope Black Lives Matter can contribute to voting Trump out of office.'" 


----------


# Black Lives Matter and Engineering #
## [Black Inventor Garrett Morgan Saved Countless Lives with Gas Mask and Improved Traffic Lights](https://www.scientificamerican.com/article/black-inventor-garrett-morgan-saved-countless-lives-with-gas-mask-and-improved-traffic-lights/) ##
"In 1916 he strapped on his “safety hood” and dragged rescuers to safety, but racism prevented him from being hailed as a hero "

"Two rescue parties entered the tunnel searching for survivors. But they lacked proper safety equipment for the smoke and fumes; 11 of the 18 rescuers died. Some 11 hours later, desperate to save anyone still alive, the Cleveland Police turned to Garrett A. Morgan—a local inventor who called himself “the Black Edison”—and the gas mask he had patented two years earlier."

"But Morgan’s brilliant observation, and the simple but practical device that resulted from it, proved difficult to sell. His father was the son of Confederate General John Hunt Morgan and an enslaved Black woman, Sandra says, and Morgan’s mother was Black, which meant the inventor was fully subject to racism. He attended school through sixth grade and was largely self-taught. But his ingenuity eventually won out. After many failed attempts to sell what he called his “safety hood,” Morgan created a theatrical scheme to bypass potential buyers’ bigotry. In 1914, he hired a white actor to pose as the inventor. Morgan then disguised himself, filled a tent with noxious smoke, and cued the actor to entertain the crowd as Morgan strapped on his breathing device and entered the tent—where he waited for nearly half an hour before emerging safely to an aghast audience. Brisk sales followed, and newspapers reported the demonstration—and that’s how the Cleveland Police Department knew about Morgan’s device."

"But Morgan’s brilliant observation, and the simple but practical device that resulted from it, proved difficult to sell. His father was the son of Confederate General John Hunt Morgan and an enslaved Black woman, Sandra says, and Morgan’s mother was Black, which meant the inventor was fully subject to racism. He attended school through sixth grade and was largely self-taught. But his ingenuity eventually won out. After many failed attempts to sell what he called his “safety hood,” Morgan created a theatrical scheme to bypass potential buyers’ bigotry. In 1914, he hired a white actor to pose as the inventor. Morgan then disguised himself, filled a tent with noxious smoke, and cued the actor to entertain the crowd as Morgan strapped on his breathing device and entered the tent—where he waited for nearly half an hour before emerging safely to an aghast audience. Brisk sales followed, and newspapers reported the demonstration—and that’s how the Cleveland Police Department knew about Morgan’s device."

"Morgan was indignant. “He wrote a scorching letter to Cleveland Mayor Harry Davis,” Sandra says, quoting from a copy: “I am not a well-educated man; however, I have a Ph.D. from the school of hard knocks and cruel treatment.”

## [Garrett Morgan](https://www.youtube.com/watch?v=b6kdVu69LMM) ##

## [African Americans, Arabs, and Algebra](https://www.bbc.com/future/article/20201204-lost-islamic-library-maths) ##
"Centuries ago, a prestigious Islamic library brought Arabic numerals to the world. Though the library long since disappeared, its mathematical revolution changed our world.

The House of Wisdom sounds a bit like make believe: no trace remains of this ancient library, destroyed in the 13th Century, so we cannot be sure exactly where it was located or what it looked like.

But this prestigious academy was in fact a major intellectual powerhouse in Baghdad during the Islamic Golden Age, and the birthplace of mathematical concepts as transformative as the common zero and our modern-day 'Arabic' numerals.

Founded as a private collection for caliph Harun Al-Rashid in the late 8th Century then converted to a public academy some 30 years later, the House of Wisdom appears to have pulled scientists from all over the world towards Baghdad, drawn as they were by the city’s vibrant intellectual curiosity and freedom of expression (Muslim, Jewish and Christian scholars were all allowed to study there).

An archive as formidable in size as the present-day British Library in London or the Bibliothèque Nationale of Paris, the House of Wisdom eventually became an unrivalled centre for the study of humanities and sciences, including mathematics, astronomy, medicine, chemistry, geography, philosophy, literature and the arts – as well as some more dubious subjects such as alchemy and astrology.

To conjure this great monument thus requires a leap of imagination (think the Citadel in Westeros, or the library at Hogwarts), but one thing is certain: the academy ushered in a cultural Renaissance that would entirely alter the course of mathematics.

The House of Wisdom was destroyed in the Mongol Siege of Baghdad in 1258 (according to legend, so many manuscripts were tossed into the River Tigris that its waters turned black from ink), but the discoveries made there introduced a powerful, abstract mathematical language that would later be adopted by the Islamic empire, Europe, and ultimately, the entire world.

'What should matter to us is not the precise details of where or when the House of Wisdom was created,' says Jim Al-Khalili, a professor of physics at the University of Surrey. 'Far more interesting is the history of the scientific ideas themselves, and how they developed as a result of it.'

Tracing the House of Wisdom’s mathematical legacy involves a bit of time travel back to the future, as it were. For hundreds of years until the ebb of the Italian Renaissance, one name was synonymous with mathematics in Europe: Leonardo da Pisa, known posthumously as Fibonacci. Born in Pisa in 1170, the Italian mathematician received his primary instruction in Bugia, a trading enclave located on the Barbary coast of Africa (coastal North Africa). In his early 20s, Fibonacci traveled to the Middle East, captivated by ideas that had come west from India through Persia. When he returned to Italy, Fibonacci published Liber Abbaci, one of the first Western works to describe the Hindu-Arabic numeric system.

When Liber Abbaci first appeared in 1202, Hindu-Arabic numerals were known to only a few intellectuals; European tradesmen and scholars were still clinging to Roman numerals, which made multiplication and division extremely cumbersome (try multiplying MXCI by LVII!). Fibonacci’s book demonstrated numerals’ use in arithmetic operations – techniques which could be applied to practical problems like profit margin, money changing, weight conversion, barter and interest. 

'Those who wish to know the art of calculating, its subtleties and ingenuities, must know computing with hand figures,' Fibonacci wrote in the first chapter of his encyclopedic work, referring to the digits that children now learn in school. 'With these nine figures and the sign 0, called zephyr, any number whatsoever is written.' Suddenly, mathematics was available to all in a useable form.

Fibonacci’s great genius was not just his creativity as a mathematician, however, but his keen understanding of the advantages known to Muslim scientists for centuries: their calculating formulas, their decimal place system, their algebra. In fact, Liber Abbaci relied almost exclusively on the algorithms of 9th-Century mathematician Al-Khwarizmi. His revolutionary treatise presented, for the first time, a systematic way of solving quadratic equations. Because of his discoveries in the field, Al-Khwarizmi is often referred to as the father of algebra – a word we owe to him, from the Arabic al-jabr, 'the restoring of broken parts'—and in 821 he was appointed astronomer and head librarian of the House of Wisdom.

Scholars and translators at the library also took great pains to ensure that their work was accessible to the reading public
Al-Khwarizmi’s treatise introduced the Muslim world to the decimal number system,' explains Al-Khalili. “Others, such as Leonardo da Pisa, helped transmit it across Europe.'

Fibonacci’s transformative influence on modern maths was thus a legacy owed in great part to Al-Khwarizmi. And so two men separated by nearly four centuries were connected by an ancient library: the most celebrated mathematician of the Middle Ages stood on the shoulder of another pioneering thinker, one whose breakthroughs were made at an iconic institution of the Islamic Golden Age.

Perhaps because so little is known about the House of Wisdom, historians are occasionally tempted to exaggerate its scope and purpose, giving it an mythic status somewhat at odds with the scant historical records left to us. 'Some argue that the House of Wisdom was nothing like as grand as it became in the eyes of many,' says Al-Khalili. 'But its association with men such as Al-Khwarizmi, with his work in mathematics, astronomy and geography, is for me strong evidence that the House of Wisdom was closer to a true academy, not just a repository of translated books.'

Scholars and translators at the library also took great pains to ensure that their work was accessible to the reading public. 'The House of Wisdom is fundamentally important, as it’s through translations there – Arabic scholars who translated Greek ideas into the vernacular – that we formed the bedrock of our mathematical understanding' says June Barrow-Green, professor of history of mathematics at the Open University in the UK. The palace library was as much a window into numerical ideas from the past as it was a site of scientific innovation.

Long before our current decimal system, the binary number system that programs our computers, before Roman numerals, before the system used by ancient Mesopotamians, humans were using early tally systems to record calculations. While we might find each of these imponderable or antiquated, differing numerical representations can actually teach us something valuable about structure, relationships, and the historical and cultural contexts from which they emerged.

They reinforce the idea of place value and abstraction, helping us to better understand how numbers work. They show that 'the Western way wasn’t the only way', says Barrow-Green. 'There is a real value in understanding different numbers systems.'

When an ancient trader wanted to write 'two sheep', for example, she could inscribe in clay a picture of two sheep. But this would be impractical if she wanted to write '20 sheep.' Sign-value notation is a system in which numeric symbols add together signify a value; in this case, drawing two sheep to represent the actual quantity.

A global shift away from Roman numerals underscores a creeping innumeracy in other aspects of life
A vestige of sign-value notation, Roman numerals somehow persisted despite the introduction of Al-Khwarizmi’s system, which relied on the position of digits to represent quantities. Like the towering monuments on which they were inscribed, Roman numerals outlived the empire that gave birth to them – whether by accident, sentiment or purpose, none can say for sure.

This year marks the 850th anniversary of Fibonacci’s birth. It could also be the moment which threatens to undo the journeywork of Roman numerals. In the UK, traditional time-pieces have been replaced with easier-to-read digital clocks in school classrooms, for fear students can no longer tell analogue time properly. In some regions of the world, governments have dropped them from road signs and official documents, while Hollywood has moved away from using Roman numerals in sequel titles. The Superbowl famously ditched them for its 50th game, worried it was confusing fans.

But a global shift away from Roman numerals underscores a creeping innumeracy in other aspects of life. Perhaps more important, the disappearance of Roman numerals reveals the politics that govern any wider discussion about mathematics.

'The question of whose stories we tell, whose culture we privilege, and which forms of knowledge we immortalise into formal learning are inevitably influenced by our Western colonial heritage' says Lucy Rycroft-Smith, editor and developer at Cambridge Mathematics. A former maths teacher, Rycroft-Smith is now a leading voice in mathematics education, and studies differences across global curricula. While Wales, Scotland and Ireland do not include Roman numerals in their learning objectives, and the US has no standard requirements, England explicitly states that students must be able to read Roman numerals up to 100.

Many of us will find nothing special about the figure MMXX (that’s 2020, if you’re unaware). We may dimly recognise Fibonacci for the famous pattern named after him: a recursive sequence that starts with 1 and is thereafter the sum of the two previous numbers.

The Fibonacci sequence is certainly remarkable, showing up with astonishing frequency in the natural world – in seashells and plant tendrils, in the spirals of sunflower heads, in pine cones, animal horns and the arrangement of leaf buds on a stem, as well as the digital realm (in computer science and sequencing). His patterns often make their way into popular culture, too: in literature, film and visual arts; as a refrain in song lyrics or orchestral scores; even in architecture.  

But Leonardo da Pisa’s most enduring mathematical contribution is something rarely taught in schools. That story begins in a palace library nearly a thousand years ago, at a time when most of Western Christendom lay in intellectual darkness. It is a tale that should dismantle our Eurocentric view of mathematics, shine a spotlight on the Islamic world’s scientific achievements and argue for the continued importance of numerical treasures from long ago." 

## [Alexander Miles and African American Inventor of Elevator](http://www.myblackhistory.net/Alexander_Miles.htm) ##
"Alexander Miles was an African-American inventor who was best known for being awarded a patent for an automatically opening and closing elevator door design in 1887. Contrary to many sources, Miles was not the original inventor of this device. In 1874, 13 years before Miles' patent was awarded, John W. Meaker was awarded U.S. Patent 147,853 for the invention of the first automatic elevator door system.

Alexander Miles was born in 1838 in Duluth, Minnesota. He moved to Waukesha, Wisconsin where he earned a living as a barber in the 1860s. After a move to Winona, Minnesota in 1870, he met his wife, Candace J. Dunlap, a white woman born in New York City in 1834. Together they had a daughter named Grace who was born in April 1879. Shortly after her birth, the family relocated to Duluth, Minnesota.

While in Duluth, Alexander operated a barbershop in the four-story St. Louis Hotel and purchased a real estate office. His wife found work as a dress maker. Miles became the first black member of the Duluth Chamber of Commerce. In 1884, Miles built a three-story brownstone building at 19 West Superior Street in Duluth. This area became known as the Miles Block. It was at this time that Miles was inspired to work on elevator door mechanisms.

While riding in an elevator in with his young daughter, Alexander Miles saw the risk associated with an elevator shaft door carelessly left ajar. This led him to draft his design for automatically opening and closing elevator doors and apply for a patent. When the elevator would arrive or depart from a given floor, the doors would move automatically. Previously, the opening and closing of the doors of both the shaft and the elevator had to be completed manually by either the elevator operator or by passengers, contributing greatly to the hazards of operating an elevator. 

Miles attached a flexible belt to the elevator cage, and when the belt came into contact with drums positioned along the elevator shaft just above and below the floors, it allowed the elevator shaft doors to operate at the appropriate times. The elevator doors themselves were automated through a series of levers and rollers. 

Before working on elevator engineering, Miles experimented with the creation of hair products. The influence of his elevator patent is still seen in modern designs, since the automatic opening and closing of elevator and elevator shaft doors is a standard feature.

By 1900, Alexander, Candace, and Grace had moved to Chicago. In Chicago, Alexander created an insurance agency with the goal of eliminating discriminatory treatment of blacks. In his own words, Miles stated that insurance companies "persist in holding out discriminative rates to these colored people...". In 1900, it was believed that Alexander Miles was the "wealthiest colored man in the Northwest."

Alexander Miles died sometime after 1905 and was inducted into the National Inventors Hall of Fame in 2007."

## [Africans Invented Arithmetic and Algebra](https://blackvoicenews.com/2006/08/27/africans-invented-arithmetic-and-algebra/) ##
"The earliest treatise on algebra is the Egyptian Rhind Papyrus (c.1700 BC). But in c.3000 BC Egyptians called it 'aha Calculus' because 'Aha,' 'Ahe,' or 'Ahau' was the name of the second pharaoh of the first dynasty. Meaning mass, quantity, or heap (a pile of many things), it was used as an abstract term for the unknown in an equation.  Originally, the word 'algebra'-('al' 'from Egypt'–'al-Kemit')–meant the reuniting of broken parts and was later defined by the Arabs as 'restoration', including 'bone setting'. Note that Yin and Yang are also about the union of separate parts.

Now, algebra deals with math structures-the solution of equations and the general relations among numbers. It embraces calculus, logic, theories of numbers, equations, functions, and their combinations. Both arithmetic and algebra are branches of mathematics and both are ways of figuring. Figuring involves discovering answers (e.g. establishing values) to problems using the amount or value given in numbers, using unknown numbers, or using letters or symbols standing for quantities. A letter or symbol for any number is called a Variable. Quantities of matter have size, weight, number, mass, height, depth, width, length, capacity, extent, endurance, time duration, and volume. They can be counted, weighed, and measured geometrically (e.g. lines, curves, angles)-and these may be added to or lessened.

Arithmetic ('the science of numbers'; 'the art of calculation') applies numbers to answer questions such as 'how many?' -how much?' –and how far?' Algebra is the next step up and features letter or symbol 'shorthand' in expressing quantities. With arithmetic the simple job of adding can be expressed as 3+4=7 or three + four = seven. However, in algebra the same could be written T + F = S-i.e. using the first letters of the words to stand for the numbers. This is called an Equation– a statement that two things are equal. Equations have many governing rules-rules which allow discovering unknown  numbers that appear in an equation with known numbers-and rules which make calculation with big numbers just as easy as calculation with small numbers. For example, 'x' (or any other letter of the alphabet) stands for an unknown quantity. As in arithmetic, addition is shown by + and subtraction is shown by -. When you put one letter over the other–like a/b– you are dividing b into a. Putting two symbols together– as ab-means to multiply them. In algebra the multiplication sign is not used when two symbols are placed side by side. T x F is written TF and 3 x T is written 3T.

Although certain symbols, marks, and letters customarily represent quantities and operations, seldom would the letters T, F, and S (see examples above) be used. Usually the early letters of the alphabet-a, b, c, etc.-are applied to stand for constants (fixed or known numbers) and the late letters-x, y, z-to stand for variables. Variables are quantities that may have various values or that are unknown. The letter 'n' is used to mean 'any given (or known) number'. A Power of a number is the product or result you get when you multiply the number by itself, one or more times. It is expressed by an Exponent (a small number written after and higher than the number). When you read it aloud as 'three squared,' this means 3 x 3 =9; or "two to the fifth power is 2x2x2x2x2 or 32. Roots, the opposite of a power, must be multiplied by itself to produce a given number. The cube root (using a number three times as a factor-4x4x4) of 64 is 4. A Series is a group of numbers related by some rule. In an arithmetic series-1, 4, 7, 10-a constant number (here, 3) is added to each term to give the next. Africans found a place for arithmetic and algebra during their on-going activities on such vast construction projects– as in building temples, pyramids, irrigation works, and obelisks."


----------


# Black Lives Matter and History #
## [https://georgetowner.com/articles/2019/02/20/black-history-georgetown-2/]() ##
"Step out of your home or walk a block from your office here in Georgetown, the oldest neighborhood in Washington, D.C., and you are sure to pass a spot that contains history — quite likely African American history. To the surprise of some, Georgetown can tell the story of early and contemporary America from a black perspective.

In 2019, we mark the 400th anniversary of enslaved Africans arriving in the British American colonies at Point Comfort, Virginia. Disembarking in 1619 were 'not any thing but 20. and odd Negroes,' according to John Rolfe, widower of Pocahontas.

The legacy of slavery continues to inform the American experience, black and white — particularly on the East Coast, where the United States began. Of the many stories to tell, we shall tell a local one.

Washington, D.C., says Marcia Chatelain, Georgetown University associate professor of history, is a place with black history that has shown 'great beauty and inequality. It is a sober reminder and a celebration, too,' she added, 'of achievement and strengths.' Knowing and understanding history, says the author of 'South Side Girls: Growing Up in the Great Migration,' Americans have a chance 'to demonstrate what’s possible' — constructing 'a well-rounded account.' Black History Month is a time 'to be reflective.'

Fifth-generation Washingtonian, P Street resident and educator Monica Roaché — former advisory neighborhood commissioner and now a D.C. Democratic Party Committee member — says she has used her platform to tell the story of black Georgetown. 'The African American community contributed to Georgetown. There were doctors, lawyers, educators and more,' she says, noting that 'Georgetown was the first D.C. neighborhood to experience gentrification.' (It did not turn out well for black Georgetowners.)

Roaché’s family was part of 'Black Georgetown Remembered,' a 1989 video and book project by Georgetown University, authored by Kathleen Lesko, Valerie Babb and Carroll Gibbs. Crediting the university, Roaché calls the book 'an encyclopedia of Georgetowners’ shared experience.'


That same Jesuit university at 37th & O Streets — the oldest Catholic institution of higher learning in the U.S. — only fully confronted its ties to slavery three years ago.

'It seems to me that the story of Georgetown and slavery is a microcosm of the whole history of slavery,' said history professor Adam Rothman, a member of Georgetown University’s Working Group on Slavery, Memory & Reconciliation, in 2016, regarding the university’s connection with the Jesuits’ 1838 sale of 272 slaves.

Since then, the university has apologized for arranging the sale of slaves from D.C. and Maryland farms to help pay off debts that endangered the survival of Georgetown College. And it has renamed two main campus buildings: for Isaac Hawkins, the first slave listed on the sales document; and for Anne Marie Becraft, who founded a school nearby for black girls and later became one of America’s first black nuns.

The school has also offered descendants of the 272 slaves, most of whom ended up in Louisiana, legacy status in admissions.


That same Jesuit university at 37th & O Streets — the oldest Catholic institution of higher learning in the U.S. — only fully confronted its ties to slavery three years ago.

'It seems to me that the story of Georgetown and slavery is a microcosm of the whole history of slavery,' said history professor Adam Rothman, a member of Georgetown University’s Working Group on Slavery, Memory & Reconciliation, in 2016, regarding the university’s connection with the Jesuits’ 1838 sale of 272 slaves.

Since then, the university has apologized for arranging the sale of slaves from D.C. and Maryland farms to help pay off debts that endangered the survival of Georgetown College. And it has renamed two main campus buildings: for Isaac Hawkins, the first slave listed on the sales document; and for Anne Marie Becraft, who founded a school nearby for black girls and later became one of America’s first black nuns.

The school has also offered descendants of the 272 slaves, most of whom ended up in Louisiana, legacy status in admissions.


That same Jesuit university at 37th & O Streets — the oldest Catholic institution of higher learning in the U.S. — only fully confronted its ties to slavery three years ago.

'It seems to me that the story of Georgetown and slavery is a microcosm of the whole history of slavery,' said history professor Adam Rothman, a member of Georgetown University’s Working Group on Slavery, Memory & Reconciliation, in 2016, regarding the university’s connection with the Jesuits’ 1838 sale of 272 slaves.

Since then, the university has apologized for arranging the sale of slaves from D.C. and Maryland farms to help pay off debts that endangered the survival of Georgetown College. And it has renamed two main campus buildings: for Isaac Hawkins, the first slave listed on the sales document; and for Anne Marie Becraft, who founded a school nearby for black girls and later became one of America’s first black nuns.

The school has also offered descendants of the 272 slaves, most of whom ended up in Louisiana, legacy status in admissions.


That same Jesuit university at 37th & O Streets — the oldest Catholic institution of higher learning in the U.S. — only fully confronted its ties to slavery three years ago.

'It seems to me that the story of Georgetown and slavery is a microcosm of the whole history of slavery,' said history professor Adam Rothman, a member of Georgetown University’s Working Group on Slavery, Memory & Reconciliation, in 2016, regarding the university’s connection with the Jesuits’ 1838 sale of 272 slaves.

Since then, the university has apologized for arranging the sale of slaves from D.C. and Maryland farms to help pay off debts that endangered the survival of Georgetown College. And it has renamed two main campus buildings: for Isaac Hawkins, the first slave listed on the sales document; and for Anne Marie Becraft, who founded a school nearby for black girls and later became one of America’s first black nuns.

The school has also offered descendants of the 272 slaves, most of whom ended up in Louisiana, legacy status in admissions.

Mention Dr. C. Herbert Marshall or Dr. Joseph Dodson and old-timers will smile in recognition. Mention the Blue Mouse Theatre, operated by George Martin, on 26th Street in the West End and older smiles will widen. Remaining in Georgetown were the families Bowman, Burnett, Butler, Calloway, Clark, Gaskin, Jackson, Jones, Marshall, Mitchell, Peebles, Roaché, Sewell, Waters and Wharton, when “Black Georgetown Remembered” was written.

'One of the things I have enjoyed, even to this day, is the communal feeling in Georgetown. We’re still close-knit, even though our numbers have dwindled,” says Neville Waters, president of the Mount Zion Female Union Band Historic Memorial Park Inc. The nonprofit’s work for the old cemetery behind 27th and Q Streets has amped up with a major fundraising campaign: 'Reclaiming Our Past to Preserve Our Future.' (The group was one of this newspaper’s 2018 Georgetowners of the Year.)

'It saddens me to think of a time when blacks and white could not be buried together, but we’ve gone beyond that,' Waters says. 'It’s important that everyone know our ancestors worked hard to help build the foundations of Washington, D.C.'

Nowadays, D.C. is no longer 'Chocolate City.' Mayor Muriel Bowser calls for 'a fair shot' for all. And the Old Dominion — as it attempts to address shameful aspects of its history, some recent — touts its '2019 Commemoration, American Evolution.'

'We’re still learning in 2019,' Roaché says."

## [400 Years of Africans and Black People in the US and Virginia](https://www.c-span.org/video/?463305-1/400th-anniversary-ceremony-africans-virginia)
"American History TV was live from Fort Monroe for the 400th anniversary ceremony commemorating the arrival of the first Africans in Virginia and the dedication of a new visitor center."


----------


# Gender, Power, and Race #
## [Gender, Power, and Whiteness in Rodeo: Breaking Away from the Ties of Sexism and Racism](https://books.google.com/books?id=xcjq7_dG1RYC&pg=PA7&lpg=PA7&dq=cowboys+west+damsels+in+distress+south&source=bl&ots=pYgLRHxQl4&sig=ACfU3U3Zx-kziU3AmBTgdPzgksPsmq6ZwA&hl=en&sa=X&ved=2ahUKEwj1_Lj8ooHvAhU2MlkFHaWmB0UQ6AEwEXoECBAQAw#v=onepage&q=cowboys%20west%20damsels%20in%20distress%20south&f=false) ##
"When I was a little girl, in the mid-1950s, I wanted more than anything than to be a cowgirl."

"The lure of cowgirls and cowboys", "the American imagination"

"a symbolic representation of the Western United States"

"the late 1800s"

"the idea of Manifest Destiny through taming the wild"

"the popular culture story at the surface - the one that is retold, repacked, and visually revised as U. S. white and male"

"the largely all-White all-Male rodeo myth"

"the narrative of the West"

"The cowgirls of today were born of the Eastern settlers from the period of the Western settlement, or Manifest Destiny. These women came from the East to settle and establish a new life with their husbands and families, with a focused goal to 'tame' the West. The pioneer women wore prairier dresses and bonnets, focused on education, and worked long hard hours to feed, clothe, and even protect their families from danger. These women were known as 'Prairie Madonnas' who 'made great pies, babies, and flour sack curtains...She kept immaculate house under impossible conditions - floors of raw dirt or unfinished woo' and she 'could handle a gun or help with the stock if her husband were away when the Indians attacked or if the cows broke down the fence." 

"the oral histories", Teresa Jordan's book, "Cowgirls: Women of the American West"

"A popular writer from this era was Laura Ingalls Wilder"

"the Western frontier"

"the cowboy image"
"the frontier cowboys"

"culture", "a way of life"

"This book is about moving marginalized individuals in rodeo to the center; however, we cannot possibly tell the whole story. The ignorance of history, a belief in a White Western narrative that erased the contributions of Lation/as, American Indians, and African Americans, and the effects of racism and White privilege are why all those in rodeo are believed to be either White and/or White males. We are unable to resurrect those cowgirls likely that Wister saw and had knowledge of Latino, American Indian, and African American cowboys. Wister also knew that women were in the West, and yet their participation is erased, as well. In Wister's revisionist telling of the 'wild West' he recounts and admires only the hard, industrious work of White men. Through the creation of *The Virginian*, in 1902, Wister 'created the archetypal cowboy hero stamped with particular qualities that virtually all his successors would perpetuate. The creation of the archetypal cowboy and the use of the White man to be the hero to fight the villains of the West (normally seen as the 'Wild' Indian or Mexican 'Desperado'), and saving White women from the dangers of the West established rigid gender stereotypes. The establishment of these gender roles helped influence the positions that owmen and ethnic minorities have in modern rodeo, because they reifed the social norms and themes that were constructed in the United States for what was appropriate for each group of people. Wister's focus on admiration for the White race sat well with his contemporaries like Rudyard Kipling, as well as with other U.S. policy and laws of the time. For example, in 1896 the U.S. Supreme Court passed the Federal Plessy v. Ferguson law, which ushered in Jim Crow, or a 'separate but equal' policy, which segregated Black and White Americans. This Federal law remained in place through 1964. In addition, in 1900 White males in the U.S. elected William McKinley, who further popularized Kipling's 1899 poem 'The White Man's Burden,' a treatise on 'the white man's burden' belief, which focused on cultural and racial imperialism. In 1900, this policy impacted U.S. and Philippines relations and U.S. and China relations (the Boxer Rebellion in China), and in 1901 it affected U.S. and Cuban relations (the Platt Amendment). Not suprisingly, given this time perio and the aforementioned U.S. laws, the myth of the West and the myth of rodeo are tied to White westward expansion. There is a parallel etween the dangers the pioneers faced during their quest of Manifest Destiny - the hostile elements, raging rivers, outlaws, Indians - and the cowboys' dnagers faced in rodeo. Later, these same racist ideals were put on film when Thomas Dixon's book, *The Clansman* (1905), was turned into the move, *Birth of A Nation*, which was directed by D. W. Griffith in 1915. Dixon was a classmate of former President Woodrow Wilson, and Wilson had a special screening of the movie at the White House, where the Supreme Court was also in attendance. As media scholar Donald Bogle noted, the film 'would work audiences into a frenzy...[I]t will make you hate.' This movie heralded the KKK as the saviors of the White race and protectors of White womanhood and virginity from the Black male brute who was no longer controlled by the system of slavery, and increased White male membership in the terrorist organization."

"legal scholar Margaret Russell"
"through a carefully constructed fusion of unprecedented technical wizadry and degrading racial stereotypes, Griffith sought to convince his audience that his was the 'true' story of the old South and that white domination was necessary for their survival. To a great extent, he succeeded: The film's enormous popularity fueled the growing influence of the Klan, and *The Birth of a Nation* remains to this day one of the highest-grossing box office successes in Hollywood history." 

"Wister's novel went through 'fifteen printings during the first eigh months after its publication; by 1911 it was in its thirty-eight printing. By 1938, it had sold mroe than one and one-half million copies.'"
"While not everyone embraced Wister's East Coast take on the West, and while other novels later existed, *The Virginian* was considered a seminal work that cemented the myth of the White American West in the U.S. imagination, as well as of the iconic stoic, independent cowboy, who is always visually depicted as a White man."

"The American cowboy is idealized in folklore as masculine, independent, and an explorer. Curiosity as a foundational element of human existence led to the stereotype of the cowboy myth, which continues to be embraced. Early explorers liek Coronado in 1541, and later Lewis and Clark in the early 1800s, said the American West was a vast open plain, a desert where one could conquer man, land, and beast. The untamed elements of the Western frontier remain static in the narrative of the West. Ideally, the American cowboy and the narrative of the Western frontier were painted with heroic myths worthy of 'god-like' worship, whereby the embellishment of the narrative outshone the lived reality of the frontier."

"The exclusionary dominance of the White cowboy as a representative of the West in rodeo depictions and as portrayed in dime novels, film, and folklore is that he is believed to be anyone: that person any White Anglo Saxon Protestant (WASP) male could become."

"He is not complicated in his white/black binary vision of the world; you are either good or bad and the judgment comes from his 'correct' attitudes, beliefs, and values, which are ideals found within the cowboy culture and code - the Code of the West. He symbolizes the possibility of what can be achieved through a hard work ethic and through traditional gender roles that reinforce Victorian ideals of White womanhood, e.g., a helpless virginal damsel in distress who needs the protection and direction of a strong man to react against any transgression committed against her. Our hero in this Western White myth is complete with his leathered face and Western drawl. He is armed with is trusty six-shooter, while keeping an eye out for American Indians. '[The] Anglo-Saxon cowboy and the Red Indian emerged as convenient action heroes. These simplified stick figures propagated a frontier mythology that hid both the systemic violence of conquest and the modern incorporation of land and labor. Cowboy hats and warrior headdresses obscured the complex racial politics of the United States and created instead a ronatic duel of white against red.' From this duel of reductionist cowboy ideals, race, and land emerged an American iconic myth (the cowboy) that is actually a conglomeration of 'White conquering West' rhetoric, media fascination, and myths - like the explorations of Daniel Boone - which loomed larger than life. The myths of man besting beast carried over into the rodeo cowboy arena."

"The cowboy represents the taming of the forces of North American civlization. In the arena, these great forces clash. The cowboy hero attempts to 'tame the wild...'"

"Wister's novel went through 'fifteen printings during the first eight months after its publication; by 1911 it was in its thirty-eight printing. By 1938, it had sold more than one and one-half million copies.'"

"the histories of the American West...[of] heroic tales: stories of adventure, exploration, and conflict."

"overcome a conflict, seek adventure, and explore new territory"

"The rodeo cowboy is only one of the numbers of modern occupational folk hero types, yet he is a fascinating one. He is, after all, a modern man - he lives in industrial America...sleeps at the Holiday Inn....[Y]et on the other hand he is a cowboy - representing facets of North America's past that evoke powerful rural and pre-industrial images. This makes for a fascinating paradox."

"The rodeo cowboy embodies two different men. On one hand, he is modern and experiences all of the modern conveniences that are available, yet he is also a man whose job it is to recreate the Wild West for entertainment. He retells an age old story of good versus evil while attempting to tame the wild, even while making a career out of being a show performer. The rodeo road for our cowboy hero has been built from a diverse history, starting with the Wild West shows."

"Amazon" - "cowgirls"

"Free from the confines of the corset, cowgirls were seen as powerful, as talented, and with fewer restrictions placed upon them. The transition from a Victorian Ideal in the East to a free-spirited lifestyle in the West was embraced wholeheartedly by the cowgirls in the arean;a the media and the society, however, were less willing to give up on the feminine side of cowgirls. Media stories highlighted the cowgirls' achievements, but also made sure to mention their domesticity in order to appease women in the East and all men's notions of 'true' womanhood."

"the flapper", "this new woman of the 1920s"

"a true woman was a true woman"
"the Cult of True Womanhood promoted in 'women's magazines, gift annuals, and religious literature made women hostages in their home'"
"These cultural feminists promoted the belief that '[all] women occupied the private sphere and men occupied the public domain.'"
"This belief prevailed in Western society for many years, because as 'values changed frequently...fortunes rose and fell with frightening rapidity...social and economic mobility provided instability as well as hope, one thing at least remained the same - a true woman was a true woman."
"In 1976 Barbara Welter coined the term 'The Cult of True Womanhood' to encapsulate Victorian gender ideology for women. The four cardinal virtues of the cult were piety, domesticity, and submissiveness that all 'true' women were expected to manifest in the nineteenth century."

"Annie Oakley was a 'true woman' who is credited with being the first performer to promote the 'All-American' cowgirl, which allowed her the freedom to compete athletically against men in her profession. Oakley was above criticism for her chosen profession by the 1890s. If one were to criticize her, it would be comparable to attacking a national icon, as she was able to take advantage of visual markers of White skin, long blonde hair, clothing, and a gender-conservative stance that made her a darling of White male notions of femininty. Oakley possessed monolithic cultural identity markers that contributed to White normative standards of beauty. These types of identity markers seem to belie the complexity of lived experiences for individuals. Having this nomrative standard of beauty coupled with her persona also protected her from being branded a 'floozy,' a derogatory term directed toward women in typical men's sports during this time period. She also differed from the 'New Woman' who was rallying for suffrage, education, and advancement. Although Annie Oakley was able to perform amazing feats inside the arena, she still preferred to act like a Victorian lady outside the arena." 

"'The [White and ethnic minority] cowgirl did not exist. The young women [regardless of race] did not go cavorting over the prairies astride bucking bronhco [sic]....[I]t would have seemed exceedingly immodest for a young woman to get astride a horse wearing any sort of riding habit. Any woman doing so would have been classed as a bawdy house character, and every home on the plains would have been closed to her."

"This is an interesting characterization, because being 'bawdy' typically referred to a woman's sexual nature. So a cowgirl was at risk fo being labeled as having a bawdy or sexual character for riding a horse incorrectly - not sidesaddle. Ironically, the safest way for a woman to ride a horse, astride the horse, was deemed bawdy. So, even if a cowgirl tossed the corset, she was still subject to patriarchal notions regarding her sexuality, depending upon how she sat on and rode the horse. If the White cowgirl was thought not to exist because her place was in the home, and had all of these patriarchal rules attached to her, then the erasure of the ethnic minority cowgirl was expected. Ethnic minority cowgirls had to be disenfranchised in order to make place for the 'non-existent' White cowgirl."


----------


# Financial History and Infrastructure #
## [Robber Barons](https://mises.org/library/truth-about-robber-barons) ##
* The Truth About the "Robber Barons"

* "Free-market capitalism is a network of free and voluntary exchanges in which producers work, produce, and exchange their products for the products of others through prices voluntarily arrived at. State capitalism consists of one or more groups making use of the coercive apparatus of the government… for themselves by expropriating the production of others by force and violence."

## [Robber Barons](https://en.wikipedia.org/wiki/Robber_baron) ##

## [US Railway Mail Service](https://www.archives.gov/publications/prologue/2005/fall/fast-mail-1.html) ##

## [A Century of Railroad Building](https://www.legendsofamerica.com/rr-railroadbuilders/) ##

## []() ##
https://www.essentialcivilwarcurriculum.com/the-economics-of-the-civil-war.html

## [Causes, Costs and Consequences: The Economics of the American Civil War](https://www.essentialcivilwarcurriculum.com/the-economics-of-the-civil-war.html) ##


----------


# Civil War, and Railway Mail #
## [Railway Post Office](https://www.cs.mcgill.ca/~rwest/wikispeedia/wpcd/wp/r/Railway_post_office.htm) ##
"Writing sixty years after the end of the American Civil War, historians Charles and Mary Beard looked back and decided that the time had come 'when the economist and lawyer, looking more calmly on the scene', could discover 'that at the bottom of the so-called Civil War, or the War between the States, was a social war, ending in the unquestioned establishment of a new power in the government.' The conflict, they insisted, was a 'Second American Revolution' that transformed the United States into an industrial society. What became known as the 'Hacker-Beard Thesis' was summarized a few years later by Louis Hacker in his book The Triumph of American Capitalism:

The American Civil War turned out to be a revolution indeed. But its striking achievement was the triumph of industrial capitalism. The industrial capitalist, through their political spokesmen, the Republicans, had succeeded in capturing the state and using it as an instrument to strengthen their economic position. … [T]he victory was made secure by the passage of tariff, banking, public-land, railroad, and contract labor legislation.[1]

Hacker and the Beards presented a dramatic historical narrative that tied the issues surrounding America’s great political crisis in the middle of the nineteenth century to the powerful dynamics behind the emergence of an industrial system dominated by large firms towards the end of the century. 'The persuasiveness (if not the logic), the panoramic scope, as well as the iconoclastic nature of the thesis,' wrote Robert Sharkey in 1959, 'recommended it to readers of history as well as historians.' Peter Novick pointed out that 'no alternative conceptualization of the sweep of American history emerged in the interwar years'[2]

Despite the obvious appeal of this grand historical narrative, a growing number of historians were uncomfortable with some of the details surrounding the Hacker-Beard thesis. Historians studying economic growth in 19th century America found that the war had not spurred economic growth, and argued industrialization would have occurred without the war. The war was seen as an unfortunate interruption to the development of the American Economy that was of little interest to economic historians.[3]

Wars seldom make much 'economic' sense. However, in the case of the Civil War, the 'economics' of the war and its aftermath have proven to be more intriguing than most. The Beards may have been off the mark in claiming that the war accelerated industrial growth, but a strong case can be made for their claim that the rapid commercial and industrial growth in the Northern states before the war played a part in fanning the regional tensions between the industrial North and the rural South. Historian Richard Brown observed in his book on the modernization of America that 'without attempting to prove that modernization ‘caused’ the Civil War, one may argue that it was very much the conflict of a modernizing society.'[4]

This essay focuses on the three major issues: the economics of slavery that were at the core of the antebellum disputes that led to the crisis of 1860, the economic factors that contributed to the North’s victory in the war, and the economic legacy of America’s most destructive war.

Slavery and the Economics of the Civil War

Slavery had been an uncomfortable fact of life in the United States since the founding of the republic. The constitution was carefully crafted to protect the right to own slaves. Most people at that time were willing to accept the fact that the 700,000 enslaved African Americans living in the United States would be treated as property, not people. Almost all of this slave property was owned by people in the Southern states, where the chattel labor formed the backbone of a plantation economy that produced tobacco, rice, sugar, and a little bit of cotton. Many Northerners had a distinct dislike of slavery; however they assumed that the Northwest Ordinance of 1787, which prohibited slavery north of the Ohio River, would effectively keep the slave population in the South. The United States in 1790 was an economy struggling to survive in a mercantilist world. As Douglass North noted, “the relative scarcity of labor and capital was not likely to be ameliorated in the near future, nor did prospects for expanding markets appear imminent.”[5]

Three developments dramatically changed this scenario. First was the invention of the cotton gin by Eli Whitney in 1790, which greatly reduced the amount of labor required to 'clean' short staple cotton. Second was the emergence of a cotton textile industry in Great Britain, which created a demand for American cotton. Finally, the acquisition of the Louisiana Purchase in 1803 significantly expanded the territory suitable for plantation agriculture. Taken together, these events transformed the United States from the struggling economy of 1790 into a bustling exporter of cotton by the end of the war of 1812.

It is difficult to exaggerate the effect these economic changes had on the political and social development of the United States. Whatever political and moral objections Americans might have to slavery, they all had a huge economic stake in South’s 'peculiar institution'. In the eleven states of the Confederacy, where the slave labor force was the backbone of the plantation economy, one out of three individuals was an economic asset in some slave owner’s portfolio. The $3 billion that Southerners invested in slaves accounted for somewhere between 12% and 15% of all real wealth in the entire United States. Figure 1 charts the increasing value of the stock of slaves from 1805 to 1860. Far from dying out, slavery was expanding at an increasing rate right up to the eve of the Civil War.

The economic problem of slavery was difficult for politicians to deal with because it proved to be very compatible with the capitalistic marketplace in the United States. Most observers of slavery failed to appreciate that the return from an investment in slaves included not only the return from the slave’s labor, but also the value of any children born to female slaves. In 1958 Alfred Chandler and John Meyer developed an 'asset-pricing' model of slavery that demonstrated that the value of slave children made slavery profitable throughout the South. Southern planters, they pointed out, not only grew cotton, rice and tobacco; they also grew slaves. Subsequent research has convincingly supported Conrad-Meyer’s argument that slavery was profitable. Slavery was thefoundation the Southern economy. The staple crops grown by slaves in the South were a pivotal part of the rapid economic growth of the entire United States in the antebellum period. Cotton exports accounted for two-thirds of the value of American exports, and one-fourth of the income accruing to all whites in the slave states could be attributed to slave labor in 1859.[6]

All this brings us back to the arguments surrounding the Hacker-Beard Thesis. While Southern farmers continued to plant more cotton, acquire more slaves and settle more land, things in the North were changing. Whether it is called it a 'market revolution,' an 'industrial revolution,' or “a take-off into sustained growth;” the inescapable fact was that a process of economic and social change was sweeping across the Northern states. Industries expanded; canals and railroads stretched from the Atlantic to the Mississippi; interregional trade flows expanded at a prodigious rate, and immigrants flooded into the cities of the North. The Southern vision of political economy was shaped by an economic system that was basically static in nature. Southerners felt threatened by what they saw as the 'Yankee Leviathan'. As historian James McPherson notes,

When secessionists protested in 1861 that they were acting to preserve traditional rights and values they were correct. … The ascension to power of the Republican Party, with its ideology of competitive, egalitarian, free-labor capitalism, was a signal to the South that the Northern majority had turned irrevocably towards this frightening, revolutionary future.[7]

The Civil War was in reality two revolutions. Southerners launched their revolution—more accurately a counterrevolution—in an effort to break free from political union with the North. Northerners fought to defend the revolutionary process that had transformed their society into a market industrial society.

Arguments over the 'right' to own slave property increasingly became a question of social and economic change. In December 1858 Senator William Seward of New York, told his colleagues that the collision of interests between North and South was not 'the work of interested or fanatical agitators;' it was, he explained, 'an irrepressible conflict between opposing and enduring forces, and it means that the United States must and will sooner or later, become entirely a slaveholding nation or entirely a free-labor nation,' Well-meaning men in congress and elsewhere could debate at length the issues of political economy between North and South, but when push came to shove the problem of what to do with 4 million slaves worth three billion dollars was a deal breaker. As Thomas Jefferson observed after the debates surrounding the Compromise of 1820, 'we have the wolf by the ear, and we can neither hold him, nor safely let him go. Justice is in one scale, and self-preservation in the other.' The inability of lawmakers to deal with economics of slavery proved to be the undoing of the American Union in the fall of 1860. 'The realignment of the 1850s,' wrote James Huston, 'was about slavery, the slave power, and the protection of a free labor village society … Republicans changed the agenda of the country by altering the property rights in people. That is not to say that either side wanted a war. The problem was that neither side was willing to back down from the showdown when it came. On April 12, 1861 Confederate batteries opened fire on Fort Sumter in Charleston Harbor.[8]

The Civil War had begun.

The Economic Costs of the War

In addition to preserving the Union, the Northern victory eliminated the right to own slaves in the United States. These outcomes were achieved at an enormous cost. Three million men – or about 10% of the population of the United States in 1860 and nearly half of all men aged 15-30 – fought in either the Union or Confederate Army. For many years the accepted estimate of deaths was 624,000 men. This figure was based the work of Thomas Livermore, a retired Union officer who studied battle reports and lists of units serving in the war. A more recent estimate of Civil War deaths constructed from census data by J. David Hacker has produced an estimate of around 750,000 deaths. Why so many more? Hacker notes that existing estimates seriously undercounted many war-related deaths. The census data captures deaths of men who died shortly after the war from injuries sustained during the war. Neither method is perfect; however, both suggest a level of mortality among Civil War soldiers that exceeds anything approached in previous or subsequent American Wars. Their deaths produced a legacy of sorrow and bitterness that lingered for generations after Appomattox.[9]

The most comprehensive estimates of the economic costs of the war are those developed by Claudia Goldin and Frank Lewis. Their estimates suggest that government expenditures by both governments totaled $3.3 billion; the estimated 'value' of human capital lost because of deaths in the war was $2.2 billion; and the Physical destruction was just under $1.5 billion. The total bill for the war came to $7 billion – or roughly two full years of GDP in 1860. What stands out from these numbers is not only the absolute magnitude of the costs, but also the disparity in the burden that these costs represented to the people in the North and the South. On a per capita basis, the costs to the Northern population were about $139 – or just slightly less than a year’s per capita GDP the income of the United States economy in 1860. The per capita burden on Southerners was almost three times that amount.[10]

The Union had a clear advantage in the 'economics' of this war. It not only had a population roughly three times the free white population of the Confederacy, it also had the advantage of larger and far more sophisticated market institutions with which to organize its war effort. However, neither side was prepared to raise the revenues required to cover the soaring costs of the war, and it took the better part of a year for each side to 'mobilize'. By the spring of 1862 it was apparent that both would have to resort to a combination of taxation, selling bonds (if they could find anyone willing to buy them), and the issuance of various forms of paper money. Figures 2 and 3 present estimates of the revenues collected by each side to “pay” for the war.

The figures present estimates for revenues raised through taxes, revenues raised by issuing treasury notes as fiat currency, i.e. not backed by or convertible into gold but only backed by silver, and revenues from interest-bearing debt that was sold to private buyers. The dotted line indicates the total revenues adjusted for inflation.[11]

The first thing to note is the extent to which both sides were forced to rely on deficit finance to pay for the war. The Union did succeed in increasing tax revenues by enacting a higher tariff, and higher excise taxes, and passing a tax on incomes above $10,000 per year. Even so, tax revenues accounted for only about a quarter of all federal revenues during the war. Confederates were much less successful in their efforts to obtain tax revenues. They inherited a tax system where tariffs had accounted for three-fourths or more of the federal government’s revenues each year. That tax base quickly eroded away as the effectiveness of the Union blockade increased. Over the course of the war, taxes and assorted revenues accounted for less than 10% of total revenue. With limited possibilities of selling bonds, the Confederates were forced to rely on the printing of money as the primary means of paying their bills. The result of that policy was an inflationary spiral that eventually reached a point where prices were more than 9,000 times their level at the beginning of the war. Inflation played a role in the financial struggles of both governments. In the North prices reached a level in 1865 that was roughly twice the level in 1860. Despite the increase in prices, revenues collected by the Union government rose steadily throughout the war. Inflation imposed a significant 'tax' on Northern consumers, but it did not seriously affect the war effort.

The same cannot be said of the Confederate mobilization efforts. Figure 4 charts the overall rise in commodity prices; it also portrays the impact of the blockade on imported goods—a situation that weighed heavily on the minds of consumers used to getting a variety of their consumption items from abroad. Finally, we can see that the level of the agricultural prices—which comprised the principal source of income for the rural South—lagged behind the costs of other goods. These developments not only drained the morale of Confederates on the home front, they also crippled the Confederate war effort Measured in 1861 prices, the flow of funds to the Richmond government reached their peak by early 1862, remained fairly stable through the middle of 1863, and then declined steadily thereafter. For all intents and purposes, the Confederacy had been reduced to a barter economy by the time Lee surrendered his army at Appomattox.

While the mobilization efforts of the South gradually bankrupted the Southern war effort, the Union was able to develop models of business operations that would influence business practices in the coming decades. In his study of the 'business' of the Civil War, Mark Wilson observes that 'for better or for worse the model of military organization and administration … did influence the modern American imagination to an extent that is rarely recognized.' This was not only true of the production of goods and services; it also pertained to the improvements that allowed the bond markets to absorb $2.3 billion in federal debt issued during the war.[12]

The Economic Consequences of the War

In a civil war, what is a 'cost' to one side may sometimes be regarded as a 'gain' to the other. An obvious example of was the emancipation of 4.5 million slaves. Goldin and Lewis estimate that freeing the slaves resulted in an economic loss of almost 2 billion dollars to southern planters. This loss was a result of the decline in cotton production associated with the end of slavery and the breakup of the plantation system. Goldin and Lewis count this as a 'cost' of the war. Richard Sutch and I point out that this 'cost' can also be considered a measure of the benefits to free black Southerners freed from the exploitation of slavery. The same logic could be applied to the capital losses suffered by slaveholders (including some in the four states that did not secede from the union), which totaled more than $4 billion. Slaveholders saw this decline in their net worth as a very real burden from outcome of the war; Northerners regarded it as a transfer payment that was justified as one of the principal accomplishments of the war.[13]

The war had done away with slavery, but in the process it destroyed the southern banking system and eliminated a major part of Southern antebellum capital stock. The sudden disappearance of both capital and labor meant that the agricultural economy of the South had to be completely restructured. Within a few years the plantation agriculture of the antebellum South had all but disappeared. What emerged in its place was a set of arrangements where landowners leased land to freedmen under a new form of tenure called “sharecropping” where the laborers agreed to work the land in return for a fraction of the crop they produced. Left to their own devices, neither the 'cropper' nor the landlord would have chosen the sharecropping arrangement. Freedmen would have preferred to rent land for cash so they could work their own farm; landlords would have preferred to hire the labor for cash and retain control of their plantation. But there was no cash available in the South in 1865-66 and the crops had to be planted. Sharecropping had the advantage that it was an arrangement that required little or no cash, and the cotton crop served as collateral for advancing credit to buy essentials at the local store.

Unfortunately, sharecropping also had the disadvantage of allowing the landowners and the merchants to exploit their tenants by 'locking' them in to the production of cotton and forcing them to purchase food rather than to grow it. The result was that crop output in the South fell dramatically at the end of the war, and had not yet recovered its antebellum level by 1879. The loss of output was particularly hard on white Southerners, whose per capita income fell from $125 in 1857, to just over $80 in 1859-60 dollars. Freedmen were better off than they had been as slaves, but there was little prospect for them to improve their economic position. Denied the opportunity to own their own land, and confronted with the inefficiency imposed by the share-cropping, blacks faced a grim future. Over the last quarter of the nineteenth century, gross crop output in the South rose by about one percent per year at a time when the GNP of United States (including the South) was rising at twice that rate. By the end of the century, Southern per capita income had fallen to roughly two-thirds the national level, and the South was locked in a cycle of poverty that lasted well into the twentieth century. How much of this failure was due to the war remains open to debate. What is clear is that the hopes of Southerners of both races, for a 'New South' that might emerge from the destruction of war after 1865, were realized.[14]

While the South struggled with the agony of defeat, the North enjoyed the fruits of victory. The demise of the slave power and its antebellum political alignments not only strengthened the federal government it shifted political power into the hands of the victorious Republicans. 'From 1861 to 1877,' writes Richard Bensel, 'the American state and the Republican Party was essentially the same thing; the federal government was simply the vehicle of common interests in economic development associated with northern finance, industry, and free soil agriculture.' In the spring of 1862 congress approved a series of laws that changed the economic landscape of the United States. The National Banking Act established a system of banks that were chartered by the federal government and issued a single currency. The Homestead Act gave settlers allotments of 160 acres of free land in the West. More than 1 million parcels of land were eventually distributed under the terms of this act. The Pacific Railway Act facilitated construction of a railway by giving grants of federal land to build the first transcontinental railroad. By 1900 there were five transcontinental railways and 200,000 miles of railroads in the United States. The Morrill Land Grant Colleges Act established federal land grants that provided the foundation for one of the most impressive systems of public education in the world. The impact of all four of these acts is still evident 150 years later. Additional legislative and judicial actions followed over the next two decades.[15]

The Beards were right in their claim that the Civil War was part of a 'revolution' that already well underway in the Northern states when war broke out. The war itself was an interruption, of that growth pattern but the changes it brought about helped to create one of the most rapid periods of industrial growth in American history. What the Beards did not fully grasp was the economic significance of the Thirteenth amendment to the Constitution which was approved by the House of Representatives on January 31, 1865. The stalemate over slavery that had produced the political crisis of 1861 was at its root an economic problem. In a market society committed to the principle of private property, the enormous influence of the huge investment in slave property was able to effective block any perceived political actions that would place limits on slave property. With a stroke of a pen the abolition of slavery simply eliminated that obstacle to political reform. Unfortunately, the economics of slavery meant that the only way to resolve the disputes over slavery and keep the union together was to wage a bloody war.

Economic factors not only played a large role in bringing about the war, they also had a huge role in determining who won the war. Southerners gambled that Southern spirit and military élan could overcome the wealth and size of the North. They were wrong. In a speech delivered after the war, Robert E. Lee’s former commander Jubal Early remarked on the consequences of that gamble.

General Lee had not been conquered in battle, but surrendered because he had no longer an army with which to give battle. What he surrendered was the skeleton, the mere ghost of the Army of Northern Virginia, which had been gradually worn down by the combined agencies of numbers, steam-power, railroads, mechanism, and all the resources of physical science. … [Four years of fighting] had finally produced that exhaustion of our army and resources, and that accumulation of numbers on the other side, which wrought the final disaster.[16]

General Early had discovered to his dismay that this was a new form of warfare where economics extended far beyond the marketplace onto the battlefields of the war. It is in this sense more than any other that the American Civil War has been termed the first 'modern' war.


----------

# History of Music, and Racism and Civil War #
## [Cowboy and Civil War Song Lyrics](http://lonehand.com/default.html) ##

## [The South between Two Frontiers: Confederate Cowboys and Savage Rednecks](https://www.researchgate.net/publication/237018811_The_South_between_Two_Frontiers_Confederate_Cowboys_and_Savage_Rednecks) ## 
"The myth of the Frontier, which locates the birth of the American nation in its confrontation with a bordering savagery, was a national myth in western films until the 1960s. As a genre shaping the features of Americanness, the Western attracted many ex-confederates in search of political legitimacy and the western Frontier became a place of national rehabilitation for the South. When the narrative of the myth inverted in favor of the Indian in the late 1960s, freedmen replaced confederate heroes in their quest to integrate the national community on screen. The Frontier as America’s birthplace gave the South a second chance and revealed its cultural meaning for the nation. But the Frontier, in its confrontational version of the savage wars, also resonates with the myth of the Lost Cause, in which barbarous freedmen threaten white society. If Birth of a Nation was the first and last film in which Blacks were pictured as dangerous in Hollywood, this internal Frontier reappears with the cultural crisis of the 1960s, when the South becomes home to savages of a new kind, degenerate rednecks, who embody the failure of the national myth in the Western, and come to represent the endemic savagery of America revealed by My Lai and Charles Manson. The South in films wavers between two Frontiers: the Frontier of American regeneration in the Western, and the Frontier as a danger to America in the Southern."

## [Exploring Land, Settling Frontiers](http://www.virginiaplaces.org/settleland/) ## 
"In the days before the Industrial Revolution created a middle class and wealth could be acquired through manufacturing, land for producing crops, wool, meat, and wood products was the basis of English wealth. Land was controlled by the hereditary aristocracy. Peasants had little opportunity to climb the social ladder and join the aristocracy, and little chance to become landowners with control over their own farms.

Roughly half of the population in England owned no land. No matter how hard they worked, those who did not inherit land had little expectation of acquiring it.

The English social system fractured as population grew from 3 million in 1500 to 5 million in 1650. Wealth remained sequestered in just a few families, high unemployment became common, and social unrest erupted into the English Civil War in the mid-1650's.1

An alternative to a lifetime of frustrating, never-ending poverty in England was emigration. Travel across the Atlantic Ocean was unpleasant and dangerous, and moving to the Virginia colony was a great risk. However, migration was the easiest way for many Englishmen to become landowners, and Virginia offered an opportunity for the minor gentry and even lower classes to climb into the upper ranks of wealth and power.

Speculation in land across the Atlantic Ocean spurred changes in traditional business practices in England. The Virginia Company was an early expression of a relatively new economic approach, the joint stock company. It was a legal tool where investors could pool their capital and risk, then share the rewards as a "corporation" rather than as individuals. If the speculative colonization venture failed, the investors' funds disappeared - but only those funds were put at risk, not the entire personal wealth of the investor."


"Explorers like Daniel Boone led the way for many farmers to clear the forest (or clear out the Native Americans) and get started with crops such as corn. Like Boone, not all settlers were savvy enough to retain their property, but many managed to provide a substantial inheritance to their children that would have been impossible in Europe.

The availability of so much cheap land did not guarantee that Virginia society would be more democratic than in England, and plantation agriculture based on tobacco led to slavery. The availability of labor determined how much tobacco could be produced in Virginia, while in England the amount of land owned by a farmer was the limiting factor for production."


"The concept of frontier is often confused with a bright-line boundary, an edge between two places. In descriptions of colonial Virginia, the term 'frontier' is often used from just the point of view of the English culture. Fur traders penetrated into the 'backcountry,' the territory beyond the frontier. As the colonial population expanded, Native American cultures were forced to surrender land, pushing back the 'frontier.'"

## [Confederate Flag](https://www.theguardian.com/us-news/2018/aug/06/pride-and-prejudice-the-americans-who-fly-the-confederate-flag) ##
"A listening tour in Mississippi asks flag supporters why they still support a symbol that represents pain, division and difficult history"
by Donna Ladd with pictures by Kate Medley

“'Effie, it’s just been a bad day,' the lawman said to his sister, as the six-year-old listened. 'I just had to go cut a black boy down off that hanging tree and take him to his mama.'

The infamous tree, used for lynching, was bending over a bridge on Highway 433 toward Lexington.

'What did he do?' Effie Luby asked.

'He raped and killed a white woman.'"

"The first cut of the film also showed Lindy and husband, Ira Isonhood, flying the Confederate battle flag on a 20ft pole in the backyard of one of their homes.

To many white people in the south and beyond, the Confederate flag is a sign of historic pride and defiance to whatever is currently called 'liberalism'; to most black Americans, the flag stands for white supremacy and racial violence. Today, the symbol often appears at 'pro-white' rallies and is a lightning rod in America’s calcifying racial divides."

"The flag’s history is fraught and complicated, as was the bloody civil war that erupted in 1861 between the US south – where America’s slave trade had relocated and expanded by the mid-1800s – and the north. After the north won, it imposed a harsh Reconstruction on the south that still fuels white resentment today.

The post-war white south embraced the Confederate battle flag, making it their sentimental symbol of the 'lost cause' of the war. By the time Mississippi embedded it into its new state flag in 1894, the flag was used to both honor the Confederate dead as well as a **'romanticized'** version of the war’s purpose.

By the mid-20th century, the flag symbolized white resistance to ending segregation laws. The Ku Klux Klan flew it at lynching parties and angry mobs waved it outside public schools as black children enrolled; in front of white “segregation academies” and next to leering dogs unleashed on black protesters wanting the right to vote. (Today, its supporters say the KKK co-opted it.)

The Isonhoods were the first stop of my May 2018 listening tour of Mississippi with photographer Kate Medley to ask flag supporters in our home state why they still support a symbol that represents so much pain, division and difficult history – even as they urge black Americans to get over their resistance to it."


"'The Confederate flag played a big, big part in our history,' Ira says. '… Why are these minorities pushing to do away with this flag? Look at what’s happening to our statues!' he says."

"'Slavery was an issue, but not the cause,' the teacher tells me. He repeats SCV’s selective semantics with precision: the south seceded over 'states’ rights' to financial independence; the north and Abraham Lincoln weren’t against slavery at the outset; northern tariffs were killing the south; few southerners and soldiers owned humans; slavery was fading anyway; and it wasn’t about white supremacy."

"I later relay Lindy’s questions to Genesis Be, a 31-year-old hip-hop artist, public speaker and anti-Confederate flag activist from Biloxi. I met Be after reporting that her grandfather, Pastor Clyde Briggs, was a target of the Klan in the 1960s for trying to organize and arm black people against white supremacy. I have stuck my finger into a bullet hole in her family home where the Klan fired into the wall above where her aunt, then a child, slept."


"By 1861, the south was demanding slavery expansion into western territories, which Lincoln’s 'Black Republicans' adamantly opposed. The SCV is correct, though, that Lincoln did not initially call for emancipation. In fact, Frederick Douglass called Lincoln 'preeminently the white man’s president, entirely devoted to the welfare of white men.'"


"Massey, who identifies as more “Blackfoot-Cherokee” than white, isn’t interested in military history, saying the flag celebrates her heritage as a southerner, period. She grew up in Red Bay, Alabama, in a former slave region that the last census showed as 93% white and 1% black.

'We just didn’t believe in racism. Nobody, my whole town,' she says."


“'It was there when our grandfathers, great-grandfathers, were struggling to feed their six, eight, 10 kids. It flew for all colors, black, white, whatever,' she says."


"Hentz, 41, is from Missouri, once a violent slave state, but calls the flag just an 'inanimate object,' adding: 'Stop letting it control you.'

'If you don’t breathe life into something, it will die,” Massey adds.

The friends reject being offended over what Hentz calls 'just a piece of cloth'.

'It was poor white southerners who fought in these battles, being strung along by rich, property-owning whites who banked on the ignorance and arrogance of the poor whites to fight and die in the war,' Be says."


"Gentlemanly Kevin Davis is surprised when we show up at his large white antebellum-style house in Simpson County. We are stopping by homes with flags, but owners keep pointing us on down the road to him.

Davis – no relation to Jeff – has taught history in public and private schools, and also turned out to be an SCV member. Thirteen of his ancestors fought for the south, but most didn’t own slaves. Three died in battle, and one in a makeshift hospital in the Lyceum at Ole Miss in Oxford, Mississippi – one of numerous buildings built by slaves.

'To me, the flag is not a racist thing. It’s a piece of our heritage that should be left there to honor sacrifices,' Davis says in a cozy parlor, adding that most soldiers were 'dirt-poor farmers' with no slaves."


"We’re on Highway 49 south when it pops up: Flag Heads, which sells 'adult novelties' and Confederate tchotchkes.

If you can put a rebel flag on it, they do: beach towels, BBQ aprons, windshield dice, coasters, flip-flops, polar fleeces, bikinis, umbrellas and more. Pipes fill a glass case, and we avoid the curtained adult room."


"Johnson, CEO of the NAACP, says he wishes poor whites would recognize how powerful politicians have long played racial politics with Confederate emblems – a deliberate strategy to divide them from people with shared economic interests.

'The very same people that exploit the working class for cheap labor and create systems to undermine their development through poor education systems use issues of racial division to maintain economic control,' the NAACP president says."


"The flag could easily be honored or studied in museums, he adds.

'The NAACP respects the constitutional, first amendment right for private citizens to maintain symbols and monuments on private property,' he says. 'Enjoy.'"


"'The war really was about slavery, and they didn’t hide it then,' I say as she listens intently. 'But I don’t believe everyone who likes the flag is racist. Many people were taught certain things.'"

## [Confederate Flag in Popular Culture - Americana or Racist Symbol](https://www.theguardian.com/artanddesign/shortcuts/2015/jun/22/confederate-flag-pop-culture-harmless-americana-racist-symbol) ##

"For a long time the flag was a touchstone for everyone from Primal Scream to the Dukes of Hazzard, but the Charleston murders have brought the American south’s iconic symbol under new scrutiny.

In the pop artist Larry Rivers’s haunting 1959 painting The Last Civil War Veteran, a man lies on his death bed under the flags of both the Confederacy and the Union. It is one of a series of works in which Rivers depicts the Confederate flag as a piece of Americana, a totem of history, a pop icon. He is far from the only artist to have used it in this way.

As the flag of the old American south comes under scrutiny for being an image of – and maybe an incitement to – racism and murderous bigotry, it is worth remembering that for a long time it has had a more ambiguous, apparently innocent reputation in popular culture.

No one accused the Dukes of Hazzard of white suprematism when the good ol’ boys who had a rollicking time in the 1970s TV series flaunted the starred diagonals of the flag that has become famous as the “Confederate battle flag” on their Dodge Charger. Similarly, no one has taken issue with its appearance everywhere from a Primal Scream album cover, which used a photograph of the stars without bars by William Eggleston, to Matt Groening’s self-parodic appearance as a flag-waving, far-right propagandist in The Simpsons (the joke being that it’s the opposite of the truth).

The Confederate flag suddenly looks like a starkly, horribly political totem, but can a flag have only one meaning? It is not even completely authentic: in reality, the southern states had several flags in the civil war, and the famous image is just part of a battery of original insignia, reduced in memory to one. Back when Larry Rivers was exploring it as a pop art icon, Jasper Johns made his great image of the Union flag with layers of collaged newsprint under its wax-painted stars and bars. In Flag, Johns captures the many stories hidden within nationhood. Flags are complex documents.

It is reasonable now to wonder if the Confederate flag is pure racist imagery, but its widespread cultural use would suggest it is more complicated than that. It also raises a bigger question. Is white southern identity itself something that needs to be abandoned or condemned? The proud cultural history of the south embraces everything from Jack Daniels and country music to the novels of William Faulkner and paintings of Cy Twombly – can that cultural richness be dismissed as archaic conservative nostalgia, or worse?

In reality, the struggle between regressive prejudices and human decency in the south has long been fought within its cultural traditions, not against them. The obvious example is country music. Robert Altman’s portrayal of country as a cynical conservative style in his film Nashville now looks like a hopelessly ignorant view of a tradition that includes radical voices like Steve Earle and Townes van Zandt.

The white American south has kept some of its most pestilential prejudices intact since the civil war. But it is not racist to drink bourbon, listen to Texas outlaw music or eat crabcakes, and it may not be racist to display a flag. In the end, it is just a piece of cloth."

"Much like some claim that the religion of Islam has been distorted and misused by some radical groups so is the case with this flag. Once the symbol of a misguided attempt to form a nation of slave holding states it is now been appropriated by hate groups, anti-government types, and militia types. So just as politicians call for those in mainstream Islam to denounce those who distort its tenets than so should they call for this flag to be put away and for strong statements to be made by white Southern Baptists Church leaders of their disgust for those groups and their use of this symbol. The nation it represented was defeated both on the battlefield and by choosing a path against human dignity. The flag belongs in museum as a reminder that people can find all kinds of ways to try to legitimize oppression even forming a central government and associated banner when hypocritically speaking of states rights."

## [Confederate Railroad - Crashing Symbols](https://www.oneillinois.com/stories/2019/7/10/crashing-symbols) ##
"Two flags: one a symbol of the nascent nation, the other a symbol of the insurgent Confederacy that declared itself independent only to be dragged back into the union in the Civil War. It seems simple enough. They’re just flags, after all. What’s the offense?

They’ve both become loaded with significance, that’s what, and many Illinoisans take offense over what they’ve come to represent.

The Confederate stars and bars is a symbol of pride to many in the South, to be sure. But that raises the question, what exactly are people proud of when they display that flag? Southern resilience? A particularly Southern spirit of ornery independence? Outright rebellion? Slavery?

 It’s a loaded symbol, and to many it’s genuinely fearsome, representing not only slavery, but those who would assert white supremacy today."
 
 “The Confederate flag is a symbol of the hate, oppression, and enslavement of African Americans. It was flown over states that committed treason and started a war — so that they could keep enslaving people. Hundreds of thousands were slaughtered in this fight over whether the nation should allow slavery or end it. Abraham Lincoln’s assassin was a disciple of the Confederacy. In short, the Confederate flag symbolizes slavery and the rebellion against the United States, and it is exactly what our state’s greatest son, President Lincoln, was fighting against. This symbol of hate, oppression, and bloodshed is categorically different from political satire.”
 
## [Railroad Songs and Ballads](https://www.loc.gov/folklife/LP/AFS_L61_opt.pdf) ##
"Few folksong collectors in the United States have not encountered at least one railroad song, and few scholars have resisted the temptation to com· ment on the meaning of such material. For a century and a half the iron horse raced across the continent; this journey was as much in the imagination as it was over the land. When a train is seen in oral or written literature and music as a mythical steed it effaces human riders and han·dlers. Yet in life each train is directed and cared for by muscle and nerve. Hence . railroad lore fuses the soun ds o f machines with the emotions of workers. Right-of way construction hands as well as operating and maintenance craftsmen perceive locomotives, cabooses, roundhouses, or track-section s as other mechanics view their own work sites. But a railroad is more than a place to earn a living. Precisely because a train is an artifact in culture which can be labeled "iron horse," it is a highly important symbol in folk tradition.
 
There may have been a legendary time when only railroaders sang their songs and told their stories. But today their lore belongs to all Americans. No indu str ial lore is as widespread as that o f the rails; it seems as much the possession of editors and teachers as of car knockers or hoggers. Consequently, bankers and Boy Scouts feel quite familiar with "Casey Jones" and "John Henry." We are all in debt to authors Ben Botkin, Frank Donovan, Alvin Harlow , Freeman Hubbard, and Archie Robertson for a rich presentation of railroad folklore in their books. We are also fortunate that the commercial phonograph industry offered train songs to the public almost from the inception of sound recordings. In the 1890's "A Night Trip to Buffalo" was popular in cylinder catalogs. In 1966 RCA Victor released a serious anthology, The Railroad in Folksong.

One illustration of the ubiquity of railroad balladry tells something of its function even on the contemporary sce ne . On Easter Sunday , 1967 , the Stoneman Family- an Appalachian string-band group with deep roots in tradition- presented an all train-song concert 

a former Norfolk and Western employee , added a bit of oral wisdom to the program. He indicated that firemen used to knot red bandanas around their necks to keep from being burned by cinders before diesel fuel supplanted coal.

The first curator of the Archive of Folk Song in the Library of Congress was Robert Winslow Gordon, a man who knew railroaders and their songs intimately. During the 1920's Gordon conducted an "old songs" column in Adventure Magazine. He was in constant touch with boomers who opened their hearts to him. Gordon was the first folklorist to collect a rail labor union song, "The ARU," dating from the Pullman strike of 1894. I desired to use this song but, unfortunately, Gordon did not record it, although he did make many cylinder recordings before the Archive perfected portable battery and electrically driven disc equipment in the 1930's.

They used these songs in all their printed anthologies and consequently played a significant role in popularizing occupational material.

Side One of the recording focuses on the construction of the railroad and railroading as a craft. Side Two features the symbolic values found in the train: conquest, escape, reSignation, love, death. If one sees the iron horse as a romantic steed, not unlike the cowboy's bronco or an Indian's pony, it becomes possible to fuse into railroad lore such disparate pieces as hobo and outlaw ballads, or bawdy and gospel songs_ In folk imagination trains do lead to heaven and to hell as well as to Hoboken and to Hackensack. It is ironic to contemplate that, in song, trains probably will continue to travel to the legendary abodes long after service has been discontinued to many earthly hamlets.

The melody , and possibly some stanzas, o f "I've Been Working on the Railroad" ("Dinah") goes back to pre-Civil War minstrel days. "Poor Paddy Works on the Railway" dates itself in the period 1841-47; it became a folk song at least a century ago.


The immigrant group which contributed most to American folklore was the Irish. Although numerous work songs are known from Irish broadsides, pocket songsters, and folios, this piece about a tough but honest workingman seems unreported as a folksong.

Fortunately, Negro railroad construction songs are well known through recordings and printed collections. The building of any roadbed section involved myriad skills: timber falling, brushing, blasting, grading, tie and steel unloading, track laying and lining, spike driving, tie tamping. Each detailed function called for a characteristic rhythm that drew to itself hundreds of floating lyrics. Henry Hankins' "Lining Track," which mentions the Biblical Noah as well as a worldly Corinna, is but one example of hundreds of Library of Congress field recordings for this gente."

## [Historical Reenactment](https://en.wikipedia.org/wiki/Historical_reenactment) ##
"Historical reenactment (or re-enactment) is an educational or entertainment activity in which mainly amateur hobbyists and history enthusiasts put on uniforms and follow a plan to recreate aspects of a historical event or period. This may be as narrow as a specific moment from a battle, such as the reenactment of Pickett's Charge presented during the Great Reunion of 1913, or as broad as an entire period, such as Regency reenactment.

While historical reenactors are generally amateurs, some participants are members of armed forces or historians. The participants, called reenactors, often do research on the equipment, uniform, and other gear they will carry or use. Reenactors buy the apparel or items they need from specialty stores or make items themselves. Historical reenactments cover a wide span of history, from the Roman empire to the major world wars and the Korean War of the 20th century."


"Activities related to "reenactment" have a long history. The Romans staged recreations of famous battles within their amphitheaters as a form of public spectacle. In the Middle Ages, tournaments often reenacted historical themes from Ancient Rome or elsewhere. Military displays and mock battles and reenactments first became popular in 17th century England. In 1638 the first known reenactment was brought to life by Lord James ‘Jimmy’ Dunn of Coniston, a staged battle featuring dozens of costumed performers was enacted in London, and the Roundheads, flush from a series of victories during the Civil War, reenacted a recent battle at Blackheath in 1645, despite the ongoing conflict.[1] In 1674, King Charles II of England staged a recreation of the siege of Maastricht the previous year, in which his illegitimate son James, Duke of Monmouth had been a key commander.[2] An eighty yard wide fortress with twelve foot thick walls and a moat was constructed near Windsor Castle and garrisoned by 500 men.[2] 700 serving soldiers then recreated the siege of the city over the space of five days, including the firing of cannon, the exploding of trench-busting mines, raiding parties capturing prisoners and parleys between attackers and defenders.[2] The reenactment attracted large crowds from London and nearby towns, including noted diarist Samuel Pepys.[2]

In the nineteenth century, historical reenactments became widespread, reflecting the then intense romantic interest in the Middle Ages. Medieval culture was widely admired as an antidote to the modern enlightenment and industrial age. Plays and theatrical works (such as Ivanhoe, which in 1820 was playing in six different productions in London alone)[3] perpetuated the romanticism of knights, castles, feasts and tournaments. The Duke of Buckingham staged naval battles from the Napoleonic War on the large lake on his estate in 1821, and a reenactment of the Battle of Waterloo was put on for a public viewing at Astley's Amphitheatre in 1824.[1]

Historical reenactment came of age with the grand spectacle of the Eglinton Tournament of 1839, a reenactment of a medieval joust and revel held in Scotland,[4] and organized by Archibald Montgomerie, 13th Earl of Eglinton. The Tournament was a deliberate act of Romanticism, and drew 100,000 spectators. The ground chosen for the tournament was low, almost marshy, with grassy slopes rising on all sides.[5] Lord Eglinton announced that the public would be welcome; he requested medieval fancy dress, if possible, and tickets were free. The pageant itself featured thirteen medieval knights on horseback."

"It was held on a meadow at a loop in the Lugton Water. The preparations, and the many works of art commissioned for or inspired by the Eglinton Tournament, had an effect on public feeling and the course of 19th-century Gothic revivalism. Its ambition carried over to events such as a similar lavish tournament in Brussels in 1905, and presaged the historical reenactments of the present. Features of the tournament were actually inspired by Walter Scott's novel Ivanhoe: it was attempting "to be a living reenactment of the literary romances".[6] In Eglinton’s own words "I am aware of the manifold deficiencies in its exhibition—more perhaps than those who were not so deeply interested in it; I am aware that it was a very humble imitation of the scenes which my imagination had portrayed, but I have, at least, done something towards the revival of chivalry".[7]

Most participants are amateurs who pursue history as a hobby. Participants within this hobby are diverse, ranging in age from young children whose parents bring them along to events, to the elderly. In addition to hobbyists, members of the armed forces and professional historians sometimes participate.

The term 'living history' describes the performance of bringing history to life for the general public in a manner that in most cases is not following a planned script. Historical presentation includes a continuum from well researched attempts to recreate a known historical event for educational purposes, through representations with theatrical elements, to competitive events for purposes of entertainment. The line between amateur and professional presentations at living history museums can be blurred. While the latter routinely use museum professionals and trained interpreters to help convey the story of history to the public, some museums and historic sites employ living history groups with high standards of authenticity for the same role at special events.

Living histories are usually meant for education of the public. Such events do not necessarily have a mock battle but instead are aimed at portraying the life, and more importantly the lifestyle, of people of the period. This often includes both military and civilian impressions. Occasionally, storytelling or acting sketches take place to involve or explain the everyday life or military activity to the viewing public. More common are craft and cooking demonstrations, song and leisure activities, and lectures. Combat training or duels can also be encountered even when larger combat demonstrations are not present.

There are different styles of living history, each with its own fidelity to the past. 'Third-person' interpreters take on the dress and work in a particular period style, but do not take on personas of past people; by taking this style, they emphasize to audiences the differences between past and present.[29] 'Second-person' interpreters take on historical personae to an extent, engaging audiences to participate in period activities, such as soap-making or churning butter, thus restaging historical episodes with their spectators.[30] Finally, 'First-person' interpreters "feign previous folk ‘from outward appearances to innermost beliefs and attitudes,’ pretending not to know anything of events past their epoch, and engaging with audiences using antiquated dialects and mannerisms.[31]

In the United States, The National Park Service land; NPS policy "does not allow for battle reenactments (simulated combat with opposing lines and casualties) on NPS property. There are exceptions i.e. Sayde[32] or the Schloss Kaltenberg knights tournament.[33] The majority of combat reenactment groups are battlefield reenactment groups, some of which have become isolated to some degree because of a strong focus on authenticity. The specific German approach of authenticity is less about replaying a certain event, but to allow an immersion in a certain era, to catch, in the sense of Walter Benjamin the 'spiritual message expressed in every monument's and every site's own "trace" and "aura"', even in the Age of Mechanical Reproduction.[34] Historic city festivals and events are quite important to build up local communities and contribute to the self-image of municipalities.[35] Events in monuments or on historical sites are less about the events related to them but serve as staffage for the immersion experience.[34] In Denmark several open air museums uses living history as a part of their concept. These include Middelaldercentret,[36] The Old Town, Aarhus and Frilandsmuseet."

Historians' perspectives on the genre of historical reenactment is mixed. On the one hand, some historians cite reenactment as a way for ordinary people to understand and engage with the narratives about the past in ways that academic history fails to do—namely, that it presents straightforward and entertaining narratives, and allows people to more fully 'embody' the past.[42] Rather than confining the production of historical narratives to academia, some argue that this 'history from below' provides an important public service to educating the public about past events, serving to "enliven history for millions who turn a blind or bored eye on monuments and museums.[42] [31]

Other historians critique the anachronisms present in reenactment and cite the impossibility of truly retrieving and reproducing the past from the vantage point of the present; "We are not past but present people, with experience, knowledge, feelings, and aims previously unknown," writes Lowenthal, and however impeccably we attempt to bring back the past, everything is filtered through our modern lens and senses.[31] Further, others worry that the focus on historical accuracy in the details, such as dress, obscure the broader historical themes that are critical for audiences to understand; this worry is more acute for certain forms of reenactment, such as U.S. Civil War reenactment, that elicit strong feelings and have real impacts in the present-day world.[31] By focusing on the accuracy of details, some worry, the discussion of the war's causes, such as the end of slavery, are confined to the margins.[31]

Further, under the guise of adhering to the past, some worry, the true, underlying purposes of some reenactments can be obscured; namely, that some reenactors defend not only their prescribed side, but also their side's beliefs: as one reenactor put it, "I do this because I believe in what they believed in ... The real pure hobby is not just looking right; it’s thinking right.’[31] In response to this, some historians call for a more 'authentic' approach to presenting the past, wherein the impacts of that representation on present-day society are honestly presented so as not to give an inaccurate picture of the past. "Historical authenticity resides not in fidelity to an alleged past’, cautions an anthropologist, but in being honest about how the present ‘re-presents that past."[43]


----------


# Entrepreneurship #
## [Yes, And](https://en.wikipedia.org/wiki/Yes,_and...) ##
""Yes, and...", also referred to as "Yes, and..." thinking, is a rule-of-thumb in improvisational comedy that suggests that a participant should accept what another participant has stated ("yes") and then expand on that line of thinking ("and"). It is also used in business and other organizations as a principle that improves the effectiveness of the brainstorming process, fosters effective communication, and encourages the free sharing of ideas.

Principles[edit]
The "Yes" portion of the rule encourages the acceptance of the contributions added by others. Participants in an improvisation are encouraged to agree to proposition, fostering a sense of cooperation rather than shutting down the suggestion and effectively ending the line of communication.

In an organizational setting, saying "Yes" in theory encourages people to listen and be receptive to the ideas of others. Rather than immediately judging the idea, as judgment has its place later on in the development process, one should initially accept the idea, which enables the discussion to expand on the idea without limitations. The next step in the process is to add new information into the narrative. The concept of "and" is to sway away from directly changing the suggested material, "and" rather building upon it."


# American Frontier, Moving West #
## [American Frontier](https://en.wikipedia.org/wiki/American_frontier) ##

## [150 Years Ago, The Homestead Act Transformed the West](https://www.hcn.org/wotr/how-150-years-ago-the-homestead-act-transformed-the-west) ##
"All across forests of the West, 10-by-12-foot cabins stand forlorn and forgotten, many with tumbledown roofs and gaping doors. Yet these modest homesteads represent a revolution in public-land policy: They were the culmination of an American dream born of Thomas Jefferson’s belief that at our best, we would become a nation of independent farmers.

This year marks the 150th anniversary of the fruit of Jefferson’s conviction -- the 1862 Homestead Act. The federal law changed the West forever by providing a new start for urban emigrants, immigrant families and single women.

Passed by Congress in 1862, during the Civil War, the Homestead Act celebrates one of the great settlement opportunities in world history. Only a young, brawny nation like the United States would be able, or willing, to give away free land.

Congress realized Jefferson’s dream when it voted to provide 160 acres, a quarter section, of free land, for anyone willing to live on it for five years, plant crops and build a cabin 10 by 12 feet in size to “prove up” their claim. In the American West, 57 percent of homesteaders made good on their claims for 600,000 patents on 80 million acres of what had been public domain.  The lure of free land drew American emigrants in covered wagons as well as European immigrants who crossed oceans and took railroads west.

Blake Bell, historian at the Homestead National Monument of America in Nebraska, notes that the Homestead Act “transformed the United States and the world as millions of lives were forever impacted by the government’s distribution of free land.”

A remarkable feature of this uniquely American law was its openness. The law did not require that homesteaders be American citizens, or even that homesteaders be men. Any adult could take up free land in the West, and dozens of single mothers tried their hand at homesteading.

The Homestead Act became wildly popular, and over the decades different versions of the law would be passed, such as the Timber Culture Act (1873), the Desert Land Act (1877), the Enlarged Homestead Act of 1909, a stock-grazer’s law where ranchers could own the surface but the federal government kept the minerals, and even a special homestead law for World War I veterans. Between 1862 and 1934, when the Taylor Grazing Act greatly diminished homesteading, 4 million land grants averaging 160 acres were made in 30 states.

Of course, fraud flourished.  Conniving ranchers sent their cowboys to homestead key springs and land along creeks. Tales are told of homesteaders swearing on the Bible that they had built a 10-by-12 cabin, without admitting that it was only 10-by-12 inches. Brothers sought adjoining claims and built one cabin straddling 320 acres instead of separate cabins on 160 acres.

Most of the homesteads have long since been incorporated into larger farms or ranches. So it was exciting to find a family that still owns its ancestors’ original homestead of 160 acres, no more, no less. The land is located in the Wet Mountain Valley of Colorado, against the east side of the rugged Sangre de Cristo Mountains.

Named a Colorado Centennial Farm, it represents five generations of consecutive family ownership since Moritz and Matilde Brandenburg homesteaded the ground in 1880. Their land patent was signed by President Chester A. Arthur. Great-great-grandson John Brandenburg explained, “The ground here was like it was in Germany -- loamy soil. It was tough times to homestead. My parents almost lost the place during the Depression in the 1930s, when you couldn’t find a dollar.”

But while thousands of homestead families sold their claims and moved away, the Brandenburgs hung on. Now the land is under a conservation easement held by the San Isabel Land Protection Trust, which safeguards sweeping views of the Sangre de Cristo Range, white now with the first snows.  Brandenburg and his son, Ken, hope to keep their property in the family. As Ken says, “It’s our refuge.”

I grew up on a former homestead of 160 acres in southeast Colorado, attending high school on the High Plains, the short-grass prairie of songbirds, raptors, jackrabbits and grama grass. It was a place of vastness where I had a view as far as the eye could see.

The homesteading legacy that peopled the West endures. Though forlorn cabins, roofless against winter winds, stand empty today, those simple structures represent success for families starting fresh, thanks to the key law that settled the West."

## [The Homestead Act](Homestead Act: Primary Documents in American History) ##
"Enacted in 1862, the Homestead Act encouraged Western migration by offering settlers 160 acres of public land. This guide compiles Library of Congress digital materials, external websites, and a print bibliography."

"Signed into law by President Abraham Lincoln on May 20, 1862, the Homestead Act encouraged Western migration by providing settlers 160 acres of public land. In exchange, homesteaders paid a small filing fee and were required to complete five years of continuous residence before receiving ownership of the land. After six months of residency, homesteaders also had the option of purchasing the land from the government for $1.25 per acre. The Homestead Act led to the distribution of 80 million acres of public land by 1900."

"President Abraham Lincoln’s signing of the Homestead Act on May 20, 1862 granted Americans 160-acre plots of public land for the price a small filing fee. The Civil War-era act, considered one of the United States’ most important pieces of legislation, led to Western expansion and allowed citizens of all walks of life—including former slaves, women and immigrants—to become landowners."


"In a July 4, 1861 speech, Lincoln told the nation the purpose of America’s government was "to elevate the condition of men, to lift artificial burdens from all shoulders and to give everyone an unfettered start and a fair chance in the race of life." He followed through with the passage of the Homestead Act, which remained active for 124 years until it was repealed in 1976, and resulted in 10 percent of U.S. land—or 270 million acres—to be claimed and settled.

The incentive to move and settled on western territory was open to all U.S. citizens, or intended citizens, and resulted in 4 million homestead claims, although 1.6 million deeds in 30 states were actually officially obtained. Montana, followed by North Dakota, Colorado and Nebraska had the most successful claims. Native Americans were forced from their lands and onto reservations to make way for homesteaders.

During a speech made in Ohio in February 1861, Lincoln said the act was “worthy of consideration, and that the wild lands of the country should be distributed so that every man should have the means and opportunity of benefiting his condition."


"Of course, there were those who took advantage of homesteading. According to the National Archives, a limited number of farmers and laborers could afford to build a farm, which included access to tools, crops, livestock and more.

“In the end, most of those who purchased land under the act came from areas quite close to their new homesteads (Iowans moved to Nebraska, Minnesotans to South Dakota, and so on),” the agency states. “Unfortunately, the act was framed so ambiguously that it seemed to invite fraud, and early modifications by Congress only compounded the problem. Most of the land went to speculators, cattlemen, miners, lumbermen, and railroads.”"


"Americans hold a certain image of the West and Great Plains: a vague concoction of pioneers in covered wagons, hardworking, honest farmers, and, of course, Little House on the Prairie. The Homestead Act (1862) garnered widespread interest in settling the U.S. West; it created the impression that anyone willing to work hard could eke out a living on their own property. Self-fashioned pioneers streamed over the prairie’s overland trails in an attempt to forge their own success on the frontier."


"Signed into law by President Abraham Lincoln in 1862 during the Civil War, the Homestead Act was the most comprehensive land distribution bill passed in the nineteenth century. Prior to the act, the U.S. government auctioned or sold public land in large lots that ordinary citizens could not afford to buy or manage. The Homestead Act ambitiously shifted land ownership and development towards average American citizens."


"During the Civil War Abraham Lincoln and his Republican majority passed a series of bills intended to develop the United States West, taking advantage of the fact that there was little competition after the South left Congress. These laws had been stymied during the Antebellum sectional crisis due to the issue of slavery in Western territories."


"The Homestead Act of 1862 stated that any current or future citizen, with a mere ten dollars, could claim a homestead of up to 160 acres of government land, and “improve” the land by putting it to use as a family plot. This meant erecting a dwelling and farming the soil for a period of five years. If the claimant did so for the allotted period, they could then gain ownership of their land free of charge. The act did not define what it meant to be the “head of a family,” save for an age restriction of twenty-one years if a single individual sought land, which made the Act egalitarian; it allowed African Americans, persecuted and famine-struck immigrants, and even women a chance to find freedom and success in the West. Although many of these settlers were not successful (due in part to expanding industrialization and the harsh climate of the Plains), the Homestead Act endured as the driving force for many Americans and immigrants seeking the “American dream,” as well as in exacerbating the strained relationship between the individual farmer and railroad companies who owned the majority of Western territory."


"Kansas: The Land of Promise for African Americans
In the Reconstruction South during the 1870s, volatile racism pushed former black slaves to seek refuge in the Midwest. Many took advantage of the Homestead Act as an opportunity to manage their own households through subsistence farming while forging new lives in the Midwest. The Homestead Act did not ask for an applicant’s race (it was assumed, at the time, applicants would all be white), so in order for historians to find African American homesteading family records in the National Archives, they must triangulate them with other sources."


"Exclusively Black Settlements
Several exclusively black settlements began to emerge in Kansas after the Homestead Act. The most well-known was a town called Nicodermus, established in 1877. Founded by land prospector W.R. Hill and advertised by black minister W.R. Smith to black communities throughout the south, the town steadily increased in size, and by 1880 over 100 people had settled there. As African Americans slowly became disheartened and disillusioned by the difficulty of homesteading, migration numbers tapered off. However, between the years of 1869 and 1879, 27,000 blacks moved to Kansas, and though few found the success they had been hoping for, a considerable number stayed, finding it a better alternative to the South. 10 An 1879 issue of the Topeka Colored Citizen stated: “Our advice…to the people of the South, Come West, Come to Kansas…in order that you may be free from the persecution of the rebels. If blacks come here and starve, all well. It is better to starve to death in Kansas than to be shot and killed in the South.” (24:41) In the end, the challenges of African American homesteaders mirrored those of other settlers: some persevered and stayed, while others went into debt and left, discouraged by an Act that they had hoped would bring them prosperity or, at the very least, a small pocket of land and a home to call their own."

## [Lewis and Clark Expedition](https://www.history.com/topics/westward-expansion/lewis-and-clark) ##
"The Lewis and Clark Expedition began in 1804, when President Thomas Jefferson tasked Meriwether Lewis with exploring lands west of the Mississippi River that comprised the Louisiana Purchase. Lewis chose William Clark as his co-leader for the mission. The excursion lasted over two years: Along the way they confronted harsh weather, unforgiving terrain, treacherous waters, injuries, starvation, disease and both friendly and hostile Native Americans. Nevertheless, the approximately 8,000-mile journey was deemed a huge success and provided new geographic, ecological and social information about previously uncharted areas of North America."

"Most of the land Lewis and Clark surveyed was already occupied by Native Americans. In fact, the Corps encountered around 50 Native American tribes including the Shoshone, the Mandan, the Minitari, the Blackfeet, the Chinook and the Sioux.

Lewis and Clark developed a first contact protocol for meeting new tribes. They bartered goods and presented the tribe’s leader with a Jefferson Indian Peace Medal, a coin engraved with the image of Thomas Jefferson on one side and an image of two hands clasped beneath a tomahawk and a peace pipe with the inscription, “Peace and Friendship” on the other.

They also told the Indians that America owned their land and offered military protection in exchange for peace.

Some Indians had met “white men” before and were friendly and open to trade. Others were wary of Lewis and Clark and their intentions and were openly hostile, though seldom violent.

In August, Lewis and Clark held peaceful Indian councils with the Odo, near present-day Council Bluffs, Iowa, and the Yankton Sioux at present-day Yankton, South Dakota."

"They crossed through Montana and made their way to the Continental Divide via Lemhi Pass where, with Sacagawea’s help, they purchased horses from the Shoshone. While there, Sacagawea reunited with her brother Cameahwait, who hadn’t seen her since she was kidnapped."

"Lewis’ group took a shortcut north to the Great Falls of the Missouri River and explored Marias River—a tributary of the Missouri in present-day Montana—while Clark’s group, including Sacagawea and her family, went south along the Yellowstone River. The two groups planned to rendezvous where the Yellowstone and Missouri met in North Dakota."


"Lewis and Clark returned to Washington, D.C., in the fall of 1806 and shared their experiences with President Jefferson.

While they had failed to identify a coveted Northwest Passage water route across the continent, they had completed their mission of surveying the Louisiana Territory from the Mississippi River to the Pacific Ocean, and did so against tremendous odds with just one death and little violence.

The Corps had traveled more than 8,000 miles, produced invaluable maps and geographical information, identified at least 120 animal specimens and 200 botanical samples and initiated peaceful relations with dozens of Native American tribes.

Both Lewis and Clark received double pay and 1,600 acres of land for their efforts. Lewis was made Governor of the Louisiana Territory and Clark was appointed Brigadier General of Militia for Louisiana Territory and a federal Indian Agent.

Clark remained well-respected and lived a successful life. Lewis, however, was not an effective governor and drank too much. He never married or had children and died in 1809 of two gunshot wounds, possibly self-inflicted. A few years later, Sacagawea died, and Clark became her children’s guardian."

## [New Frontiers: South and West](https://wwnorton.com/college/history/archive/resources/documents/ch19_01.htm) ##
"The end of the Civil War found Americans confronting two frontiers of opportunity: the devastated South and the untamed West. They were—and are—the most distinctive sections of the country, and both regions exerted a magnetic attraction for adventurers and entrepreneurs. In the postwar South, people set about rebuilding railroads, mills, stores, barns, and homes. In the process of such renewal, a strenuous debate arose over the nature of the "New South." Should it try to recreate the agrarian culture of the antebellum period? Or should it adopt the northern model of a more diversified economy and urban-industrial society? The debate was never settled completely, and as a result both viewpoints competed for attention throughout the last quarter of the nineteenth century. By 1900, the South remained primarily an agricultural region, but it also had developed a far-flung network of textile mills, railroad lines, and manufacturing plants.

African Americans in the former Confederacy often found themselves at the center of the economic and political debate in the "New South." By the end of the century, black leaders themselves were divided over the best course to follow. For his part, Booker T. Washington counseled southern blacks to focus on economic and educational opportunities at the expense of asserting their political and legal rights. Not so, declared W. E. B. Du Bois. He attacked Washington's "accommodationist" strategy and urged blacks to undertake a program of "ceaseless agitation" for political and social equality.

Controversy also swirled around the frenzied renewal of western settlement after the Civil War. During the century after 1865, fourteen new states were carved out of the western territories. To encourage new settlers, the federal government helped finance the construction of four transcontinental railroads, conquered and displaced the Indians, and sold public land at low prices. Propelled by a lust for land and profits, millions of Americans headed west across the Mississippi River to establish homesteads, stake out mining claims, and set up shop in the many "boom towns" cropping up across the Great Plains and in the Far West.

This postwar surge of western migration had many of the romantic qualities so often depicted in novels, films, and television. The varied landscape of prairies, rivers, deserts, and mountains was stunning. And the people who braved incredibly harsh conditions to begin new lives in the West were indeed courageous and tenacious. Cowboys and Indians, outlaws and vigilantes, farmers and herders populated the plains, while miners and trappers led nomadic lives in hills and backwoods.

But these familiar images of western life tell only part of the story. Drudgery and tragedy were as commonplace as adventure and success. Droughts, locusts, disease, tornadoes, and the erratic fluctuations of commody markets made life relentlessly precarious. The people who settled the trans-Mississippi frontier were in fact a diverse lot: they included women as well as men, African Americans, Hispanics, Asians, and European immigrants.

Many of the settlers were also blinded by short-sighted greed and prone to irresponsible behavior. In the process of "removing" the Indians, military forces sometimes exterminated them. By the 1890s there were only 250,000 Native Americans left in the United States. The feverish quest for quick profits also helped fuel a boom/bust economic cycle that injected a chronic instability into the society and politics of the region.

The history of the Old West is thus a much more complicated story than that conveyed through popular culture—or through the accounts of some historians. In 1893 the historian Frederick Jackson Turner announced his so-called frontier thesis. The process of taming and settling an ever-receding frontier, Turner declared, gave American culture its distinctive institutions, values, and energy. The rigors and demands of westward settlement, for example, helped implant in Americans their rugged individualism and hardihood, and such qualities helped reinforce the democratic spirit that set them apart from other peoples. "Up to our day," Turner said, "American history has been in large degree the history of the colonization of the Great West. The existence of an area of free land, its continuous recession, and the advance of American settlement westward, explain American development." He was both right and wrong. The frontier experience explains much about the development of American society, but not all."

## [Montana Bullriders & Confederate Flag](https://www.goldmountaintrading.com/bullrider-buckle.html) ##
"Large Bullrider Buckle with Flags by Montana Silversmiths. A 4 inch by 5 inch buckle with lots of color and contrast ... no doubt is left that the wearer of this buckle is into bulls, bulls, and more bulls! American and Confederate flags frame a bull and rider going at full steam ahead. Silver stars shine brightly against the black bordered background."

## [The Wild West Meets the Southern Border](https://www.newyorker.com/magazine/2019/06/10/the-wild-west-meets-the-southern-border) ##
"The show is about to start, so we step into the O.K. Corral and find seats in the metal bleachers, among twenty or thirty spectators. The show itself goes over my head—Clantons, Earps, Clantons, Earps—but every single one of the many gunshots in the short performance makes me jump. Perhaps because I didn’t grow up in the U.S., Wild West reënactments evoke no nostalgia in me. When I ask American friends what they know about the reënactment world, most mumble something about the Civil War. Some were dragged as kids to a reënactment of the Battle of Gettysburg, which for the past twenty-five years has taken place annually at the site where the real battles were fought. Few people I come across know that there are more than fifty thousand Civil War reënactors in the country, members of a guild with strict hierarchies and distinctions. Tony Horwitz, in his book “Confederates in the Attic,” analyzes what he calls “a period rush,” the particular adrenaline-fuelled energy that comes with being fully immersed in an authentic re-creation. Authenticity is the yardstick in reënactment culture. A “farb” is a reënactor who doesn’t spend enough time or money on props and costumes. The most committed call themselves “living historians,” and the “hard-cores” among them sometimes go on spartanlike diets in order to resemble underfed nineteenth-century soldiers; others soak the buttons that they sew on their uniforms in urine, to generate just the right amount of rust."

"America was mythologizing, via tourism and pop culture, its still recent past, and there was plenty of material to work with. In the latter half of the nineteenth century, nickelodeons and dime novels had featured the “lawless towns” of the West, and stories of cowboys, saloons, gunfights, and outlaws had become part of the collective imagination. Then came television and Hollywood, to further consolidate the myths of the Wild West."

"Traywick is full of stories, a kind of Wizard of Oz of Tombstone, and the author of countless reënactment skits. He wrote the original O.K. Corral scene (and played Wyatt Earp for twenty years)."

"Traywick tells Pejk and Cantú a long story about beheadings in China and shows them pictures of decapitated men, while I browse in the bookstore. There’s a Confederate flag in the back, some Mayan masks and relics behind Traywick’s desk, a few dusty mariachi hats, many framed pictures of admirals and generals—among them Nathan Bedford Forrest, a Confederate Army general and the first Grand Wizard of the Ku Klux Klan—and a poster of Donald Trump dressed as a cowboy, with a gun under his belt, and the slogan 'Keeping America Safe Again.'"

"The mythos of the Wild West celebrates the spirit of those who sought to settle in a new land, domesticate its difficulties, and thrive. Why, I ask, is that spirit admired in some cases and condemned in others? Our Shakespeare guides protest that I’m conflating two different things. One case is 'historical' and the other is . . . not."

"Driving south, toward the border, we see no signs of crisis, no migrants, and few cars. We see a Border Patrol cam truck—a pickup with a surveillance camera mounted on a tall mast—and many commercial trucks, probably transporting commodities in and out of the country. The great paradox of the nafta agreement is that it has allowed for freer trade of merchandise across the border, and less freedom of movement for people."


"Shakespeare is in New Mexico. Tombstone, in Arizona. Both are old mining towns near the U.S.-Mexico border. They came into existence in the eighteen-seventies, during the silver strike, but soon suffered the same fate as most of the other mining towns in the region: boom, depression, abandonment, and then a strange kind of afterlife."

## [The Myth of the Cowboy](https://www.theguardian.com/books/2013/mar/20/myth-of-the-cowboy) ##
"Our starting point is the fact that, in and outside Europe, the 'western' in its modern sense – that is, the myth of the cowboy – is a late variant of a very early and deep-rooted image: that of the wild west in general. Fenimore Cooper, whose popularity in Europe followed immediately upon his first publication – Victor Hugo thought he was 'the American Walter Scott' – is the most familiar version of this. Nor is he dead. Without the memory of Leatherstocking, would English punks have invented Mohican hairstyles?

The original image of the wild west, I suggest, contains two elements: the confrontation of nature and civilisation, and of freedom with social constraint. Civilisation is what threatens nature; and their move from bondage or constraint into independence, which constitutes the essence of America as a radical European ideal in the 18th and early 19th centuries, is actually what brings civilisation into the wild west and so destroys it. The plough that broke the plains is the end of the buffalo and the Indian.

In terms of literary pedigree, the invented cowboy was a late romantic creation. But in terms of social content, he had a double function: he represented the ideal of individualist freedom pushed into a sort of inescapable jail by the closing of the frontier and the coming of the big corporations. As a reviewer said of Frederic Remington's articles, illustrated by himself in 1895, the cowboy roamed 'where the American may still revel in the great red-shirted freedom which has been pushed so far to the mountain wall that it threatens soon to expire somewhere near the top'. In hindsight, the west could seem thus, as it seemed to that sentimentalist and first great star of movie westerns William S Hart, for whom the cattle and mining frontier 'to this country … means the very essence of national life … It is but a generation or so since virtually all this country was frontier. Consequently its spirit is bound up in American citizenship.' As a quantitative statement this is absurd, but its significance is symbolic. And the invented tradition of the west is entirely symbolic, inasmuch as it generalises the experience of a comparative handful of marginal people. Who, after all, cares that the total number of deaths by gunshot in all the major cattle towns put together between 1870 and 1885 – in Wichita plus Abilene plus Dodge City plus Ellsworth – was 45, or an average of 1.5 per cattle-trading season, or that local western newspapers were not filled with stories about bar-room fights, but about property values and business opportunities?

Is this Reaganite myth of the west an international tradition? I think not. In the first place because the major American medium by which the invented west was propagated has died out. The western novel, as I have suggested, is no longer an international phenomenon. The private eye has killed the Virginian. Larry McMurtry and his like, whatever their place in American literature, are virtually unknown outside their native country. As for the western movie, it was killed by TV; and the western TV series, which was probably the last genuinely international mass triumph of the invented west, became a mere adjunct to children's hour, and in turn it has faded away. Where are Hopalong Cassidy, The Lone Ranger, Roy Rogers, Laramie, Gunsmoke and the rest on which the kids of the 1950s thrived? The real western movie became deliberately highbrow, a carrier of social, moral and political significance in the 1950s, until it in turn collapsed under their weight as well as the advancing age of the makers and stars – of Ford and Wayne and Cooper. I'm not criticising them. On the contrary, practically all the westerns that any of us would wish to see again date from after Stagecoach (which was released in 1939). But what carried the west into the hearts and homes of five continents was not movies that aimed at winning Oscars or critical applause. What is more, once the late western movie had itself become infected by Reaganism – or by John Wayne as an ideologist – it became so American that most of the rest of the world didn't get the point, or, if it did, didn't like it.

In Britain, at least, the word 'cowboy' today has a secondary meaning, which is much more familiar than the primary meaning of a fellow in the Marlboro ads: a fellow who comes in from nowhere offering a service, such as to repair your roof, but who doesn't know what he's doing or doesn't care except about ripping you off: a 'cowboy plumber' or a 'cowboy bricklayer'. I leave you to speculate (a) how this secondary meaning derives from the Shane or John Wayne stereotype and (b) how much it reflects the reality of the Reaganite wearers of dude Stetsons in the sunbelt. I don't know when the term first appears in British usage, but certainly it was not before the mid-1960s. In this version, what a man's got to do is to fleece us and disappear into the sunset.

What was so special about cowboys? First, clearly, that they occurred in a country that was universally visible and central to the 19th-century world, of which it constituted, as it were, the utopian dimension: the living dream. Anything that happened in America seemed bigger, more extreme, more dramatic and unlimited, even when it wasn't – and of course often it was, though not in the case of the cowboys. Second, because the purely local vogue for western myth was magnified and internationalised by means of the global influence of American popular culture, the most original and creative in the industrial and urban world, and the mass media that carried it and which the US dominated. And let me observe in passing that it made its way in the world not only directly, but also indirectly, via the European intellectuals it attracted to the US, or at a distance.

This would certainly explain why cowboys are better known than vaqueros or gauchos, but not, I think, the full range of the international vibrations they set up, or used to set up. This, I suggest, is due to the in-built anarchism of American capitalism. I mean not only the anarchism of the market, but the ideal of an individual uncontrolled by any constraints of state authority. In many ways the 19th-century US was a stateless society. Compare the myths of the American and the Canadian west: the one is a myth of a Hobbesian state of nature mitigated only by individual and collective self-help: licensed or unlicensed gunmen, posses of vigilantes and occasional cavalry charges. The other is the myth of the imposition of government and public order as symbolised by the uniforms of the Canadian version of the horseman-hero, the Royal Canadian Mounted Police.

I don't think it was an accident that the ideal-typical cowboy hero of the classic invented west was a loner, not beholden to anyone; nor, I think, that money was not important for him. As Tom Mix put it: "I ride into a place owning my own horse, saddle and bridle. It isn't my quarrel, but I get into trouble doing the right thing for somebody else. When it's all ironed out, I never get any money reward.

In a way the loner lent himself to imaginary self-identification just because he was a loner. To be Gary Cooper at high noon or Sam Spade, you just have to imagine you are one man, whereas to be Don Corleone or Rico, let alone Hitler, you have to imagine a collective of people who follow and obey you, which is less plausible. I suggest that the cowboy, just because he was a myth of an ultra-individualist society, the only society of the bourgeois era without real pre-bourgeois roots, was an unusually effective vehicle for dreaming – which is all that most of us get in the way of unlimited opportunities. To ride alone is less implausible than to wait until that marshal's baton in your knapsack becomes reality."

## [Cowboys in Life and Legend](https://faculty.chass.ncsu.edu/slatta/cowboys/CBintro.htm) ##
"Etymologists trace the use of the term cowboy back to 1000 AD in Ireland. Swift used it in 1705, logically enough, to describe a boy who tends cows. Modern usage, first in hyphenated form, dates from the 1830s in Texas. Colonel John S. "Rip" Ford used the word cow-boy to describe the Texan border raider who drove off Mexican cattle during the 1830s. The term carried a tinge of wildness, of life at the fringes of law and 'civilization.' After the American Civil War, Westerners applied the term cowboy to ranch hands, rather than cattle thieves. 

The Denver Republican (October 1, 1883) observed that 'it matters not what age, if a man works on a salary and rides after the herd, he is called a 'cowboy.' A cowboy, then as now, is a man who works at least part of the year as a salaried ranch hand. Ranchers or 'cowmen' owned land and cattle; cowboys did not own land and seldom owned cattle.

The cowboy of the American West, a dashing figure in popular novels and films, was in reality a poorly paid laborer engaged in difficult, dirty, often monotonous work. During the years after the Civil War the range cattle industry spread northward from Texas. During the 1870s cowboying spread to the Southwest and the northern plains. Although some of the young men who worked on these ranches were from the northeastern states, a majority were probably southerners. Many had fought for the Confederacy. 

Cowboys branding cattle - RACE: Unlike most movie depictions, not all cowboys were white. Racial distribution varied from place-to-place. Mostly Anglo cowboys worked the Montana ranges. Further south, however, in Texas, for example, perhaps one-third of the hands may have been African-Americans or Mexican-Americans. 

Cowboys herding cattle - WORK LIFE: The Cowboy's work year centered on two big events, the roundup and the long drive. Roundups were held in the spring and often also in the fall. After cowboys had herded cattle to a central location, they branded newborn calves, castrated and dehorned older animals, and, in the spring, chose the cattle to be taken to market. 

From 1865 to 1880 at least 3.5 million cattle were driven in herds of between 1,500 and 3,000 from southern Texas to cattle towns on rail lines in Kansas, Nebraska, and Wyoming. The route most frequently used was the Chisholm Trail which went to Abilene, Kansas. Working up to 20 hours a day, cowboys drove the animals from one watering place to the next. They had to guard against predators (two- and four-footed), straying cattle, and stampedes at night. For his hard and dirty work the typical cowboy earned between $25 and $40 a month. 

By about 1890 much of the range had been fenced. The westward extension of the railroads eliminated the need for the long cattle drives. The 'good old days' of epic drives and open range riding came to an end. At this point, however, dime novels wild west shows, and books such as Owen Wister's The Virginian (1902) offered the nostalgic public a stalwart, romantic cowboy hero. Although far removed from the drab truth, the image of excitement, freedom, and drama continues to dominate popular accounts of the cattle frontier. 

Cowboys bedding down for the night - VIEWS OF THE COWBOY: The cowboy generated conflicting appraisals. When observed at the end of a long trail drive, 'hellin' 'round town," cowboys attracted little praise. The Topeka Commonwealth (August 15, 1871), painted an unflattering portrait of the cowboy on a tear.

Cowboys were no paragons of virtue, as many romantics and popularizers would have it. Nor were they the uncouth barbarians of the plains described by self-anointed spokesmen of civilization and culture. Externalities--principally the law and employers--imposed restrictions that shaped their lives. But cowboys lived as much as possible by their own internal codes of conduct. The cardinal virtues for the American cowboy were to do his best and to be cheerful, courageous, uncomplaining, helpful, and chivalrous. Of course, few cowboys maintained these ideals at all times in their lives."

## [The Myth of the Literary Cowboy, Part 1: Peculiarly American](https://blog.pshares.org/the-myth-of-the-literary-cowboy-part-1-peculiarly-american/) ##
"Being raised in West Texas, I have experience with cowboys. I’ve taught and been taught by them, worked with them, listened to their poetry, and eaten their food. My cowboys are the real, working men who get their hands dirty, but have never (to my knowledge) been in a shoot out. This, however, does not diminish my love for their literary counterparts: the lean silhouette against a sunset, hat tipped, cigarette dangling, gun at hip. Whether L’Amour or McMurtry, Shane or Cool Hand Luke, Gunsmoke or Deadwood, I, like most Americans, have grown up with the cowboy, a unique character spun from the past that has become part of our mythology.

After the Civil War smoke cleared, America was challenged with not just rebuilding the nation, but constructing a new national identity that favored neither North nor South. Rather, the call was for a cohesive story for the future that could overcome war-time grudges and fit into a singular American identity. In 1901, Theodore Roosevelt, a man who built his image on cowboy masculinity, gave America a place to look for this new culture in his “Manhood and Statehood” speech: '[This] Republic will find its guidance in the West, because the conditions of development in the West have steadily tended to accentuate the peculiarly American characteristics of its people.'

These peculiar characteristics would find their home against backdrop of the neutral West, with the cowboy a hero the divided country could root for. Despite a general dislike of British traditions during this time, writers like Owen Wister and Zane Grey sculpted the cowboy from the central figure of the British knight in popular tales of King Arthur and Robin Hood.

During my graduate Arthurian Literature course, we were asked about the survival of knighthood chivalry in the the American cowboy. Pregnant at the time, I gave an emotional answer about the cowboys I knew, like a man at work who was so concerned I wouldn’t have a ride to the hospital due to my husband’s work schedule, he insisted on giving me his home phone number (he also brought me pie every week).

On a literary level, comparing the two had not crossed my mind until then, but the similarities are evident. Horse-reliant wanderers, they are symbols of gallantry and masculinity forged during times of social and economic change. The cowboy rode out of the Civil war; the knight rose to popularity in the waning years of feudalism. Beyond a military figure, the literary knight was romanticized with a chivalric code, and became a dispenser of justice and bringer of order.

Similarly, the American cowboy character, removed from the actual vocation (and not to be confused with other cowboy types such as the vaquero, gaucho, or buaso), represented an ideal separate from the feudalistic South and industrial North — Anglo, stoic, spiritual, self-reliant, and detached from the corruptions of society. As with the knight, the cowboy was tasked with settling the West and maintaining order in whatever way he might define it. The West became a place of black hats and white hats where moral order reined above all else. On that front, while the knight might answer to a king, the cowboy answered only to himself (and God), allowing him, like America, to construct his own rules and identity, a prime example of the “American Adam” described by R.W.B. Lewis.

The cowboy also owes his construction to exaggerated legends of real, still-living men. The existence of a historical Arthur or Robin Hood warrant continued debate; men like Jesse James and Wyatt Earp not only existed, but achieved celebrity because their exploits were sensationalized in newspapers and dime novels, blurring the line between fact and fiction, folk tale and journalism. Wild West shows became the stomping ground for those swept up in the romance of the fictionalized West, selling the American people its lawlessness as entertainment. Controlled and bereft of real danger, it allowed people to experience the lifestyle from a safe distance that kept the image intact.

With time, the cowboy would add singer, poet, and entertainer to his list of achievements, the character appearing in multiple mediums while still maintaining the basic elements developed by those early writers. Like Arthurian lore, the cowboy would be redefined and rebuilt each generation, at once thoroughly American yet malleable for stories representing a wildness and code of living, no matter the time or place.

Part of the continuing appeal might be the paradox of morality—the cowboy’s untamed toughness is tempered with personal ethics that make him a moral equalizer, a purveyor of justice outside the law. Because this can best be tested in places where wildness still exists, it makes sense that the cowboy of today is often sent into space for a Woody meets Buzz Lightyear smashup of tradition and technology. No matter his location, the literary cowboy will never truly be tamed. His rejection of the societal trappings is crucial, as he is not part of any specific social class. In fact, attempts to civilize him end poorly (or comically as the story calls for it).

The literary figure of the cowboy might have been constructed as a part of nationalist sentiment, but he has come to represent an ideology that is inseparable from America (as evidenced by the many times Team USA athletes have entered an Olympic stadium in cowboy hats). Perhaps because the cowboy icon is such a part of our culture, he cannot be assigned to any other nationality, and he continues to garner invitations to the range of imagination. In the coming months, I will be walking through the cowboy’s peculiarly American history in literature from his development in Wister’s The Virginian to his deconstruction in recent years on the page and screen. So saddle up, and get ready for a ride!"

## [The Myth of the Literary Cowboy, Part 2: Make Me a Cowboy](https://blog.pshares.org/the-myth-of-the-literary-cowboy-part-2-make-me-a-cowboy/) ##
"Last time on Myth of the Literary Cowboy, our hero was developed from the English knight as a post-Civil War appeal to nationalism, and my husband discovered I withheld pie a few years ago.

While the cowboy is inspired by the knight, however, he is his own man, one defined by characteristics that have become part of American pop culture. Dime novels and real life heroes sparked the imagination, but it was the novel of one man that gave us a literary blueprint for how to make a cowboy: Owen Wister’s The Virginian.

Made most famous by Gary Cooper on the big screen and James Drury on the small, The Virginian has numerous adaptations. The novel, written in 1902, created Westerns as we know them, taking them out of the cheap realm of pulp novels and into their own literary genre. Wister combined several Western-set short stories with elements of Arthurian literature, mixed in a romance, and seasoned it with a dash of Theodore Roosevelt, to whom the novel is dedicated.

A cowboy known only as the Virginian leads the inexperienced, unnamed narrator through the wilds of Wyoming to Judge Henry’s ranch in Sun Creek, where the story focuses on the Virginian’s life in the lawless West. The story contains all the elements we have come to expect in a Western: love, hate, revenge, friendship, action, and violence.

At the core of the story is the Virginian, who would be the literary cowboy model for decades to come. In a 1988 New York Times article, Larry McMurtry, who is the most noteworthy shaper of Western literature in the past fifty years, named himself “a critic of the myth of the cowboy.” I would agree, but I would also argue that in order to criticize, he still relies on the pattern established by Wister. (I would not, however, argue this to his face. He wore jeans to collect his Academy Award—I don’t mess with that kind of swagger.) McMurtry, Grey, McCarthy, L’Amour, and a passel of others may twist, deify, or deconstruct the cowboy, but there are some fundamentals that define their characters as cowboys thanks to Mr. Wister and his Virginian.

Mad Horse Skills

In 1956, Disney created an animated short called “A Cowboy Needs a Horse.” The song by George Bruns (which I might guess is part of Texas preschool curriculum; both my kids have learned it) begins with the film’s title, clearly pointing out the horse as rudimentary part of a cowboy’s life. This is one of those elements that harkens back to the knight; after all, neither can ride the country-side righting wrongs without a noble steed. The Virginian is even subtitled The Horseman of the Plains, and our first view of the Virginian is roping a pony with ease—after which it becomes evident that he has a special way with horses, so much so that he woos his future wife through riding lessons. Monte, his own mount, is by his side for the majority of novel.

Self-Made

The West was viewed as a land of opportunity where people could build their own destinies. Cowboys are the personification of that desire. Even if they come from wealth or status, they reject those traditions to construct their own destinies. The Virginian left home at 14 because he disagreed with his family. We know little else of his past except that he does not return to his family, as they no longer understand him. His ties to his past are irrelevant. On the merit of his skills and hard work he is made the ranch foreman. Not satisfied with life as a simple horseman, the Virginian reads works of literature, showing a preference for Shakespeare. His mind, identity, and moral code are his own to define.

Moral

Speaking of the moral code, the Virginian showcases this shining characteristic of the cowboy. Later television incarnations would amp up the white hat/black hate view of the West, but Wister presents the complex justice of cowboy morality. Perhaps one of the novel’s most profound subplots centers on the Virginian hanging a group of cattle rustlers which includes his one-time friend, Steve. Many, most notably the Virginian’s love Molly, call him a murderer. He stands by his actions and eventually the Judge supports his proceedings, arguing that in the absence of government action, people must become the enforcers.  By exploring Western law in this way, Wister develops the image of the gun and the cowboy as the balance of right in the untamed (and often crooked) wilderness. The cowboy then must define justice for himself and defend right in the face of corruption.

Masculine

The West is no place for guy liner and androgyny. Like Roosevelt, the Virginian is a picture of masculinity, one who showcases leadership skills which eventually lead him to be made foreman of the Judge’s ranch. He has the respect of his fellow cowboys (who he can also joke with) and the admiration of ladies. He’s a man’s man, physically and mentally sturdy, with an equally strong moral character and stoicism. The narrator, upon viewing a collection of cowboys at the beginning of Chapter 3, notes “In their flesh our natural passions ran tumultuous; but often in their spirit sat hidden a true nobility, and often beneath its unexpected shining their figures took on heroic structure.” Which leads us to . . .

Brave

As with the knights and epic heroes, the cowboy must be brave. We know the Virginian is brave because we are told so by a dealer who claims only cowards are dangerous with guns as they’ll “always go shooting before it’s necessary.” Courageous men like the Virginian will only shoot when all else fails and never out of fear. By the time the Virginian shoots, the dealer asserts, “it’d be too late” to worry. Not only does this digression comment on the nature of the cowboy, it provides foreshadowing for the climax of the book when the Virginian does enter into a duel to defend his honor, and his enemy, a coward who has shadowed him throughout the book, has left him no other options.

Good with a Gun

Like any good hero, the Virginian must be tested by a villain. In this case that scoundrel is Trampas, who is established early in the novel as an enemy when he calls the Virginian a “son-of-a—” during a card game. The Virginian’s response, “When you call me that, smile,” sets in motion a five-year vendetta that culminates in a showdown.

The gunfight might be Wister’s most important contribution to the cowboy. To truly be a cowboy, the character must be a skilled gunfighter. Whether or not he uses those skills depends on the circumstances. But they must be present, at the ready to burn rivals when all else fails so that justice may win the day.

The cowboy is a complex individual who could warrant a whole book of analysis. These fundamentals are just the highlights of this American favorite. Tune in next time as we take a gander at the television and film cowboys who rode across the screen and into America’s hearts."

## [American Cowboy](https://books.google.com/books?id=y-oCAAAAMBAJ&pg=PA22&lpg=PA22&dq=cowboys+western+romantic+southern+virgins&source=bl&ots=R8twtrv8WP&sig=ACfU3U23r3Vlw0CqQl0okOuMmrKnm6FQlg&hl=en&sa=X&ved=2ahUKEwjDx8qQsejuAhVqGVkFHbS9BcU4FBDoATADegQIBhAC#v=onepage&q&f=false) ##

## [A Two Horse Race: An Explanation of the Virginian's Natural Equality Based on Man's Faculty of Reason and Sentiment of Pity](https://www.ashbrook.org/wp-content/uploads/2012/06/2007-Leibolt.pdf) ##

## [How Mark Twain Invented the Wild West](https://themillions.com/2017/01/how-mark-twain-invented-the-wild-west.html) ##

## [Roughing It](https://en.wikipedia.org/wiki/Roughing_It) ##

## [Mark Twain](https://texastrailoffame.org/inductees/mark-twain/) ##
"Samuel Langhorn Clemens, better known by his pen name, Mark Twain, is an American icon whose razor-sharp wit and inimitable genius have entertained countless readers for more that a century. His many publications include such gallant childhood essentials as The Adventures of Tom Sawyer and Adventures of Huckleberry Finn along with many other works ranging from airy magazine columns to focused, biting, anti-imperialist satire."


----------


# Journalism #
## [Satire](https://oxfordre.com/communication/view/10.1093/acrefore/9780190228613.001.0001/acrefore-9780190228613-e-871) ##
"Satire represents a form of public discourse that invites critical judgment of some sociopolitical folly, absurdity, or contradiction. Through devices like exaggeration, irony, and imitation, a satirical text aspires to cut through spin, deception, and misrepresentation in order to spotlight a given state of affairs as they are or could be. That is, satire is propelled by an impulse to elucidate; to highlight some truth. In many respects, journalism’s normative aspirations are similar to that of satire. Journalism’s guiding principles are commonly discussed in light of a central mission to seek and report the best obtainable version of the truth. Though satirical and journalistic endeavors are often carried out with contrasting tones of sobriety, both forms of discourse exhibit idealism in offering unblinking assessments of social realities. Accordingly, it is hardly surprising that satire and journalism have an extensive history of interplay, dating back to some of the earliest venues of modern journalism. Given satire’s penchant to freely draw from the conventions and norms of a wide range of cultural practices in its pursuit of mounting social critiques, it follows that satire would frequently leverage the tools of journalism for its purposes. The journalism profession has long laid claim to privileged legitimacy in the public sphere, positioning itself as a voice of authority in interpreting public affairs events and issues. Journalism’s traditional (though certainly not uncontested) position of privilege has proven useful to satirists. Likewise, satire’s entertaining and attention-getting qualities have long enticed news media actors.

Academic scholarship centered on the interplay of satire and journalism emanates from a variety of research orientations, employs a diversity of methods, and focuses on a wide range of topics and cultural contexts. The bulk of this body of research highlights satirical work that draws from journalism-based conventions and practices (for example, The Daily Show with Jon Stewart), but pockets of scholarship also consider conventional journalism’s engagement with satire. Still other scholars focus more on how the convergences of journalism and satire spawn hybrid forms of discourse that contribute to public culture in meaningful ways. Building on the insights afforded by these diverse lines of research, future satire–journalism scholarship would be well served by continuing to draw from across these multifaceted research streams."

## [News Satire](https://en.wikipedia.org/wiki/News_satire) ##
"News satire is a type of parody presented in a format typical of mainstream journalism, and called a satire because of its content. News satire has been around almost as long as journalism itself, but it is particularly popular on the web, with websites like The Onion, where it is relatively easy to mimic a legitimate news source. News satire relies heavily on irony and deadpan humor.

Two slightly different types of news satire exist. One form uses satirical commentary and sketch comedy to comment on real-world news events, while the other presents wholly fictionalized news stories."


"Author Samuel Clemens (Mark Twain) was employed as a newspaper reporter before becoming famous as a novelist, and in this position he published many satirical articles. He left two separate journalism positions, Nevada (1864) fleeing a challenge to duel[1] and San Francisco fleeing outraged police officials because his satire and fiction were often taken for the truthful accounts they were presented as. Ironically, the accuracy of many newspaper and autobiographical accounts used to follow the early life of Samuel Clemens are in doubt.[2]

Newspapers still print occasional news satire features, in particular on April Fools' Day. This news is specifically identified somewhere in the paper or in the next day as a joke.

In 1933 and 1934, Metro-Goldwyn-Mayer released a series of ten one-reel theatrical shorts called Goofy Movies, which included "Wotaphony Newsreel," a newsreel parody that paired actual footage with a mocking, deadpan narration.[3][4]

Also in 1934, halfway through a Kraft Music Hall radio show, Dean Taylor ("Others collect the news, Dean makes it!") narrated a fake newsreel which began with a report on the New York Giants and Philadelphia Phillies being cancelled due to bad weather, and baseball season being rescheduled to when farmers need rain."

## [Engaging Journalism Audiences Through Satire](https://gijn.org/2019/12/23/engaging-journalism-audiences-through-satire/) ##
"If you want to tell people the truth, make them laugh, otherwise they’ll kill you.”― Oscar Wilde

"Satire can make journalism more entertaining and accessible for new audiences. It can be challenging to produce in an era of fake news and disinformation; it should enhance rather than distract from good journalism. But how can you turn your headline into a punchline?

Satirists and cartoonists are often among the first targets of authoritarian regimes and those who would silence freedom of expression. This is no accident: Laughter can reclaim power in the face of seeming hopelessness, and temper fear in the face of oppression. Well-wielded satire can communicate truths, challenge taboos, and entertain audiences in a more accessible and engaging way than conventional, straight-faced journalism.

The 'Daily Show Effect' of current affairs satire is a well-studied phenomenon, at least in the US context: Such formats appeal to younger audiences, who are more likely to follow the news, seek further information, recall facts, and participate in political activities as a result of consuming political comedy. A 2017 study in the Journal of Communication found satire was very effective at engaging audiences who otherwise had little interest in politics, while giving them “feelings of political efficacy – belief that they can influence political processes.” As to the negative: Findings suggest satire may also harden audiences, raise the level of cynicism, and contribute to polarization of political outlook (a caveat is that the majority of such media research is carried out in the US, on US audiences, and in the US political context).

Satire is more than just jokes – it must be funny, but it must also make a point. It should show awareness of its subject, 'punching up' rather than down. Amina Boubia from the Open Society Foundations’ Program on Independent Journalism spoke to two veterans of political satire: Isam Uraiqat and Juan Ravell. Isam is the founder of Al Hudood, a media organization specializing in satire, which is behind the eponymous Arabic-language site dubbed 'the Onion of the Middle East.' Juan is CEO of the Venezuelan content agency Plop Media, which also runs the satirical Venezuelan outlet El Chigüire Bipolar.

Satire is important because it can reach a much wider segment of the population and popularize issues society isn’t talking about. It’s even more important in the Middle East because of the massive restrictions on freedom of speech. It is one of the few formats that can override censorship as the authorities don’t always know how to deal with it.

How does Al Hudood work on a daily basis?

Uraiqat: We have editorial meetings every morning during which we discuss the main news of the day in the Middle East. We do a lot of media monitoring, we choose the most important stories, and we ask ourselves: 'What do we want to say about this? What’s our take on this? Why does it matter? What’s the problem with this? Where’s the irony?' We first figure out the angle. Then we come up with phrasing for the jokes.

The jokes themselves are not the most difficult part. Once you train your mind to think in a certain way, it feels like accessing a set of complex templates in your brain. The most important aspect of our work is our editorial take on something, similar to the process of writing an opinion piece. We have developed methodologies to produce satirical news content on a daily basis for the website and for the new monthly print issue. We spent a year and half producing a detailed internal 30-page guide explaining the difference between good and bad satire, and how to produce it. We rely on this guide to orientate new members of the team.

Doesn’t satire depend a lot on the writer’s personality and sense of humor?

Uraiqat: Personality sometimes hurts more than it helps, because it can get in the way of what is being said — some satirists rely on their charisma more than their actual words and content. Most people on our team are introverts; even if someone is not naturally funny they can learn to produce good satire. We also run workshops on how to produce satirical news based on our guide. We take participants through small exercises, then we let them see how we work, bringing them into our daily editorial meetings to discuss story ideas. This helps people understand the importance of conversation between journalists, which is essential for good content production. If there’s one thing we ban at Al Hudood it is saying: 'This is not funny.' That doesn’t help.

Uraiqat: We need to be very careful as satire can sometimes make things worse and go viral for the wrong reasons. We have a flag system and 11 principles to help us operate (these include not “punching down,” being careful not to become too cynical, and “not stopping at 10 principles just because 10 is a complete and compelling number”).

We need to make sure our satirical stories are not misinterpreted as true because this would be fake news, which can happen if they lack enough irony. We also try to cover all sides of a story as much as possible. For instance, in relation to the Saudi-Iranian divide, if we have a story about the Saudis, we make sure we throw something in about Iran too. Whenever possible we do it in the same story, because stories have a life of their own. We even do this in the headline whenever we can, as this can reach six times more people than the story itself."


"A lot of stories can reach further with a little bit of humor or satire. The Washington Post for instance has someone doing satire and managing their TikTok account. But some subjects are impossible to tackle with humor, or at least you have to go about it in a very delicate way. For example, we are working on a project covering the migrant crisis in Central America — we interviewed a specialized reporter, Bartolo Fuentes, who was in the migrants’ caravan, but we also had a Venezuelan comedian who walked with them from Cúcuta to Bogota with a camera. What’s interesting about his web show is that the humor comes from the people he is traveling with: We are not laughing at them, we are laughing with them. It’s very hard to achieve because you have to walk and live with people while having the imagination and sense of humor to befriend them and have fun while on camera."

## [Producing Journalistic News Satire: How Nordic Satirists Negotiate a Hybrid Genre](https://www.tandfonline.com/doi/abs/10.1080/1461670X.2020.1720522?journalCode=rjos20) ##
"Political satire is an elusive hybrid genre that through its evolution over the past two decades has gained both media and scholarly interest. Inspired by American TV shows like Last Week Tonight, a new wave of more journalistic news satire has spread across the world. Studies have scrutinized its contents and effects, but the production side has remained largely uncovered. This study applies the concepts of genre and boundary work to analyze how advocates of this practice relate themselves to news journalism and previous satire. Based on qualitative interviews with 16 key production team members of four topical satire programs, we investigate how Nordic news satirists interpret their aims and work routines. We argue that both Finnish and Swedish news satirists embrace some of the traditional values of journalism such as striving for factuality, political relevance, and monitoring the powerful while they simultaneously aim for more emotional, opinionated, and exaggerated expression than in regular news reporting. The implications of this hybrid, 'neomodern' ethos are examined."

## [Satire as Journalism: The Daily Show and American Politics at the Turn of the Twenty-First Century](https://academiccommons.columbia.edu/doi/10.7916/D8W66SQC) ##
"Notions of community and civic participation, and the role journalism plays in establishing, reinforcing or disrupting them, have been part of American life since the early days of the republic. Equally American, and closely connected with them, are the ideas that our public institutions and elected officials are appropriate targets for both journalistic scrutiny and comedic satire. Press and speech protections that James Madison and Thomas Jefferson wrote into the Constitution have served journalists and satirists - and those who work both camps, such as Ben Franklin, Mark Twain and H.L Mencken - during critical times in our history. Indeed, the blurring of lines between news and entertainment, public policy and popular culture, is not a new phenomenon. Yet, re cent concerns that journalism is being subsumed within the larger field of mass communication and competing with an increasingly diverse group of narratives that includes political satire are well-founded. Changes in media technology and acute economic uncertainty have hit traditional news outlets at a time when Americans clearly want a voice they can trust to challenge institutions they believe are failing them. And during the first decade of the twenty-first century, none has filled that role as uniquely as Jon Stewart, host of The Daily Show on the Comedy Central Network. When Time recently asked readers to identify "the most trusted newsperson in America," Stewart was the runaway winner. That matched an earlier survey by the Pew Center in which Stewart tied Brian Williams, Tom Browkaw, Dan Rather and Anderson Cooper as the journalist respondents most admire. Scholarly work on Stewart typically builds on surveys that show young adults get political information from his show (Pew, ANES). It also challenges his frequent claim that he is nothing more than a stand-up comedian peddling satire, and it argues that his shtick, which he calls "fake news," is actually a quasi-journalistic product. This study moves beyond those issues by reviving questions about the role news media play in creating community. It applies research though the method of the interpretive turn pioneered by James Carey, and challenges the notion that Stewart's viewers are no more than fans who tune in to him as isolated individuals seeking entertainment. It argues that they seek him out because the para-political talk he offers helps them connect with a larger community of like-minded fellows. It draws on Mills' distinctions between mass media and public media, and it uses Freud's interpretation of jokes as a vehicle to address ruptured relationships and wish-fulfillment to examine the demand for a public conversation lacking in the news offered by aloof network anchors who became the faces of broadcast journalism during the latter part of the twentieth century. Finally, it considers the broader implications this nexus between media satire and news reporting - and the communities that are building around it - has for journalism and its traditional role in our participatory democracy. Research for this study, especially ideas and perceptions about how mainstream media work, is grounded in my own professional experience of fifteen years as a daily newspaper reporter, political writer and press secretary in three major political campaigns. Ideas and observations about stand-up comedy come from a year-long ethnography of The Comedy Cellar, a stand-up club in Greenwich Village known for political humor, from numerous visits to tapings of The Daily Show, The Colbert Report and Tough Crowd, and from interviews with a number of stand-up comedians (apart from the ethnographic work) and writers for those shows. Ideas about the interplay between traditional journalism and so-called "fake news," the narrative offered by Stewart and others, come from interviews with roughly a half-dozen nationally recognized journalists who reported on the 2004 presidential campaign. A significant amount of archival research in the popular press - specifically newspapers and news magazines - was necessary because it is a large repository for background into Stewart's professional life and training, and that is essential context for a specific dialogue about the changing landscape of American journalism. Finally, impressions and findings about Stewart's audience and the Americans who are increasingly turning to satire as a vehicle for information to locate themselves in our participatory democracy came largely from observations and interviews conducted in Washington D.C. for four days before, during and after the Rally to Restore Sanity. Early scholarship on the increasingly complex relationship between satire and traditional journalism has focused on the satirists and attempted to define their narratives as something more than comedy - some type of popular journalistic hybrid or emerging narrative that is a new form of journalism. This study acknowledges that debate but moves beyond it. In fact, it is grounded in the idea that although the television shows are new, there is nothing new about satirists using the media of their day to challenge powerful institutions, including public office holders. Instead, it approaches the rise of these satirists by asking what is happening in America that is causing citizens to turn away from traditional sources of news and information in favor of the narratives they offer. It examines the likelihood that the popular demand for Stewart's narrative signals a larger shift in the way Americans think about news and where they go to get it - away from institutional journalism and its longstanding ethos of objectivity and the authoritative voice and toward more independent voices that essentially return to iconic ideas of the press as a tool for building community and enabling conversations between publics rather than acting as the mass medium it did in the latter part of the twentieth century."

## [Evaluating News: Satirical News](https://uscupstate.libguides.com/news_aware/SatireNews) ##
"Satire is a literary genre that employs humor when making commentary on individuals or activities and their perceived vices, shortcomings, or mistakes. In satire, humor is used to underscore an opinion or point about an issue or event. Most often, satirists use wit to criticize or attack something of which they disapprove. Parody (or spoofs), sarcasm, exaggeration, and analogy are defining literary tools of satire that help create its humorous tone.

In journalism, satire most commonly pokes fun at the news or uses parody portrayed as conventional news. While satirical news is defined by its comedic nature, using deadpan humor to create what is called 'fake news,' its underlying objective is to make statements about real people, events, and trends, often with the intent of influencing change. In this way, it is usually fundamentally biased. This objective also highlights a key difference between the satire of news and parody of news: While parody uses humor for humor's sake, news satire employs humor to attain the greater result of social criticism and/or promote change. Politics and current events are common themes in news satire, although the genre is not limited to them."

## [Fake News: Political Satire in the Age of President Trump](https://digitalcommons.usu.edu/cgi/viewcontent.cgi?article=1461&context=honors) ##
"This thesis examines Donald Trump's disruption of political satire. The history and format of the White House Correspondents ' Dinner provides a framework for understanding the shifting relationship between the president's administration, the journalists who cover that administration, and political comedians. These three groups cross paths at the White House Correspondents' Association's annual dinner, which the president traditionally attends and where a headlining comedian entertains guests with a monologue. Trump's decision to skip the Correspondents' Dinner set the stage for a renegotiation of the traditional relationship between president, press, and performer. As President Trump continues to attack both journalists and late-night hosts , the two groups continue to discover common ground. The work of comedians looks increasingly like news reporting, and late-night shows have developed a format based on extensive research and journalistic storytelling. These comedians , however , insist they are only comedians , and dismiss the idea that they are responsible for any political outcomes. Controversy surrounding the 2018 Correspondents' Dinner centered on this question of the role of comedy. Tracing the history of the 2006, 2011, and 2017 Correspondents' Dinners provides a context for examining Michelle Wolfs consequential monologue at the 2018 Correspondents' Dinner , which highlighted both the potential and the limitations of political satire in Donald Trump's political world.

On the 100th day of his presidency, Donald Trump took the stage at a campaign-style rally in Pennsylvania and shouted to his supporters, "You notice now everybody's using the word 'fake news?' Where did you hear it first, folks?!" 1 Trump's implication that he coined the phrase "fake news" and made it popular highlight s his antagon ism toward the news media. That he was holding a rally in Pennsylvania in the first place underscored the tension between the president and the press; on that day, Trump could have enjoyed an extravagant dinner with the White House Correspondents' Association at its annual event honoring Washington journalists. But he declined the invitation via Twitter and went to Harrisburg instead.

He informed his supporters at the rally that "a large group of Hollywood celebrities and Washington media are consoling each other in a hotel ballroom." His assumption that the media needed consolation after his win indicates his belief that the news media collectively opposed him and his presidential campaign. The rhetoric also assured his base in Harrisburg that he was on their side in a struggle against the mainstream media and politicians. As supporters behind him waved signs reading "DRAIN THE SWAMP," Trump emphasized that he "could not possibly be more thrilled than to be more than 100 miles away from the Washington swamp ... with much better people.'

Trump's trip to Harrisburg marked the first time that a sitting president had skipped the White House Correspondents' Dinner in 36 years. Trump's refusal to associate with the press stems from his belief that journalists report fake stories and treat him unfairly.

Fake News used to refer to what Jon Stewa11did on Comedy Central. He sat behind his desk in a suit and tie, a map of the world behind him, and delivered his satirical version of the news. ln a departure from the format of traditional 'fake news' shows, however, Stewart did not read made-up headlines for comedic effect. From his early days at the Daily Show , Stewart saw that 'you can satirize news media conventions ju st by embodying the form in slightly exaggerated or subtle ways,' but 'making the story itself have purpose-that 's when I felt we got something.' 10 He wanted to create more than a news parody. Instead, he saw the possibilitie s for creating a show with a unique voice and a point of view. Stephen Colbert described how the shifting concept of political humor during his time at the Daily Show influenced his own perception of what satire could do. 'I didn't do political humor,' he said. 'Political humor to me meant, 'Hey, Ted Kennedy's drunk again!' Then Jon came in with a real desire to have a satirical point of view about the substance of the ideas, not just the actions of the people.' 11 Stewart envisioned a satirical show that examined the hypocrisy of politician s and viewed news media outlets through a critical lens.

A desire to have a point of view about the news shifted the show toward a more journalistic approach. Ed Helms, an early Daily Show correspondent, expressed the tension between comedy and journalism. 'I love journalism, real journalism ,' he said. "I think it' s an exciting profession, and there were times even during Daily Show segments when I would think, 'God, I wish I could ju st put the comedy aside and really dig in with this person.'

The relationship between the president and the press involves some tension , but the Correspondents' Dinner presents an opportunity, once a year, to relieve that tension and celebrate the First Amendment. The president takes an opportunity to perform a few self-deprecating jokes and make a few good-natured jabs at news media and political figures. A comedic perfonner functions as a mediating figure , keeping everyone entertained and bringing president and press together , if only for one night of the year. Everyone agrees to set aside the inherent tensions associated with their roles as journalists and politicians to come together and celebrate the First Amendment in style.

Stephen Colbert's performance in 2006 was not only a breakthrough performance for him as a political commentator, but also a reconstruction of the triangular relationship between president, press, and performer at the Correspondents' Dinner. The press wasn't laughing , but the public was. And if reporters failed to keep themselves and the administration accountable , Colbert asserted that satirists would.

The choice made sense in light of the 'celebrification' of the Correspondents' Dinner. News organizations traditionally invite celebrities as their guests to the dinner because the presence of A-listers looks good for the networks and increases public interest in the event. The celebrity guest list continued to grow during President Obama's tenure, partly due to celebrity involvement in Obama's campaigns. Obama signaled the growing influence of celebrities by joking that his 'core constituency' was 'movie stars.' Hollywood moved in closer to the world of politics, and that move was reflected around the tables of the 2011 Correspondents' Dinner. The crowd of celebrities muffled the message of celebrating the First Amendment.

Obama took a sarcastic approach . Trump had indicated an interest in pursuing the presidency, and Obama suggested that Trump didn't have what it would take to be commander-in-chief. 'All kidding aside,' he addressed Trump in a mock-serious tone, 'obviously we all know about your credentials and breadth of experience.'
from an audience that could not take Trump seriously. Obama played the straight man as the audience ridiculed Trump with every laugh. Obama's satire made Trump's humiliation public. The laughter that filled the ballroom in response to Obama's performance was based on the consensus that Trump was ridiculous. Not only was he humiliated in public, he was humiliated by the public.

Meyers then got up and drove home Obama's implication that Trump was too ridiculous to be president. 'Donald Trump has been saying that he will run for president as a Republican,' he said, 'which is surprising, since I just assumed he was running as a joke.' The public humiliation angered Trump. As the two headliners of the evening mocked him, the C-SPAN cameras frequently panned to Trump sitting at the Washington Post table. He sat motionless and expressionless, staring straight ahead. He maintained the stone-faced expression as the surrounding tables full of celebrities and political figures erupted in laughter. At the end of the dinner, Trump left quickly, and the next morning he told an interviewer that 'Seth Meyers has no talent.'

The star guests of 2017, in the absence of the president, were Bob Woodward and Carl Bernstein , the Washington Post reporters who broke the story of the Watergate scandal. They didn't tell any jokes, instead opting to sincerely encourage the journalists in the room to keep up the good work.

because we are living in this strange time where trust is more important than truth

He then argued that, while journalists may be doing good work with truth, they had lost trust. 'I don't have a solution on how to win back trust,' he said, 'but in the age of Trump, I know that you guys have to be more perfect now more than ever . .. Because when one of you messes up, he blames your entire group. And now you know what it feels like to be a minority.'

The award commended Oliver for his ability to focus on important stories, 'at times becoming an investigative joumalist.' But in an interview with
PBS NewsHour's Jeffrey Brown, Oliver dismissed the idea that he has any influence as a comedian. When Brown asked if Oliver had been surprised at how many people responded to his story on net neutrality and wrote to the FCC, Oliver replied with skepticism, 'I don't know ifl really have any power.' As Brown argued that the public response to the show indicated a certain amount of comedic power, Oliver maintained that the amount is insignificant. 'I have no moral authority,' he said, 'I'm a comedian.' 

Minhaj warned journalists that one of the most difficult aspects of being a minority is that 'when you actually manage to do great work, you get hit with the most condescending line in the English language: 'Hey, you're actually one of the good ones.' Then you have to smile and say thank you . Kind of sucks, doesn't it?' With his rhetorical question granting journalists temporary minority status, Minhaj underscored the newfound feeling of understanding and appreciation that journalists and comedians had for one another. In the absence of President Trump , and at the tamest Correspon dents' Dinner in years, Minhaj exuded a 'we're in this together' attitude. 'Your work is invaluable,' he said. 'I mean that as a fake journalist. I'm rooting for you.

As a result, Trump's presidency has highlighted some of the limits of satire. Michelle Wolfs crass and straightforward monologue in 2018 exposed what Masha Gessen calls 'the fiction' that all the guests of the Correspondents' Dinner "inhabit the same reality, and that both the humor and the objects of the humor are innocuous.' 'Rather than provide an evening of innocuous entertainment, Wolf opted for humor with a political agenda. In return, her routine was renounced by the journalists who had hired her, and the Correspondents' Association decided to quit inviting comedians to their dinner.

Comedians may be right about the limits of their political satire. During "A Closer Look" segment about Deputy Attorney General Rod Rosenstein's alleged suggestion to wiretap the president, Seth Meyers noted that so many jokes comedians had made about a Trump presidency had come true. 'Don't make jokes,' he concluded. 'Jokes are broken now .'"

## [Deepfakery: satire, human rights, art and journalism in a time of infodemics](https://www.youtube.com/watch?v=QbxinUJcLGg) ##
"Deepfakes as 'history'"

## [What are Deepfakes – and how can you spot them?]


----------


# Hillbilly Elegy and White Culture #
## [Hillbillies, Rednecks, Crackers and White Trash](https://digitalcommons.wku.edu/cgi/viewcontent.cgi?article=1007&context=history_fac_pubs) ##
"The myriad labels for poor and working-class white southerners have long been used as pejorative putdowns an~ embraced as markers of regional and cultural identity. Although ver- nacular usage almost certainly goes back in time much further, appear- ances in print of the dominant terms for these people on tlte social and economic fringe date back to at least the 18th cen- tury. The term 'cracker' first appeared in the 1760s whereas 'P90 white trash' (often condensed to 'po' white trash' or just 'white trash') began to appear semiregularly in the 1830s, used first by African Americans to refer to non-slave- holding whites and then by wealthier whites as a means of stigmatizing and denigrating nonblacks they deemed be- neath them. 'Redneck' and 'hillbilly' date only to the turn of the 20th cenc tury, both first appearing in th~ explic- itly political context of supporters or opponents of southern politicians but quickly thereafter expanding to other social and cultural settings.

These derisive labels and other similar tenDS were intended to in- dicate a diet rooted in scarcity ("clay eater," "corn-crackeri' "rabbit twister"), physical appearance and clothing that denoted hard and specifically working- class laboring conditions ("redneck," "wool hat," "lint head"), an animal-like existence on the economic and physical fringes of society ("brush ape," "ridge r~ner," "briar hopper"), ignorance and racism, and, in all cases, economic, genetic, and cultural impoverishment (best summed up by the pointed label "poor white trash"). These terms spread with working-class southern whites as they migrated to southern and mid- western urban centers in the mid-20th century. In the civil rights movement era of the 1950S and 1960s these descrip- tors, especially "cracker" and "redneck," were widely used in news accounts and by civil rights activists to emphasize the backward-looking racism of southern lawmen and townspeople who fought integration.

Slightly later, in the 1920S,West Vir~amine wars when striking miners wore red bandanas, it was tied to radical unionization efforts. In the 1950S and 1960s it became synonymous with virulent racism and opposition to civil rights lions of the white working class (largely but not exclusively men) worked to redefine the term as a cultural identifier positioned in dual opposition to both the power and cultural values of the upper-middle class and what it perceived to be a welfare-dependent and minority underclass. In the decades since, the success of Jeff Foxworthy's You Might Be a Redneck If... joke books and comedy routines and similar
cultural products have given it a more benign and broadly middle-class cultural meaning but still one that indicates racial whiteness and a resistance to intellectualism.

'Hillbilly has proved to be the most ambiguous of these labels. Although ostensibly a term for residents of the southern mountains from the Ozarks to the Blue Ridge, the label has been applied to people and culture across the broad interior of the nation. It has been used simultaneously to evoke, on the one hand, degradation, violence, animalism, and carnality and, on the other, romanticized rurality, cultural and ethnic purity, pioneer heritage, and personal and communal independence and self-sufficiency. It thus has resonated most broadly with audiences both nationally and in the southern hill country and has been the most commonly used such label in popular culture. It has applied to country music (indeed, 'hill- billy music' was the standard if at times contested term for the genre from the 1920s to the 1950s}, a range of cartoons and. comic strips, and the title of one of America's most popular and influential television shows (The Beverly Hillbillies). Both adbpted and rejected by southern mountain folk living in and outside of the region, it retained in the early 21St century its fundamental ambivalence, if not the social bite it once held.

'Poor white trash,' the crudest of these terms, is nonetheless still routinely used in televised comedy and talk shows and even general conversation. It also
is the one that most starkly reveals the fundamental tensions in all these words between supposed normative racial identity ('white') and an antinormative (indeed, uncivilized) cultural and social status and outlook:Throughout the early 19th century the term was employed for different purposes by African Americans, abolitionists, and slavery apologists and defenders, all of whom used the label to critique (explicitly or implicitly) or justify the institution of slavery and its impact on southern SOciety. In the early 20th century, textile mill operators and middle-class progressives who were heavily shaped by the predominant Social Darwinist view of biological social determinism also used the concept as a way of culturally bounding poor whites as lazy, dirty, criminal, and imbecilic degenerates who threatened national progress.. The term thus was a means to assert the unquestionable superiority of their own cultural value ystem. By the late 20th century the term had lost altogether its southern regional specificity, instead becoming a generalized if increasingly cartoonish critique of non-people of color who rejected middle-class stan- dards of social advancement and ways of living. In the same manher as did Its companion terms, it thus reinforced the· 'naturalness' of middle class sensibilities and justified economic inequality by blaming poor whites for their own lower social and economic status. Used as explanatory labels, these words thus we're ultimately means of avoiding con~erns about the failures of capitalism to truly I benefit all in the society.

The explicitly political origins and consequences of these terms and their do~tly derogatory connotations, however, were hidden behind their ostensibly comical overtones, particularly for middle- and upper-class whites in positions of authority, but also, in a different context and with a different intent, for working-class whites and people of color. Accordingly. they have proved to be remarkably semantically and geographically malleable. As noted, 'since at least the 1970s, "hillbilly," "red- neck," "cracker," and, more recently, even "poor white trash" have all been, reappropriated by some working-class and lower-middle-class whites as badges of class and racial identity and pride. In, this context, they mark opposition to (or at least distinction from) hegemonic middle-class social aspirations and norms and, less explicitly, to the relative gain in status of Mrican, Americans and other minority social groups. As these terms have been increasingly embraced by those they were intended to deni- , grate, they have sn:etched well beyond their southern origins and are now used and adopted around the United States and even Canada."

## [Johnny Cash: The Life](https://www.newyorker.com/magazine/2013/12/23/briefly-noted-736) ##
"Johnny Cash, by Robert Hilburn (Little, Brown). When Johnny Cash appeared at Folsom Prison on January 13, 1968, he was trying to recover from an artistic slump and prayed that his voice wouldn’t give out. “I took more pills that morning than I ever had in my life,” he recalled. But, as Hilburn, who attended the concert, writes, in his meticulous biography, the performance produced one of Cash’s greatest albums. Hilburn gives a frank account of the singer’s life, including his struggles with drugs and alcohol, and his probable affair with his wife’s sister, Anita. But while he does not glorify Cash’s worst behavior—smashing chandeliers, throwing a typewriter out a window, setting his car on fire—he is at times too eager to offer an excuse in Cash’s defense."


----------


# Sadomasochism in Music #
## [Why Readers Love Big Biographies](https://www.salon.com/2013/10/27/why_readers_love_big_biographies/) ##

## [Sadomasochism in Music](https://ultimateclassicrock.com/politically-incorrect-songs/) ##

## [The Darker Side of Dixie: Southern Music and the Seamier Side of the Rural South](https://lib.dr.iastate.edu/cgi/viewcontent.cgi?article=11911&context=rtd) ##
"This study investigates several issues in southern culture that have here to fore been largely ignored. Music has been, and still is, a major force in southern society, and for hundreds of years this mode of communication has reflected regional ideas as much as any social institution. In order for music to reflect southern culture, it must first speak the language of the region, exhibit regional cultural attributes, and accept thedistinctivecharacteristicsoftheSouth. By so doing, music becomes culturally accepted and, therefore, it reinforces the messages, the opinions,andtheideasofsouthernsociety. This study examines some of the rural cultural themes utilized in southern music. The principal cultural topics to be analyzed include racism, domestic violence, male control over women, drunkenness, brutality, murder, gun ownership, Confederate symbolism,folk justice, and family honor. Since these themes are evident in folk music, early blues tunes, post-World War II country lyrics, and southern rock and roll of the late twentieth century, music illustrates the continuity of southern culture."

"This was especially true when a family member had been the victim. In the late twentieth century, for example, when Charlie Daniels called for lynchings, and 'an eye for an eye and a tooth for a tooth,' and when Hank Williams Or claimed that he was going to shoot the man who killed his family, both artists sounded similar to the rural mountain balladeers of the nineteenth century. Not much had changed. In the eyes of these performers, vigilantism worked, and it should be used. Moreover, this study will explore other topics, such as illegal drug use, which have not been major themes in southern music. By doing so, it will address the question whether those southern African Americans who migrated to northern urban areas prior to the World War II deserved to be labeled cocaine fiends, or whether this was a racial stereotype created by northern whites."

"Musical lyrics are of value to historians because they are cultural artifacts of a community and a culture that allow scholars to examine the issues, problems, values, and ideas of the time period in which the lyrics were written. When dealing with gender issues, for example, song lyrics are excellent historical tools because they portray gender roles that illustrate how both males and females think and act, or are expected to act, within a given culture. The study of these kinds of lyrics are also important because the words demonstrate how southern men dealt with gender issues. Since musical lyrics reflect cultural attitudes, if the culture of the rural South approved of the domination of women by men, and if southern men physically abused women, these themes will appear in the region's
music."

"They should pick cotton instead of guitar strings."

"Besides exploring domestic violence and gender control, this study will also examine how rural southerners responded to other important issues. During the Civil War and Reconstruction eras, for example, what were the major southern symbols, and how did southern songsters deal with losing this all-important war? Music allows scholars to determine if the common people were apologetic or unrepentant. Similarly, in the late nineteenth century how did folk balladeers deal with the increased rates of raciallynchings? Whodidtheyblamefortheseacts,thevictimsorthe victimizers? Howdidtheyexplainthebrutalmutilationsandexecutionsof African American males? By omitting certain realities, did these musicians promote racial hate? Furthermore, in this era of high murder rates, how did southerners view their murderous world? When someone was killed, who or what did they blame? Similarly, were the people shocked, or did they simply consider brutality a regrettable but indubitable fact of southern life? Moreover,how did African American and white women deal differently with domestic violence? Is it significant that in blues songs African American women often grabbed a firearm and fought back, but in folk music Caucasian women usually begged for mercy?"

"Despite growing industrialization and urbanization, the myth of the rural South also survived in popular imagination."

"In that regard, this work will examine the responsibility southern music had for the survival of the region's rural image that still haunts southerners today. Moreover, it will analyze how southern males historically compared themselves to northern males. In the late twentieth century,for example,did southern redneck rock groups, like their nineteenth-century predecessors, still push the archaic notions that not only could any southern man"

"Finally, when modern country and rock musicians flaunted Confederate symbolism, were they only telling everyone that they were proud to be
southerners? In the 1970s, for example, why did Georgia crowds go berserk when Lynyrd Skynyrd's lead singer, Ronnie Van Zant, waved a Confederate flag and screamed out, '01e' Neil Young should remember that a southern man don't need him around, anyhow?' Southern music gives scholars a unique insight into these, and many other, important social questions."

"Moreover, video tapes of old southern musical shows enable historians to comprehend the excitement audiences exhibited for particular songs. A 1969 episode of 'Del Reeves' Country Carnival,' for example, illustrates this splendidly. When Reeves sang 'Are You From Dixie,' the audience, composed of males and females in their mid-forties, were energized. Similarly, southerners went wild when Johnny Cash yelled out, in his first hit tune 'Ha Porter,' that he had to 'get back' to the South, so that he could 'plant my feet on southern soil, and breath that southern air.' Similarly, modern concert performances by such southern groups as Lynyrd Skynyrd, Alabama, Black Oak Arkansas, and Hank Williams Jr. offer scholars valuable insight into the culture. A teach of their concerts Confederate symbolism emerged as a major theme.'"

"Therefore, many southern groups, such as Confederate Railroad and Molly Hatchet, have used southern emblems, such as the Confederate Flag, on their jackets to increase sales."

"These artists were not only popular, but they also either sang songs that reflected the culture or stressed their southerness. On most of its albums,tapes,videos,and compact disks,for example, Alabama usually included several numbers that either glorified or romanticized the South."

"Unlike the earlier rockers, these southern males were not only belligerent, but they always emphasized their southern roots. These
men, for example, continually claimed that a southerner could 'beat the hell' out of anybody. In fact, most pushed southerness to the extreme."

"Many bands told young southerners to be proud of their history."

"Unlike Elvis, these whiskey-soaked, macho-acting, southern males also gathered fans and sold millions of albums by reverting to old negative southern themes, such astheConfederacy,racism,whiskey,guns,andviolence, Afewofthemost prominent bands in this category included Lynyrd Skynyrd, Molly Hatchet, Black Oak Arkansas, The Charlie Daniels Band, .38 Special, The Marshall Tucker Band, The Ozark Mountain Daredevils, ZZ Top, The Allman Brothers, and The Outlaws."

"a very dark side to southern rural music"

"Instead of being only a happy and positive place, this music illustrates that for generations racism, sexism, vigilantism, hate, violence, crime, alcoholism, murder, and poverty have been significant aspects of southern society."

"In retrospect, although not every person residing in the South would approve of all the themes outlined in this study (not every southerner, for example, hates homosexuals, holds firm to fundamentalism, believes in white supremacy, or thinks that a real man has to be a rugged fighter), music
reflects that such ideas have been culturally significant."

"It would be foolish to claim that men only killed or beat women in the South."

"This is culturally significant, because it indicates that gender and control was deeply ingrained in southern culture."

"Because few historical sources deal with the killing of southern women, particularly the rural poor of both races, music offers scholars a unique insight into this hidden problem. Pre-World War II femicide lyrics are of value to historians because they are cultural artifacts of a community and culture that allow scholars to have an unobtrusive look into the issues, values, and ideas of the time period in which the lyrics were written. When dealing with gender issues,such as femicide, song lyrics are excellent historical tools because they portray gender roles that illustrate how both males and females thought and acted, or were expected to behave, within a given culture. The study of southern femicide lyrics is also important because the words demonstrate how some southern men dealt with women when certain gender specific situations arose, such as adultery and pre-martial pregnancy. Of course,not every souther nmale killed or even sanctioned the slaying of women. In fact,it would be foolish and historically irresponsible to claim that every man who caught his wife in the act of adultery, murdered her. Music, however, is useful because it does indicate that such ideas were firmly established in the region's intellectual mind-set."

"Even though females have been murdered throughout American society, on certain occasions southern culture sanctioned its use more than other areas of the country. Between 1882 and 1927, for example, ninety-two women were lynched in the UnitedStates."

"In fact,historican Dickerson D. Bruce Jr., pointed out that in the nineteenth-century South, violence was viewed as 'an essential fact of human life some how built into human relationships." 

"In addition to being lynched, burned at the stake, and killed in race riots, in the post-Civil War era African American females were simply 'just murdered.'" 

In such an environment, music reflects that both black and white women were killed. Similarly, both black and white folk songs show the extent of lethal violence against southern women in the pre-World War II era. In fact, no matter how sensational these folk songs might appear to contemporary observers, in the past rural southerners did not find the stories inconceivable. When the songs dealt with vicious female homicides they discussed events that occurred. Most of the local folktunes were indeed factual."

"The most violent act that can be committed is murder, and imported folk ballads that described the killing of women were often more popular in the South than in other sections of the United States. These tunes entered the region via a wide variety of non-North American locations, including England, Scotland, and Norway, as well as several non-southern North American sites. Although the songs originated from different locales, they were popular with both African American and white rural southerners from the Florida Everglades to the Ozark mountains"

"According to scholars such as Michael E. Bush, female murder tunes were popularintheSouth. They were a major part of the oral tradition. In fact, imported murder ballads that depicted the murdering of women were found in every southern state."

"Although not every imported femicide song was popular throughout the South, several such violent ballads and their numerous variations were prevalent in one or more southern states. These violent tunes were popular with rural southern audiences for several reasons. Chiefly, rural southerners identified with the message, because as many scholarly studies have shown, murder was an integral part of the culture. Since, according to several music scholars, only songs that mirrored some essential element of southern culture survived in the region's oral tradition, it is important to analyze which events remained unchanged in imported femicide tunes. What was the crucial element in these songs that enabled them to endure in the South, sometimes for generations after they ceased to be sung in Europe, while other tunes simply faded from the region's collective memory? First and foremost, although several southern versions of a particular
female murder ballad might differ in tone or location, one thing always remained the same--a woman was killed. By examining the femicidal ballads Appalachian whites sang, it became apparent that material not essential to themurderdidnotsurvive. Similarly, in the Virginia version of the Scottish number 'Jellon Grame'," the central theme, the killing of the woman, stayed, but the Scottish dialect and uncommon words were changed or omitted. Because femicides occurred in the region, southern ballad singers did not change that aspect of the tune. Rural southern audiences under stood that when certain situations arose, males could and did kill females."

Southern femicide tunes are excellent historical sources, because they enable scholars to cut beneath the facade of southern life and see how southern society treated and viewed women. They indicate, for example, that a paternalistic society existed in the South. In fact,they prove that southern culture even condoned the use of lethal violence to control women. This can best be seen in adultery songs. Not only are these tunes filled with deadly violence, but they also reflect that southern males sanctionedthisviolentbehavior. Several southern states have had, and some parts of the region still do have, unwritten laws that allow a man to kill his unfaithful wife."

"Adultery songs are interesting because they show that southern males often believed that it was justifiable homicide to kill women that committed adultery."

"In Lawrence County, Kentucky, during the late 1890s, a similar murder occurred when Lucy Adams was shot and killed by her husband. He found her with another man, Ande Kitchen. Not only was her husband, Jesse, acquitted in court, but an interesting song of the events was written. This particular tune again demonstrates that southern culture justified such behavior. First, the community where the killing occurred. Brushy Fork, maintained thatKitchen 'must die.'"

"The brutal treatment of unfaithful women was not only a white southernattribute. In southern history African American females have been lynched and burned at the stake for no apparent reason, thus, it is not surprisingthattheywerealsokilledforadultery. Lyrically,when African American women ran away from their husbands but then begged to be reunited,they were frequently beaten."

"In black and white tunes the message is clear: women were warned that adultery could lead to death. These songs indicate that both blacks and whites believed that female infidelity was a serious cultural taboo. These songs also reveal that when culturally unacceptable events provoked southern males to commit murder, the community forgave the male killer and chastised his female victim. Although each song had its own particular twist, one thing almost always remained the same: women who cheated on their husbands invariably died, or at the very least were savagely beaten."

"Instead of only reflecting the cultural views southern society had towards women who committed adultery, these tunes are also meaningful because they show how the culture perceived males. While both black and white southern men who killed their adulterous lovers were glamorized in the music, men who did nothing about such relationships were depicted as culturaloutcasts,notheroes. In one folk song, 'May I Sleep In Your Barn Tonight, Mister?,' a man who did not punish his adulterous wife became a 'tramp' looking for pity and a place to stay on a stormy night."

"In both African American and white southern songs murdering males were romanticized, while less aggressive men were scorned. These tunes demonstrate that southern culture had no sympathy for males who did not react violently when their female family members, who were supposed to be under male control, disregarded cultural norms."

"It is blatant sexual exploitation when a man kills a woman simply because she refuses his marriage proposal."

"These kinds of songs are important to understanding gender relations in the South, but to fully understand the topic of female control in southern murder songs historians must consider why men also died in these tunes. Scholars cannot contend, for example, that because adulterous black and white males were also killed, these types of murder songs only demonstrate that a powerful fundamentalist morality was in force throughout the rural South. Instead of portraying religious morality, feminist scholars maintain such murders demonstrate that males controlled females. It does not matter if the homicide was committed by a jealous husband, father, or brother because the 'same complex of control and male authority is involved when men kill men because of jealousy and possessiveness'"

"Like oral history sources, these songs indicate that male family members were expected to kill white women and their lovers for being promiscuous. Second, these tunes portray men who did not kill such women as cowards and bums. As a result these tunes show that a patriarchal society, based on lethal force, existed in the South. These tunes indicate that above all else, southern males believed that women had to be controlled, even if that meant committing murder. In fact, the continual emergence of these themes shows that such ideas were thoroughly embedded in southern culture."

"These sadistic songs help scholars understand gender relationships in southern culture. First and foremost,they show that when dealing with women, males could be brutal. Second, according to criminologists, the use of excessive violence indicates that the men consciously determined to kill their female victims. Third, and on a deeper psychological level, these songs mentioned excessive violence in order to intimidate women. According to Kate Millett, patriarchal societies use violence and the threat of it to keep control. This form of terror is attempted to keep women from gaining any control over their lives. This is evident when considering that the horrible deaths generally followed some sort of deed done by a woman, usually indications of premarital sex or adultery, which was considered culturally unacceptable for females. In 'Pearl Bryant,' for instance, the woman had an abortion before she was brutally killed. In case the threat of being murdered was not enough to deter southern women from breaking cultural norms, the songs stressed that torture, ghastly wounds, or mutilation of the corpse could occur."

"In addition to those tunes, other southern ballads involve the killing of pregnant white women. In fact,some are only found in the South."

"The tunes and the oral histories that surround this femicide are particularly interesting because they reveal that the 'good girl' versus 'bad girl' duality was thoroughly woven into southern culture. Several song versions, for example, imparted the message that bad things happened to 'good girls' when they turned into 'badgirls.' As late as the early twentieth century oral sources pointed out that Lewis 'ruin[ed]' Wise's 'fairname'  by getting her pregnant. She had been a decent, moral woman, until she had pre-marital sex. In their eyes, when she engaged in sex before marriage, she automatically 'disgrace[d]' herself. In fact, this attitudeemergedinmostversionsofthetune. Severalsongsters,for example, sang that Lewis promised to marry Wise so that there would be "no
disgrace.' One balladeer even pointed out that Lewis had 'shame[d] and disgrace[d]' Wise. In fact, when the singer claimed that Wise begged for her life and said, don't kill me, 'Let me live, full of shame,' he made it clear that he thought that Wise had been immoral. In addition, moral lessons emerged in many versions of the tune. One songster even cautioned young women that they must not be fooled into having pre-marital sex, or 'you are sure to meet Naomi's fate.' Another songster warned 'young ladies' not to be 'ruined' by such men."

"In the eyes of rural southern society, an unmarried woman's virginity was all important. Such songs also reflect that women, especially white women, were held to a higher sexual standard than men. Unlike a man, whose 'infidelity' was viewed by area residents as 'a natural sort of thing,' an unmarried white woman who lost her virginity was 'ruined.' Both Wise and Hattie Elliott had been 'good girls' before they met Lewis, but unlike Wise, the 'pure' Elliott 'baffled' Lewis when he tried to seduce her. In the end, however, Lewis chose to marry the virgin and kill the 'ruined' Wise. The moral message was clear; females, especially young white women, had to be 'good' or they had to be prepared to face the lethal consequences."

"Finally, femicide tunes are also culturally significant because they reveal how white southern society expected white women to behave. Infact, there were major gender differences in how white men and white women lyrically met their deaths. While white men often brawled with their would-be killers, and were romanticized for doing so, white women rarely were shown physically fighting their murderers before they were killed. Instead of glorifying white women who fought their attackers, these songs did the opposite--they reinforced the belief that a white woman should not be aggressive under any circumstances."

"These tunes also show that southern women were in a helpless position. Because the culture expected males to be aggressive and domineering, as the music indicates, women often felt helpless. Studies that deal with the abuse of women in male dominated societies show that when women are abused by males and do not fight back, they are expressing what society expects of them. These women feel helpless to protect themselves when 'confronted with a man who had been taught that the hands and feet may sometimes be used as weapons, and that dominance and aggression are justified expressions of his emotion or intent.' When southern music showed white women not responding aggressively to male violence, it reflected cultural realities. According to numerous studies, southern males were accustomed to fighting."

"As these examples demonstrate,the South was a male dominated society where brute force prevailed, and music reflected that most females simply had no other satisfactory alternative but to take to the abuse."

"In fact, if a woman killed her tormentor before he killed her, southern society over looked the male abuse and executed her. This is reflected in tunes such as 'Frankie Silver,' one of the few southern folk songs that depicted a white woman murde ringaman."


"In fact, in 1824 the Supreme Court of Mississippi became the first state court to recognize a husband'srighttobeathiswife. Mississippi wanted husbands to enforce 'domestic discipline.' Moreover, although in the late nineteenth century some southern states adopted anti-wife beating laws, no real enforcement policies existed. These laws were on the books, but criminal sanctions were rarely assessed."

"In 'TheDumb Wife'..."

"In 1931 this blues star released the hit "Southern Can Is Mine," and in 1933 he followed suit with 'SouthernCanMama.'"

"These melodies also indicate that the rural South was a region where both African American and white women, especially wives, had limited power."

"In fact, blues men often attributed their brutal deeds to outside forces. In his 1928 hit 'Nobody's Dirty Business,' Mississippi John Hurt warned his female lover that one 'of these mornings' he was going to wake up drunk, grab his gun, and kill her. Resembling many other folk and blues tunes, in this popular number alcohol conveniently became the scapegoat for a vicious man. This is an indication that, similar to today, in the pre-World War II era alcohol was a frequent excuse, used by both males and southern society in general, to justify the battering of women. As long as society continued to blame domestic violence on either liquor or on the female victims themselves, the abuse would not end.

This indicates that the culture trivialized the abuse. In such cases,the domestic abuse was almost completely forgotten and glossed over. In fact, in the eyes of the singers, who reflected society's views, the female victims generally deserved whatever punishment they received.

Although music exposes that southern society expected males to enforce domestic discipline in their own households, in order to clearly understand how southern culture viewed women, some non-physical abuse tunes mustalsobeexamined. When analyzing southern songs it becomes apparent
that some men did not respect women.

Significantly, in both African American and white music, women were also seen as in animate objects. This could take on many different forms. A woman's looks were seen as essential to her worth. There are many such songs, but a few will suffice.

Other such songs also showed that unattractive women were left to their own protection, while young and beautiful women would be protected by males. Finally, many white songs discussed the 'lily white' hands, the delicate appearance and the child-like behavior of white women. This is not only blatant gender stereotyping, it also reinforced a common view that independent women were unattractive and manly.

Instead of starting out trading a horse, this southern man trades ahuman being. The man first 'buys' a wife. He than attempts to carry her home in a wheel barrow, but it broke, so, he 'sold' his wife and 'bought' a cow.

Moreover, in the most fundamental social structure of southern society, the family, folksongs demonstrate that it was culturally unacceptable for women to make decisions.

The blues also illustrated that black singers considered wives and female lovers the property of men. 

In the lyrics of these males, women were necessary for sex and procreation purposes, but that was about all. In fact, lyrically, females were often seen as disposable items that could be used and abused a male will tell a female that their children are solely her responsibility, and he will not allow her to work outside the home. Moreover, if a woman tries to leave her male lover, he will warn her that she will never see the children again. Similarly, these women are told that their children's friends or teachers will scorn them because of her actions.

If a female did not follow cultural norms, she was told that her children would suffer. In addition,society threatened to take children away from bad mothers. These threats were powerful. In fact, in the nineteenth century society used such warnings to stop divorce."

"In 'TheDumbWife,' for example, a doctor told a man that in order to 'make a scolding wife hold her tongue,' he should beat her with a hickory stick."

"Both the North and the South published hundreds of tunes during the Civil War, but there were major differences in how southern and northern singers and composers communicated the messages. Southern ditties, for example, were less humorous and more "ferocious and savage" than those of the North. Similarly, before and after the Civil War rural southern whites enjoyed singing savage English and Scottish murder ballads. In fact, homicide was one of the most popular song themes. "

Music helped southerners understand, accept, and explain their violent world.

"The prevalence of fighting and murdering tunes also reflects that in the late nineteenth century the rural South was rocked by "widespread and multifaceted crisis." In times of economic and social stress, southern mountaineers drank too much whiskey, behaved aggressively, and fought freely. This behavior eased their anxieties and emotions. It really did not matter that people died in the process, because that was how these males traditional reacted to their problems. Moreover, as the tunes indicated, a crime wave swept the region in the 1880s and 1890s, and southern homicides and prison populations both increased. In some areas of the rural South, the rowdiness actually grew worse in the years between the worldwars. In a small area on the Tennessee and Kentucky line, for example, approximately thirty people died violently between 1890-1919, thirty-three others followed suit from 1915-1940"

"In fact, rural hooligans customarily disrupted religious services by loitering outside church building, shooting their guns, drinking moonshine, talking loud, and cursing at all who passed by.

Since antebellum and postbellum folksongs were similar in how they portrayed social relations and human life, they reinforce studies that indicate the South has traditionally been a violent region. 

hot-tempers, trusted no one, instantaneously turned ruthless at the
slightest unfavorable remark, relied on brute force, and fought savagely. Instead of resembling the gallant gentleman of popular imagination, for example, music showed that southern brawlers would do anything in order to win. They stabbed people in the back, they clubbed defenseless individuals, they ambushed their human prey, and they used whatever weapon was available. Instead of formal duels, songs indicated that mountaineers were more apt to shoot someone from behind a tree or grab a stick of stove wood and bash in their unsuspecting victim's skull."

"African American tunes also reflected cultural ideas. Williamson, and a host of other singers did not have to give a motive, because blacks also thought people were simply cruel. In this regard, music shows southern African Americans and whites had a lot in common. Moreover, these tunes mirrored reality. Although African American rousters, for example, were not to carry weapons on river boats, most did. There were so many stabbings and slashings on some boats that everyone would have to line up and throw their knives into the water. In fact, immediately before World War II when black singers sang about using knives, razors, or guns, they discussed real events. Performer Dickie Wells claimed that both black and white musicians carried weapons. Wells always toted a pistol in the South, because his band 'ran up against a lot of frightful people' who wanted to 'beat up the band or shoot somebody.' When Well spulled his revolver, however, 'the cat' generally 'cool[ed] down.'

Many had abandoned the rural South because of the agricultural depression, only to find similar, or worse, conditions in the urban North. These songs demonstrated that African American males felt their manhood had been challenged. By bragging about killing or beating everyone that ever treated them wrong, these men were fighting back the only way they knew how. As their music indicated they equated manliness with brute force.

Music also mirrors that southern whites terrorized blacks more than African Americans killed whites. Again, these lyrics reflect reality. Although blacks could be violent, they generally directed their brutality towards other African Americans. Both the blues and African American folk music demonstrates this situation prevailed before WorldWarII. 

Such tunes also depicted that intense negative undercurrents existed between the two races.

southern music shows that deep-down African Americans knew the truth and bitterly resented the treatment they received"

The prevalence of violent tunes also reflects that in the nineteenth and early twentieth centuries brutality ruled on southern dance floors. Similar, they mirror the fact that musicians of both races had a rugged life in the South. White southern musicians of tenper formed in rough environments. When the seper formers sang about killing and fighting, they revealed their everyday existences. Fights routinely brokeout at white dances throughout the mountain region. Music illustrates that many square dances were not the stereotypical prim and proper events of popular imagination. In the Ozarks, for example, backwoods frolics were still wild occurrences in the 1920s. People drank too much whiskey, most of the young males carried weapons, and bloody fights commonly occurred. In fact, rival families or neighborhoods met and settled quarrels at Ozark dances. If a gang of Arkansas males felt that they were not 'treated with proper consideration,' dwellings would be destroyed, lamps broken, and roofs 'riddled withbullets.' The settlers of Newton County, Arkansas, enjoyed square dances, but when the liquor flowed freely a "free-for-all fight and the use ofalong,keen-edgedknife,orpistol,wasnothinguncommon." When such fights occurred, chaos ruled, and feuds developed. At these events the proprietors customarily built a special shack in which they stored the violentmales. The men were held there until they cooled off.

"At Memphis taverns dead bodies were simply dumped outside so undertakers could collect them on their nightly runs. The Deep South was no better for black musicians."

"Before World War II every location below the Mason Dixon line may not have experienced extreme violence, but music indicates that at least some key areas did

Although songs cannot prove that the whole South was violent, they indicate that several culturally significant, and extremely large, areas were indeed brutal. Lyrics reflect that scholars were correct when they claimed violence was 'an essential fact of human life' in the South. In fact, the whole musical scene demonstrated that both black and white southerners had a predisposition to lethal violence.

Moreover, violence continued to erupt in times of social stress.

Finally, in the modern era the lack of murder tunes illustrated that rural southern culture and society had changed.

Although various motives behind lyrical violence existed, a significant theme reemerged in the music of the modern South: some southerners still thought that brute force,instead of debate, solved problems.

With sadistic events occurring throughout the region, some tunes, like the people themselves, began to display a very militant, often violent, attitude. In fact, at times southern music became as repulsive as it had been during Reconstruction. Prominent music historian Bill Malone calls this the 'ugliest chapter in country music's history.'"

"It is an indication that many southerners not oly resented the prosperity of the rest of nation, but they also understood the South's weakpoints. Like the people themselves, southern singers put on a 'big front,' but music illustrates that they knew that most southern states habitually ranked last in every positive classification, or first in every negative category. This type of music demonstrates that for several generations many southerners have had a 'chip on their shoulder,' when it came to 'yankees' and northern prosperity.

In the late twentieth century musicians not only lyrically associated the ideas of fighting and southern manliness, but in their public images and actions they also linked the two concepts. 

Furthermore, when all these southern 'good ol' boys' continually sang about adult lives filled with hard work, heavy drinking, and brawling, they mirrored significant cultural traits. This type of music reflects that when many young southern males walked off the factory line or skipped 'study hall' on Friday afternoon, they looked forward to 'picking up' women, filling their tanks with gas, drinking whiskey, and having a fight or two, so they could brag about all of it to their buddies. In songs like 'Wildlife Sanctuary' Bandy and Stampley were proud of this kind of lifestyle. In this song the duo boasted that a 'wildlife sanctuary' should be established for the dying breed of 'good ol' boys' who liked to brawl, throw liquor bottles at the band, and drink until the last drop of alcohol was gone unlike the rest of the United States, a majority of southerners are intolerant of homosexuality. In fact, according to many oral sources, gays are routinely harassed in the modern South. In one major study three- fourths of the participants reported harassment. As this tune indicated, this group was still persecuted openly in the 1980s and 1990s. In the 1980s 'Philip,' a gay male from South Carolina, reported that southerners habitually called him 'faggot' and 'queer.'"

"Another type of factual tunes, feud songs, demonstrates that southern males used guns to uphold family honor.

All of the evidence also shows that southerners have traditionally viewed guns as more than simple hunting tools. In the music of the South firearms are generally used to kill humans, not animals. Instead of only being used for sport, in southern society guns have historically been viewed as protection devices for two of the most important elements in southern culture, family and honor. Feud songs were not the only songs that demonstrated this. 

Although firearms played a significant role in many of the cowboy tunes popular in the South, in these songs women did not customarily posses theguns. 

Theyrevealthat firearms have deep psychological and cultural roots in the South.

By listening to sadistic songs many white southerners proved they did not consider brutality towards blacks morally wrong. Such music indicates that some white southerners felt beating or burning a black person was really no different than punishing a disobedient animal. Instead of being something to abhor, the screams of a member of this race being tortured was something to be danced to and enjoyed." 

"Hundreds of farmers produced illegal whiskey before the Civil War, and back country southerners claimed, 'Where there's smoke, there's bound to
a be whiskey.'

After the Civil War liquor continued to be an important cultural element.

"Although the abundance of liquor tunes reflect that Appalachian inhabitants produced a considerable amount of moonshine, songs also clearly indicate that southerners in other locations participated in the occupation. Northern Arkansas was notorious for ambushing moonshiners and its good, albeit, illegal whiskey. There, many people accepted the trade and sang moonshine tunes. Ozark melodies, for instance, criticized Benjamin Franklin Taylor, a late nineteenth century revenue. Musical numbers also illustrate that non-mountainous regions made whiskey." 

"Besides reflecting that southern males continually bragged about their liquor consumption, such tunes illustrate deep-seated cultural assumptions. When southern singers boasted about their own, or other southern males, drinking habits, they revealed that for generations the macho male complex has been deeply ingrained in southern culture. This was never only a white or a black trait, because music indicates it influenced both races."

"Committing suicide with drugs also emerged in blues tunes, including Sam Collins' 1927 hit 'The Jail House Blues' and Rosa May Moore's 1928 single 'Stranger Blues,' but these were not the only blues numbers that alluded to drugs. As in folk tunes, however, dope tunes never approached the popularity of blues liquor tunes. The use of morphine, needles, cocaine, reefers, and dope are discussed, but references to whiskey alone outnumbered drug terms in blues songs popular enough to be reissued in the 1920s, 1930s, and 1940s. As in earlier black folktunes cocaine was the most prevalent drug alluded to, but this drug made an appearance in fewer than ten songs"

"Also a large majority of addicts were middle and upper class southerners, but folk music was generally the music of the rural poor. In addition, many addicts were Civil War veterans who had been prescribed opiates in the war. This group hid their addictions, because when exposed they lost their pensions. These men would not have jeopardized themselves lyrically"

"Truck driving was one occupation especially affected by this drug. The pill popping habits of truck drivers were as much a part of their macho mystic as diesel fumes and eighteen wheelers. In reality these hard working individuals had to take speed in order to drive longer hours, stop less for food, and keep awake. The more miles they traveled, the more money they made. Southern truckers 'fulled on amphetamine goodwill' were common throughout the region, and they were audiences members in many backwater southern bars." 

Johnny Cash was also addicted to this drug. It was not gangsters, however, but Grand 01e Opry employees who got Cash hooked on the pills that almost destroyed his career."

"It was culturally acceptable for Cash to sing about truckers swallowing speed, because, unlike smoking reefer, the deeds reflected common situations, appeared macho, and were legal
Not only would the police harass musicians, but they might not have a job"

"Since the Civil War militant pro-South symbols have continuously emerged in southern music. During the Civil War, for instance, many melodies glorified the Confederate flag. After the war, flag and militant tunes remained in the oral tradition throughout the rural South. Although the patriotic zeal that accompanied America's entrance into World War II temporarily silenced southerners from glorifying the Confederacy, immediately after the war when the federal government began challenging the South's racial status quo. Confederate symbols reemerged. In fact, in the modern era Confederate symbolism routinely appeared in white tunes, concerts, and on album-cover art. Confederate memorabilia not only engulfed the whole southern rock and roll scene of the 1970s, but several southern performers also continued to utilize such items in the 1990s."

"Civil War and Reconstruction songs about the flag are significant, because they indicate that southerners viewed the stars and bars as more than a piece of cloth: it symbolized their nation. The popularity of these tunes also indicates that although southerners lost the Civil War, from the beginning of Reconstruction many were not going to obey northern dictates. As early as 1866 the tune, 'I'm A Good Old Rebel,' made this clear."

Although red-neck southern rockers stressed Confederate imagery the most, some country musicians also utilized the theme. In 1960, for example, a Hank Williams, Jr. publicity photograph showed the singer standing by his gun and sword collection, and its backdrop was a large Confederate flag."

Confederate Railroad, songs of Dixiee

"When Confederate symbolism continued to sell albums and promote southerness into the 1990s, it indicated that white southerners were still emotionally attached to the Civil War. In many ways they could not forget the past, nor could they completely cast off the idea that they were a unique group of people. Instead of being ashamed of their forefathers' actions, music illustrates that contemporary southerners continued to think and act like their Reconstruction ancestors."

"lyrically proud to be rebels

## [The Darker Side of Dixie: Southern Music and the Seamier Side of the Rural South](https://www.semanticscholar.org/paper/The-darker-side-of-Dixie-%3A-southern-music-and-the-Hutson/79bf78a02849cb107ae7323c22ba420438320b20) ##

## [Country Music](https://www.indiewire.com/2019/09/country-music-pbs-ken-burns-rosanne-cash-marty-stuart-1202173799/) ##
"The actual musicians who came onto the project were also able to help bridge the gap between these facts and the lore. Country music is rife with storytelling, and it’s just natural that some stories become more important that the actual way that events happen. Songwriter Harland Howard had once said, 'Country music is three chords and the truth. In the series, Texan singer-songwriter Rodney Crowell said, 'Country music at its best is truth-telling even when it’s a big fat lie.'"

Embracing country music means to embrace the storytelling, and thus it honors the colorful yarns spun and larger-than-life figures.

I listened to Sam [Phillips] tell how he discovered Elvis. The truth was better than anything Sam ever told, but that nobody was going to go, ‘Sam, that’s not how it happened.'” said Stuart. 'One thing that I love about country music, probably more so than any other culture – maybe the blues rivals it – there are so many American folk heroes. There’s the Coal Miner’s Daughter, the Man in Black, the Red-Headed Stranger, and on and on. They didn’t become folk heroes by pure myth; the thing I love is all of those people were voted in by the people.

The origins of country music can’t ignore the black influence, and the first episode is even titled 'The Rub,' referring to the friction or rubbing between black and white America. For example, the banjo is seen as a classic country music instrument, and it was descended from the African lute that was made from gourds. 'Country music comes from the south because that’s where slavery happened,' the series says.

In the series, only a handful of black country music performers are highlighted, and the common denominator in these stories is how race became an issue in their success and how they were perceived. Of course, standouts like Charley Pride and Carolina Chocolate Drops frontwoman Rhannon Giddens have been embraced in the field, but it still feels as if inclusion is still the exception. Although the series doesn’t venture far past 1996, one wonders how it would’ve handled the importance of someone like Lil Nas X – an out and proud gay black rapper who topped the country charts with his remix of his song “Old Town Road” with Billy Ray Cyrus.

Cash acknowledges how the personal accounts can color the story, but emphasizes that some facts just cannot be ignored, even by those who’d wish otherwise.

My own experience can’t help but color what I put out there. They were very generous and had respect about wanting to see through that prism, but everybody had it through their own prism,' she said. 'Facts are facts obviously – although today we are told they’re not – but they are. Seeing those facts through how they influenced different musicians and also the cohesion of how they told the story – bringing together Appalachian music and Bob Wills and Bakersfield and the African banjo and early folk music – all were put into the piece.'

Early setbacks for black artists are given a passing mention, before the series moves on. African-American musician DeFord Bailey was the first musician to be introduced on the Grand Ole Opry radio program and its first black performer when it became a stage show. When he went on tour, many of his fellow white performers had to stick by him when he was refused service because of his race. But in 1941, during the height of the licensing wars, he refused to learn non-ASCAP songs and was promptly fired. Judge George Hay, who had first hired Bailey, wrote off his longtime colleague, saying, 'Like many of his race, he was lazy.'

Although 'Country Music' doesn’t delve much deeper to examine the everyday racism in the music and its greatest stars, the truth lies in the present day. The mingling of cultures brought about this new genre, and yet, it’s evolved to forget and exclude African Americans. Or perhaps black America has decided to leave country music behind."


----------


## [Scandalous Saddle](https://truewestmagazine.com/the-scandalous-saddle/) ##
"Women riding aside leads to dangerous (and ridiculous) saddle invention.

Buffalo Bill’s Wild West sharpshooter Annie Oakley rode aside, as in this picture, performing '…horseback tricks from a sidesaddle, a contraption with a flat seat, on which the rider sat sideways, and a thick, leather-covered hook, which the rider used to anchor herself by her leg to the horse’s back,' wrote Glenda Riley, in The Life and Legacy of Annie Oakley. She also took advantage of the sidesaddle, Riley added. When Oakley dangled off the side of her horse to pick up a hat off the ground, she appeared as if “she floated on the horse’s back.

As absurd as this may sound, the sidesaddle took hold in the 14th century to protect the virginity of a teenaged princess traveling across Europe to wed the young King of England.

Surprised? Don’t feel alone. Most assume the sidesaddle was the natural outcome of fashion, demanded by the long, flowing, sometimes over-hooped skirts favored for so many centuries.

For some 500 years, women were told the only way a 'proper lady' sat on a horse was sideways, holding on for dear life, a passenger on a 1,500-pound animal she could barely control."


"Princess Anne of Bohemia, a predecessor of the modern Czech Republic, was the daughter of the most powerful monarch in Europe in 1382 when she left for England to wed King Richard II. To ensure her virgin marriage, ruling men instructed her to ride aside, rather than astride."


"Women hadn’t always ridden so askew.

Although ancient Greek sculptures depict women riding aside, it was an option, not a demand. Joan of Arc didn’t ride into battle in the 1400s as a dainty maid. Geoffrey Chaucer depicted his 'Wife of Bath' riding astride in the 1300s. Central Asian women mounted horses like their brothers did, and Amazon women were famous for both their trousers and riding astride.

But then came Anne and the fixation on 'virtuous virgins.' Folks like to mimic royals, so the idea of a sidesaddle spread.

By 1600, riding aside was the only way a “decent” woman could ride a horse without scorn. Most women went willingly along—except for Catherine the Great, of course, who was so powerful, she decreed her court would all ride astride.

'The reins, both of personal power and individual equestrian control, had been taken away by men who now restricted a woman’s political and equestrian destinies,' CuChullaine O’Reilly wrote for the Long Riders Guild Academic Foundation."


"Sidesaddle Designs

The earliest sidesaddle design was little more than a pillow and a piece of wood that faced the woman off to the scenery on the left side of the horse. This replaced the pillion—a small padded seat where the woman rode behind a male rider. The newer saddle allowed the lady to ride alone, but still gave her no control over the animal—she sat so precariously, it’s a wonder all rides didn’t end in injury. Another rider held the reins and led her horse along; she could do little but cling to the pommel and hope she didn’t fall off. The woman was not exactly “riding” the horse; she was just sitting on it as it moved.

In the 16th century, Catherine de’ Medici is credited with inspiring a saddle that allowed the woman to face forward. In this saddle, she hooked her right leg around a pommel on the saddle and placed her left foot in a stirrup. This gave her a fighting chance to stay in the saddle and handle the reins herself. But even this saddle only allowed her to proceed slowly—any speed was dangerous.

Even some female writers agreed. As the 20th century dawned and balked, British author Alice Hayes saw the first rumblings against a sidesaddle, denouncing these 'feminine desperadoes.' Although she vehemently argued women should ride sidesaddle, she did admit that the sidesaddle’s impractical design placed women in harm’s way."

"1893 book, The Horsewoman: A Practical Guide to Side-Saddle Riding"


"By 1900, American women were split on the issue—along geographic lines. Women in the East clung to the sidesaddle as proper and necessary, while Western women saw them as impractical and dangerous. Western women were far more likely to use a horse for farm and ranch labor than their Eastern sisters, who saw the horse as a weekend entertainment.

'Not one of us would tolerate the old-fashioned sidesaddle,' said one of the record 25 women inducted into the Vaquero Riding Club, composed of expert horsemen of Spanish heritage, during the early 1900s."


“'Two-Gun' Nan Aspinwall began calling herself 'Montana Girl' in 1906, two years before she started performing with Buffalo Bill’s Wild West and Pawnee Bill’s Great Far East troupe, where she became a hit."

“Snappy Western Girl Who Rode Horse Clear Across Continent”

Death Valley Days
Sisters in the Saddle

"In 1912, Alberta Claire made her 8,000-mile solo trip from Wyoming to Oregon, down through California, across the Arizona desert and into New York City. Along the way, she declared to anyone who’d listen that she had both the right to ride astride and the right to vote.

History does not record whether or not Claire ever met New York’s Inez Milholland, though they were contemporaries. Nevertheless, these two women were sisters in the saddle.

Nobody tied politics and riding astride as did Milholland, the beautiful face of the suffrage movement.

Milholland was born into a liberal family of means in Brooklyn in 1886. She became a lawyer—turned down by Yale and Harvard because of her sex—and gave lectures throughout the nation to support women’s rights. She led suffrage marches in 1911, 1912 and 1913, while astride a white horse named Gray Dawn."


"Getting up on a high horse takes on a new meaning when you think about the public performances of women ascending hot air balloons while seated sidesaddle on her horse, as shown in this circa 1880 lithograph. The first horse sent aloft in the air flew by platform, a dream realized by fox hunter Tetu-Brissy in 1797, and the horse graduated to a balloon in 1830, thanks to English aeronaut Charles Green. — Courtesy Library of Congress"


"Western women were also making their mark as North America’s first professional female athletes—in rodeos. Not one of them considered riding sidesaddle as they put their lives on the line to entertain while on horseback."


"Strangely enough, though, one of the greatest rodeo queens got her start riding sidesaddle. In her first rodeo event, at a county fair in 1906, 13-year-old Vera McGinnis was the only rider who rode sidesaddle, in a dress, competing against much older girls. 'It so happened that the horse show judge was a bit old fashioned and frowned upon such things as girls riding clothespin-style so Vera won first prize, a gold-handled umbrella,' True West reported in 1991."

“Sidesaddles and Suffragettes, the Fight to Ride and Vote.”

“'The fall of the sidesaddle is linked to the rise of female liberty, for it was the dawning of political freedom which brought about the overdue death of this repressive equine invention,' she wrote."

The Book of the Horse
Outrageous Arizona
Cattle Kate

https://biologicalrootsofhumanity.wordpress.com/2019/06/15/a-cultural-shift-or-variation-cowboys-and-the-confederate-flag/


----------


# Manifest Destiny and Frontiers #
## [Revisiting China’s Southern Frontiers in the Ming–Qing Periods: Editors’ Introduction](https://www.tandfonline.com/doi/full/10.1080/00094633.2019.1635850) ##
"In 1911, the revolution led by Sun Yat-sen (1866–1925) and his associates in the Revolutionary Alliance that overthrew the Manchu Qing dynasty was a landmark event in the history of Asia. It not only founded the first republic in Asia, but also ended the imperial rule of the country in the past two millennia. In other words, the 1911 Revolution marked the transition of empire to nation-state for China. While this change was consistent with worldwide historical developments, this was by no means an easy and smooth process for the Chinese. From the early 17th century, nation-state building began in Western Europe and gradually became a main trend of history around the world in the subsequent centuries. One of the major differences between empire and nation-state was shown in its policy toward outside regions. From ancient period, Chinese rulers entertained the notion of “All under Heaven” (tianxia 天下) in describing its imperial realm. Some scholars have considered such view as the “boundless world” (wubian tianxia 無邊天下). By contrast, a nation-state is built on a clearly defined border, or with the “limited boundary” (youxian jiangjie 有限疆界).1 From another perspective, an empire usually consisted of innerland and frontier, or center-periphery regions, whereas a nation-state hopes to control, indiscriminately, all regions within its territory. The changing meaning of the term Zhongguo 中國 underscored the transition of China from an empire to a nation-state in the early twentieth century. Over the long imperial period, Zhongguo usually referred to the core area under the reigning dynasty. As such, it was rendered as the “Middle Kingdom.” But in the process of nation-building, Zhongguo began to be used, by historians in particular, to describe China as a modern state.

But the imperial legacy remained, particularly with respect to modern China’s territorial control. The Republic of China of 1911 and the subsequent People’s Republic of China founded in 1949 both inherited the Qing empire’s territory, consisting such frontier regions as Manchuria in the northeast, (Inner) Mongolia in the northwest, and Tibet in the southwest. In this issue of Chinese Studies in History, we present the studies of frontier regions in South China, including today’s Tibetan Buddhist regions in Sichuan, mountainous areas in Yunnan, and southeast coastal regions in Fujian, during the late imperial periods. Our purpose is to showcase how the Ming and Qing dynasties envisioned their territories, designed their frontier policies, and implemented them for exercising control.

The field of frontier studies was dominated by a center-periphery discourse for a long time. That is, the idea of “All under Heaven” was a dominating concept for rulers in China, regardless their ethnicity, to entertain an all-encompassing notion of their world. Meanwhile, most rulers also had a full recognition that their imperial realm was composed of various zones, differentiated by levels of cultural development and characteristics of ethnicity. In early imperial China, for example, the policymakers had already developed the “five zone” concept in perceiving their territorial and demographic composition. For each zone, they designed different policies to best exercise control, ranging, as it were, from “free reign” to “acculturation” and “pacification.” In building modern China, needless to say, the Chinese government developed markedly different ruling policies toward frontier regions. But after founding of the People’s Republic of China in 1949, communist leaders also established several “autonomous districts” in outside regions like Xinjiang, Tibet, and Guangxi, which remain in place today. Thus, there has been a level of historical continuity with respect to frontier policies. At the same time, we also recognize that in more recent years, Chinese leaders have made significant changes to their ruling methods of these aforementioned regions. All this, we hope, attests to the importance of the study included in this issue.

This issue is edited also because though the outward expansion through military and economic vehicles from China’s political centers was, by any measure, the basic pattern that dynasties in Chinese history took shape, the historiography on such processes has experienced dramatic change over the past decades. The idea of overwhelming imperial extension that encompasses political annexation, cultural assimilation, and economic colonization has been constantly challenged. Instead, more attention is cast on the so-called frontier dwellers who were previously deemed voiceless and had no agency in the face of imperial imposition. Such a shift is at first made possible by the discovery of local materials in the so-called frontier regions, and second, is a reflection of new scholarly interest that calls for revisiting the nature of empires with marginalized experiences. The four articles in this special issue together present how this new trend is played out in Chinese academia."


"At the risk of oversimplification, we may perhaps argue that there have occurred two “turns” in the historiography of Chinese frontier history that affected the study as a whole in recent years: the “empire turn” and the “local turn.” The “empire turn” reconsiders “frontier” not as clearly demarcated border that separates nation-states, but the utmost reach of imperial expansion. In other words, “frontier” is not a linear boundary that defines the realm of state control, but rather an open sphere of encounter, contestation, and test point of the limit of imperial power. In this way, studies on the frontiers following the “empire turn” are usually situated in the macro frameworks of transnational geopolitics or structural comparison between multiple polities. By contrast, the “local turn” usually examines frontier history at the micro level. By paying attention to specific locales or communities, scholars tend to highlight on-the-ground agency and grassroots improvization. As such, the local turn enables scholars to reconsider the center-periphery dichotomy. Indigenous voices from the frontier may reveal how the so-called peripheries conceived themselves and their domains as the center lying amid multiple outsiders from afar. Therefore, the history of frontiers should be investigated on their own terms. The notion of “center-periphery,” as a conceptual tool, tends to marginalize the frontier region’s role in state formation. While the interaction between the metropole and the frontier is not always precipitated by the former, it is often the frontier that triggers changes and bends the state apparatus to its own will."


"The rise and development of two schools reflect and influenced the aforementioned two turns in Chinese frontier history: the New Qing History school (新清史) and the Southern China school (華南學派). One must note that these are not self-appellations, but rather names given by others. Although dissents existed within both schools, scholars tend to agree on certain key points or address common questions in similar ways. The New Qing History scholars question the hegemony of Chinese materials and classic Chinese historiography. On the contrary, they rely on non-Chinese sources to reconsider the structure of Qing imperial repertoire and revisit “China” as an analytical category. Highlighting the diversity and variety within the empire, the New Qing History scholars take frontier regions as the manifestation of the Qing empire’s heterogenous imperial nature. But is the Qing unique in this regard? As indicated in Lian Ruizhi and Zhao Shiyu’s articles, the Ming empire was quite flexible as well in creating an administrative structure that allows semiautonomous secular regimes and religious communities for indigenous practices. In that case, do we see any fundamental difference between the Ming and Qing empires’ multiethnic and hierarchical imperial order? Another contribution made by the authors of this special issue is to challenge the hegemony of ethnicity. As one significant keyword in early-stage New Qing History scholarship, ethnic identification was given extensive attention to check the domination of the Sinicization discourse. However, as Chen Boyi and Hu Xiaobai point out, ethnicity was not always the parameter of the Qing empire’s frontier policy. Chen claims that approaches to restructure grassroots communities in China proper may not differ much from those in non-Han regions; religion, as indicated in Hu’s work, oftentimes transcended ethnic and linguistic boundaries and functioned as a significant variable that formed and reformed frontier landscape. The four articles on Ming–Qing China’s southern frontier demonstrate great potential to dialog with the New Qing History scholarship that so far has shed more light on the empire’s Inner Asian frontiers."

